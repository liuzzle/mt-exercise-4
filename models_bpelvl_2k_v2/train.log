2025-05-29 17:37:49,722 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                           cfg.name : transformer_sample_config
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                     cfg.data.train : sampled_data/train.de-it
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                       cfg.data.dev : sampled_data/dev.de-it
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                      cfg.data.test : sampled_data/test.de-it
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : joint_vocab.txt
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : bpe_codes
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : joint_vocab.txt
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : bpe_codes
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -             cfg.testing.beam_alpha : 1.0
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-29 17:37:49,722 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -             cfg.training.model_dir : models_bpelvl_2k_v2
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-29 17:37:49,723 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-29 17:37:49,725 - INFO - joeynmt.data - Building tokenizer...
2025-05-29 17:37:49,727 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 17:37:49,727 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-29 17:37:49,727 - INFO - joeynmt.data - Loading train set...
2025-05-29 17:37:49,813 - INFO - joeynmt.data - Building vocabulary...
2025-05-29 17:37:49,835 - INFO - joeynmt.data - Loading dev set...
2025-05-29 17:37:49,836 - INFO - joeynmt.data - Loading test set...
2025-05-29 17:37:49,840 - INFO - joeynmt.data - Data loaded.
2025-05-29 17:37:49,840 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 17:37:49,840 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 17:37:49,840 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-29 17:37:49,840 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ or@@ e: Die Ab@@ w@@ end@@ ung der K@@ li@@ ma@@ k@@ at@@ a@@ str@@ op@@ h@@ e
	[TRG] A@@ l G@@ or@@ e: ar@@ rest@@ i@@ amo il ris@@ cal@@ d@@ amento glob@@ ale
2025-05-29 17:37:49,840 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)   (5) £ (6) ¥ (7) © (8) « (9) ®
2025-05-29 17:37:49,840 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)   (5) £ (6) ¥ (7) © (8) « (9) ®
2025-05-29 17:37:49,840 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2002
2025-05-29 17:37:49,841 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2002
2025-05-29 17:37:49,841 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 17:37:49,868 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 17:37:49,870 - INFO - joeynmt.model - Total params: 3411712
2025-05-29 17:37:49,870 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-29 17:37:49,870 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-29 17:37:49,871 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-29 17:37:49,871 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-29 17:37:49,871 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-29 17:37:49,871 - INFO - joeynmt.training - EPOCH 1
2025-05-29 17:38:02,871 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.978551, Batch Acc: 0.034511, Tokens per Sec:     5561, Lr: 0.000300
2025-05-29 17:38:16,284 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.800228, Batch Acc: 0.052176, Tokens per Sec:     5163, Lr: 0.000300
2025-05-29 17:38:29,649 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.758311, Batch Acc: 0.060279, Tokens per Sec:     5029, Lr: 0.000300
2025-05-29 17:38:43,334 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.734516, Batch Acc: 0.065002, Tokens per Sec:     5318, Lr: 0.000300
2025-05-29 17:38:56,319 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.656026, Batch Acc: 0.069276, Tokens per Sec:     5374, Lr: 0.000300
2025-05-29 17:38:56,319 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:40:39,869 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.65, ppl:  38.65, acc:   0.07, generation: 103.5375[sec], evaluation: 0.0000[sec]
2025-05-29 17:40:39,870 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:40:39,955 - INFO - joeynmt.training - Example #0
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'che', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'i', 'c@@', 'i', 'c@@', 'i', 'c@@', 'a', 'di', 's@@', 'u@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'i', 'p@@', 'i', 'p@@', 'o', 'di', 'un', 'p@@', 'i', 'p@@', 'i', 'p@@', 'i', 'di', 'un', 'p@@', 'o', 'di']
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Hypothesis: E un po di un po di un pa di un po di un po di un pa di un pa di un pa di un pa di un pa di un pa di un pa di un pa di un pa di un pa che un pa di un pa di un pa di un pa di un po di un pi ci ci ca di suo di un pa di un pa di un pi pi po di un pi pi pi di un po di
2025-05-29 17:40:39,956 - INFO - joeynmt.training - Example #1
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'che', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'c@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 's@@', 'u@@', 'o', 'di', 'un', 'p@@', 'a', 'c@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'c@@', 'a', 'di', 's@@', 'u@@', '.', '</s>']
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Hypothesis: E un po di un po che un po di un po di un po di un po di un po di un po di un po di un pa di un pa di un pa di un pa di co di un pa di un pa di un pa di un pa di un pa di suo di un pa co di un pa di ca di su.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - Example #2
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'a', 'di', 's@@', 'u@@', 'o', 'che', 'un', 'p@@', 'o', 'di', 's@@', 'u@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'o.', '</s>']
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - 	Hypothesis: E un pa di suo che un po di suo di un po di un po di un po di un po di un pa di un po.
2025-05-29 17:40:39,956 - INFO - joeynmt.training - Example #3
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:40:39,956 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'a', 'di', 's@@', 'u@@', 'a', 'di', 'un', 'p@@', 'a', 'di', 's@@', 'u@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 's@@', 'u@@', '.', '</s>']
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Hypothesis: E un pa di sua di un pa di suo di un pa di su.
2025-05-29 17:40:39,957 - INFO - joeynmt.training - Example #4
2025-05-29 17:40:39,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:40:39,957 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:40:39,957 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'a', 'di', 'un', 'p@@', 'o', 'di', 'un', 'p@@', 'o.', '</s>']
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:40:39,957 - INFO - joeynmt.training - 	Hypothesis: E un po di un po di un po di un po di un po di un po di un po di un pa di un po di un po.
2025-05-29 17:40:53,280 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.614436, Batch Acc: 0.073562, Tokens per Sec:     5529, Lr: 0.000300
2025-05-29 17:41:06,845 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.585676, Batch Acc: 0.076312, Tokens per Sec:     5195, Lr: 0.000300
2025-05-29 17:41:20,670 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.562559, Batch Acc: 0.078395, Tokens per Sec:     5141, Lr: 0.000300
2025-05-29 17:41:34,906 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.571166, Batch Acc: 0.081822, Tokens per Sec:     5020, Lr: 0.000300
2025-05-29 17:41:48,571 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.502599, Batch Acc: 0.085888, Tokens per Sec:     5183, Lr: 0.000300
2025-05-29 17:41:48,571 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:43:33,321 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.49, ppl:  32.94, acc:   0.08, generation: 104.7409[sec], evaluation: 0.0000[sec]
2025-05-29 17:43:33,324 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:43:33,415 - INFO - joeynmt.training - Example #0
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 's@@', 'ec@@', 'e', 'che', 'il', 'mondo', 'che', 'la', 's@@', 'in@@', 'o', 'che', 'la', 's@@', 'in@@', ',', 'e', 'che', 'il', 's@@', 'in@@', ',', 'che', 'la', 's@@', 'in@@', ',', 'e', 'la', 's@@', 'in@@', ',', 'il', 's@@', 'in@@', ',', 'e', 'che', 'la', 's@@', 'in@@', ',', 'e', 'il', 'mondo', 'che', 'un', 's@@', 'in@@', ',', 'e', 'che', 'un', 's@@', 'in@@', 'p@@', 'et@@', 'a', 'di', 'un', 's@@', 'in@@', '.', '</s>']
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Hypothesis: E il sece che il mondo che la sino che la sin, e che il sin, che la sin, e la sin, il sin, e che la sin, e il mondo che un sin, e che un sinpeta di un sin.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - Example #1
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 's@@', 'ar@@', ',', 'il', 'mondo', 'che', 'un', 's@@', 'in@@', 'o', 'di', 'un', 's@@', 'in@@', ',', 'che', 'un', 's@@', 'in@@', ',', 'che', 'un', 's@@', 'in@@', ',', 'che', 'un', 's@@', 'in@@', '.', '</s>']
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Hypothesis: E il sar, il mondo che un sino di un sin, che un sin, che un sin, che un sin.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - Example #2
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 's@@', 'in@@', ',', 'il', 's@@', 'in@@', ',', 'il', 's@@', 'in@@', ',', 'il', 's@@', 'in@@', ',', 'il', 's@@', 'in@@', ',', 'di', 'un', 's@@', 'in@@', '.', '</s>']
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - 	Hypothesis: E il sin, il sin, il sin, il sin, il sin, di un sin.
2025-05-29 17:43:33,416 - INFO - joeynmt.training - Example #3
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:43:33,416 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 's@@', 'in@@', 'o', 'e', 'e', 'e', 'e', 'il', 's@@', 'in@@', 'o', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'un', 's@@', 'in@@', '.', '</s>']
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Hypothesis: E il sino e e e e il sino e e e e e e e e e e un sin.
2025-05-29 17:43:33,417 - INFO - joeynmt.training - Example #4
2025-05-29 17:43:33,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:43:33,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:43:33,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'un', 's@@', 'in@@', '.', '</s>']
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:43:33,417 - INFO - joeynmt.training - 	Hypothesis: E che è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è un sin.
2025-05-29 17:43:46,082 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.473018, Batch Acc: 0.091081, Tokens per Sec:     5431, Lr: 0.000300
2025-05-29 17:43:59,495 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.406041, Batch Acc: 0.095310, Tokens per Sec:     5401, Lr: 0.000300
2025-05-29 17:44:12,645 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.361216, Batch Acc: 0.098188, Tokens per Sec:     5482, Lr: 0.000300
2025-05-29 17:44:26,638 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.388724, Batch Acc: 0.105389, Tokens per Sec:     5211, Lr: 0.000300
2025-05-29 17:44:40,291 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.237084, Batch Acc: 0.115797, Tokens per Sec:     5218, Lr: 0.000300
2025-05-29 17:44:40,291 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:46:30,309 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.32, ppl:  27.59, acc:   0.12, generation: 110.0032[sec], evaluation: 0.0000[sec]
2025-05-29 17:46:30,311 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:46:30,399 - INFO - joeynmt.training - Example #0
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'un', 'mondo', 'di', 'di', 'un', 'pr@@', 'em@@', 'o', 'di', 'un', 'pr@@', 'egn@@', 'are', 'che', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'si', 'di', 'di', 'di', 'un', 'mon@@', 'do.', '</s>']
2025-05-29 17:46:30,399 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:46:30,399 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:46:30,399 - INFO - joeynmt.training - 	Hypothesis: E è è è è un mondo di di un premo di un pregnare che si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si si di di di un mondo.
2025-05-29 17:46:30,399 - INFO - joeynmt.training - Example #1
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:46:30,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'è', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-29 17:46:30,399 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Hypothesis: E non è è un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-29 17:46:30,400 - INFO - joeynmt.training - Example #2
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', 'c@@', 'ur@@', 'o', 'di', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Hypothesis: E è un curo di un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-29 17:46:30,400 - INFO - joeynmt.training - Example #3
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'c@@', 'etto', 'di', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', 'C@@', '.', '</s>']
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Hypothesis: E la cetto di CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - Example #4
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:46:30,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'un', 'mondo', 'di', 'di', 'di', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:46:30,400 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è un mondo di di di un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-29 17:46:43,982 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.251821, Batch Acc: 0.124887, Tokens per Sec:     5037, Lr: 0.000300
2025-05-29 17:46:57,688 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.145368, Batch Acc: 0.137109, Tokens per Sec:     5201, Lr: 0.000300
2025-05-29 17:47:11,178 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.173324, Batch Acc: 0.147682, Tokens per Sec:     5226, Lr: 0.000300
2025-05-29 17:47:25,168 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.081227, Batch Acc: 0.154705, Tokens per Sec:     5158, Lr: 0.000300
2025-05-29 17:47:39,152 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.961582, Batch Acc: 0.163631, Tokens per Sec:     5069, Lr: 0.000300
2025-05-29 17:47:39,152 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:49:19,612 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.04, ppl:  20.95, acc:   0.16, generation: 100.4503[sec], evaluation: 0.0000[sec]
2025-05-29 17:49:19,614 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:49:19,703 - INFO - joeynmt.training - Example #0
2025-05-29 17:49:19,703 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'os@@', 'so', 'che', 'ho', 'fatto', 'che', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'vita', 'di', 'cui', 'sono', 'i', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro', 'loro']
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Hypothesis: Posso che ho fatto che la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua vita di cui sono i loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro loro
2025-05-29 17:49:19,704 - INFO - joeynmt.training - Example #1
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'mio', 'p@@', 'es@@', 'o', 'che', 'non', 'è', 'che', 'non', 'è', 'è', 'il', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'p@@', 'an@@', 'a', 'di', 'cui', 'non', 'è', 'il', 'suo', 'suo', 's@@', 'o.', '</s>']
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Hypothesis: Ma non è il mio peso che non è che non è è il suo suo suo suo suo suo suo suo suo suo pana di cui non è il suo suo so.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - Example #2
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'c@@', 'a.', '</s>']
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Hypothesis: La sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua ca.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - Example #3
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:49:19,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'os@@', 'so', 'di', 'di', 'C@@', 'on@@', 'on@@', 'on@@', 'on@@', 'i', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'la', 'sua', 'sua', 'c@@', 'at@@', 'a.', '</s>']
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:49:19,704 - INFO - joeynmt.training - 	Hypothesis: Posso di di Cononononi e e e e e e e e e e e e e e e e e e e e la sua sua cata.
2025-05-29 17:49:19,705 - INFO - joeynmt.training - Example #4
2025-05-29 17:49:19,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:49:19,705 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:49:19,705 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ot@@', 'ot@@', 'ti@@', ',', 'il', 'mio', 'p@@', 'etr@@', 'o', 'di', 'questo', 'è', 'il', 'mio', 'mio', 'mio', 'mio', 'p@@', 'etr@@', 'o', 'di', 'un', 'p@@', 'es@@', 'es@@', 'e.', '</s>']
2025-05-29 17:49:19,705 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:49:19,705 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:49:19,705 - INFO - joeynmt.training - 	Hypothesis: Il prototti, il mio petro di questo è il mio mio mio mio petro di un pesese.
2025-05-29 17:49:33,045 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     3.068272, Batch Acc: 0.167914, Tokens per Sec:     5294, Lr: 0.000300
2025-05-29 17:49:46,558 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     3.153845, Batch Acc: 0.176898, Tokens per Sec:     5220, Lr: 0.000300
2025-05-29 17:49:59,735 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.929495, Batch Acc: 0.184392, Tokens per Sec:     5371, Lr: 0.000300
2025-05-29 17:50:13,434 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.832494, Batch Acc: 0.192292, Tokens per Sec:     5330, Lr: 0.000300
2025-05-29 17:50:27,495 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.746110, Batch Acc: 0.193348, Tokens per Sec:     4946, Lr: 0.000300
2025-05-29 17:50:27,496 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:52:18,411 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.88, ppl:  17.80, acc:   0.19, generation: 110.9035[sec], evaluation: 0.0000[sec]
2025-05-29 17:52:18,414 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:52:18,503 - INFO - joeynmt.training - Example #0
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ho', 'fatto', 'che', 'la', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'm@@', 'es@@', 'es@@']
2025-05-29 17:52:18,503 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:52:18,503 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:52:18,503 - INFO - joeynmt.training - 	Hypothesis: E ho fatto che la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia meses
2025-05-29 17:52:18,503 - INFO - joeynmt.training - Example #1
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:52:18,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'una', 'cosa', 'che', 'non', 'è', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'che', 'non', 'è', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 'cosa', 'di', 'una', 's@@', 'an@@', 'a', 'di', 'una', 's@@', 'an@@', 'a', 'di', 'un', 'modo', 'di', 'di', 'non', 'si', 'può', 'essere', 'un', 'modo', 'di', 'di', 'non', 'è', 'un', 'modo', 'di', 'di', 'di', 'un', 'modo', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 'di', 's@@', 'an@@', 'a.', '</s>']
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Hypothesis: Ma non è una cosa che non è una cosa di una cosa di una cosa di una cosa di una cosa di una cosa che non è una cosa di una cosa di una cosa di una cosa di una sana di una sana di un modo di di non si può essere un modo di di non è un modo di di di un modo di di di di di di di di sana.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - Example #2
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia']
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Hypothesis: E la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia
2025-05-29 17:52:18,504 - INFO - joeynmt.training - Example #3
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'c@@', 'at@@', 'a.', '</s>']
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Hypothesis: E la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia cata.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - Example #4
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:52:18,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'mio', 'mio', 'mio', 'p@@', 'es@@', 'co', 'di', 'un', 'pa@@', 'io', 'di', 'un', 'pa@@', 'io', 'di', 'di', 'un', 'pa@@', 'io', 'di', 'di', 'un', 'pa@@', 'esi', 'di', 'di', 'un', 'pa@@', 'io', 'di', 'di', 'un', 'pa@@', 'es@@', 'e.', '</s>']
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:52:18,504 - INFO - joeynmt.training - 	Hypothesis: Il mio mio mio mio pesco di un paio di un paio di di un paio di di un paesi di di un paio di di un paese.
2025-05-29 17:52:31,878 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.844805, Batch Acc: 0.197560, Tokens per Sec:     5417, Lr: 0.000300
2025-05-29 17:52:45,821 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.735697, Batch Acc: 0.202489, Tokens per Sec:     5148, Lr: 0.000300
2025-05-29 17:52:58,187 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.746621, Batch Acc: 0.208270, Tokens per Sec:     5758, Lr: 0.000300
2025-05-29 17:53:10,570 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.628194, Batch Acc: 0.215873, Tokens per Sec:     5837, Lr: 0.000300
2025-05-29 17:53:23,551 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.774890, Batch Acc: 0.215383, Tokens per Sec:     5495, Lr: 0.000300
2025-05-29 17:53:23,552 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:54:58,472 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.77, ppl:  15.90, acc:   0.21, generation: 94.9111[sec], evaluation: 0.0000[sec]
2025-05-29 17:54:58,474 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:54:58,567 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/500.ckpt
2025-05-29 17:54:58,580 - INFO - joeynmt.training - Example #0
2025-05-29 17:54:58,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:54:58,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:54:58,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['D@@', 'ov@@', 'vi@@', 'o', 'di', 'questi', 'due', 'anni', 'che', 'ho', 'fatto', 'che', 'la', 'nostra', 'vita', 'di', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'abbiamo', 'fatto', 'che', 'la', 'nostra', 'c@@', 'aus@@', 'a', 'di', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'ho', 'fatto', 'che', 'la', 'nostra', 'st@@', 'ati', 'in', 'cui', 'ho', 'fatto', 'che', 'il', 'mo@@', 'dell@@', 'o', 'di', 'persone', 'che', 'è', 'il', 'p@@', 'es@@', 'ist@@', 'u@@', 'zione', 'di', 'cui', 'sono', 'st@@', 'ati', 'in', 'cui', 'ho', 'fatto', 'il', 'mo@@', 'dell@@', 'o', 'di', 'di', 'di', 'di', 'doll@@', 'ar@@', 'i.', '</s>']
2025-05-29 17:54:58,580 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:54:58,580 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:54:58,580 - INFO - joeynmt.training - 	Hypothesis: Dovvio di questi due anni che ho fatto che la nostra vita di cui sono stati in cui sono stati in cui abbiamo fatto che la nostra causa di cui sono stati in cui sono stati in cui sono stati in cui sono stati in cui sono stati in cui sono stati in cui sono stati in cui ho fatto che la nostra stati in cui ho fatto che il modello di persone che è il pesistuzione di cui sono stati in cui ho fatto il modello di di di di dollari.
2025-05-29 17:54:58,580 - INFO - joeynmt.training - Example #1
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'gente', 'non', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'una', 'c@@', 'aus@@', 'a', 'di', 'cui', 'non', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'cui', 'non', 'è', 'la', 'maggi@@', 'or', 'parte', 'del', 'p@@', 'al@@', 'ment@@', 'o', 'di', 'questo', 'è', 'la', 'maggi@@', 'or', 'parte', 'del', 'p@@', 'al@@', 'ment@@', 'o', 'del', 'p@@', 'es@@', 'e.', '</s>']
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Hypothesis: Ma non è la gente non è la causa di una causa di cui non è la causa di cui non è la maggior parte del palmento di questo è la maggior parte del palmento del pese.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - Example #2
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'questo', 'è', 'la', 'nostra', 'nostra', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'una', 'c@@', 'ri@@', 'vol@@', 'a', 'di', 'questo', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'questo', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'un', 'p@@', 'an@@', 'c@@', 'a.', '</s>']
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Hypothesis: In questo è la nostra nostra è la causa di una crivola di questo è la causa di questo è la causa di un panca.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - Example #3
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'c@@', 'at@@', 'a.', '</s>']
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Hypothesis: E la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua cata.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - Example #4
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:54:58,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'gente', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'è', 'un', 'pa@@', 'io', 'di', 'anni', 'che', 'è', 'che', 'è', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato']
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:54:58,581 - INFO - joeynmt.training - 	Hypothesis: La gente che ho fatto che ho fatto che ho fatto che è un paio di anni che è che è stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato stato
2025-05-29 17:55:10,757 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.753378, Batch Acc: 0.219248, Tokens per Sec:     5788, Lr: 0.000300
2025-05-29 17:55:22,853 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.680263, Batch Acc: 0.224352, Tokens per Sec:     5731, Lr: 0.000300
2025-05-29 17:55:35,167 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.689982, Batch Acc: 0.230051, Tokens per Sec:     5882, Lr: 0.000300
2025-05-29 17:55:47,538 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.763858, Batch Acc: 0.234315, Tokens per Sec:     5763, Lr: 0.000300
2025-05-29 17:56:00,309 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.795923, Batch Acc: 0.238045, Tokens per Sec:     5516, Lr: 0.000300
2025-05-29 17:56:00,310 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:57:26,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.68, ppl:  14.60, acc:   0.23, generation: 85.9237[sec], evaluation: 0.0000[sec]
2025-05-29 17:57:26,244 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:57:26,385 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/1000.ckpt
2025-05-29 17:57:26,395 - INFO - joeynmt.training - Example #0
2025-05-29 17:57:26,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:57:26,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:57:26,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', "'è", 'una', 's@@', 'ec@@', 'c@@', 'a,', 'ho', 'fatto', 'che', "l'@@", 'ar@@', 'chit@@', 'ett@@', 'ura', 'che', 'si', 'è', 'che', 'la', 'gente', 'che', 'si', 'è', 'che', 'la', 'gente', 'che', 'è', 'il', 'f@@', 'o@@', 'to', 'per', 'il', 'f@@', 'o@@', 'to', 'di', 's@@', 'ec@@', 'ol@@', 'o,', 'il', 'il', 'mon@@', 'do,', 'che', 'è', 'il', '1@@', '0@@', '%', 'di', 'anni', 'f@@', 'a,', 'che', 'si', 'è', 'il', '1@@', '00', 'milioni', 'di', 'doll@@', 'ari', 'per', 'il', 'mon@@', 'do.', '</s>']
2025-05-29 17:57:26,395 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:57:26,395 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Hypothesis: C'è una secca, ho fatto che l'architettura che si è che la gente che si è che la gente che è il foto per il foto di secolo, il il mondo, che è il 10% di anni fa, che si è il 100 milioni di dollari per il mondo.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - Example #1
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'modo', 'non', 'è', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a.', '</s>']
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Hypothesis: Ma non è il modo non è la cosa che la cosa che la cosa che non è il problema non è il problema non è il problema non è il problema.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - Example #2
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'è', 'il', 'p@@', 'es@@', 'o', 'è', 'la', 'nostra', 'è', 'la', 'nostra', 'in@@', 'f@@', 'lu@@', 'enza', 'del', 'nostro', 'mo@@', 'dell@@', 'o', 'di', 'c@@', 'arb@@', 'on@@', 'e.', '</s>']
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Hypothesis: In realtà è il peso è la nostra è la nostra influenza del nostro modello di carbone.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - Example #3
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'anno', 'il', 'mio', 'p@@', 'ad@@', 'r@@', 'ato', 'e', 'la', 'sua', 's@@', 'ort@@', 'a', 'di', 's@@', 'par@@', 'te.', '</s>']
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - 	Hypothesis: Hanno il mio padrato e la sua sorta di sparte.
2025-05-29 17:57:26,396 - INFO - joeynmt.training - Example #4
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:57:26,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'in', 'cui', 'ho', 'fatto', 'in', 'cui', 'av@@', 'evo', 'av@@', 'evo', 'fatto', 'in', 'cui', 'è', 'è', 'stato', 'stato', 'stato', 'in', 'cui', 'è', 'è', 'stato', 'stato', 'stato', 'stato', 'stato', 'in', 'cui', 'è', 'è', 'il', '1@@', '5', 'anni@@', '.', '</s>']
2025-05-29 17:57:26,397 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:57:26,397 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:57:26,397 - INFO - joeynmt.training - 	Hypothesis: La cosa che ho fatto che ho fatto che ho fatto che ho fatto in cui ho fatto in cui avevo avevo fatto in cui è è stato stato stato in cui è è stato stato stato stato stato in cui è è il 15 anni.
2025-05-29 17:57:39,220 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.685507, Batch Acc: 0.243162, Tokens per Sec:     5691, Lr: 0.000300
2025-05-29 17:57:52,122 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.590110, Batch Acc: 0.243873, Tokens per Sec:     5532, Lr: 0.000300
2025-05-29 17:58:04,956 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.508560, Batch Acc: 0.246443, Tokens per Sec:     5625, Lr: 0.000300
2025-05-29 17:58:17,660 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.464483, Batch Acc: 0.253471, Tokens per Sec:     5738, Lr: 0.000300
2025-05-29 17:58:29,727 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.523119, Batch Acc: 0.254049, Tokens per Sec:     5834, Lr: 0.000300
2025-05-29 17:58:29,727 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 17:59:40,556 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.61, ppl:  13.54, acc:   0.25, generation: 70.8186[sec], evaluation: 0.0000[sec]
2025-05-29 17:59:40,557 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 17:59:40,649 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/1500.ckpt
2025-05-29 17:59:40,662 - INFO - joeynmt.training - Example #0
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'v@@', 'evo', 'un', 'pa@@', 'io', 'di', 'di', 'questi', 'due', 'anni', 'f@@', 'a,', 'per', 'la', 'pr@@', 'inci@@', 'p@@', 'ale', 'che', 'è', 'che', 'la', 'c@@', 'at@@', 'ura', 'di', 'doll@@', 'ari', 'che', 'sono', 'due', 'milioni', 'di', 'doll@@', 'ari', 'per', 'milioni', 'di', 'anni', 'f@@', 'a,', 'che', 'il', '5@@', '%', 'di', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 17:59:40,662 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 17:59:40,662 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 17:59:40,662 - INFO - joeynmt.training - 	Hypothesis: Avevo un paio di di questi due anni fa, per la principale che è che la catura di dollari che sono due milioni di dollari per milioni di anni fa, che il 5% di anni fa.
2025-05-29 17:59:40,662 - INFO - joeynmt.training - Example #1
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 17:59:40,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'è', 'che', 'la', 'c@@', 'ura', 'di', 'cui', 'non', 'è', 'il', 'problem@@', 'a', 'di', 'cui', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a.', '</s>']
2025-05-29 17:59:40,662 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Hypothesis: Ma non è il problema non è il problema è che la cura di cui non è il problema di cui non è il problema non è il problema non è il problema non è il problema.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - Example #2
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 'è', 'il', 'f@@', 'ut@@', 'ur@@', 'o', 'è', 'la', 'c@@', 'at@@', 'ura', 'di', 'c@@', 'arb@@', 'on@@', 'ica', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'ur@@', 'b@@', 'i', 'di', 'c@@', 'ur@@', 'b@@', 'i', 'di', 'c@@', 'li@@', '.', '</s>']
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Hypothesis: In effetti è il futuro è la catura di carbonica di clione di curbi di curbi di cli.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - Example #3
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete,', 'in', 'in', 'in', 'cui', 'e', 'si', 'si', 's@@', 'per@@', 'a', 'in', 'in', 'cui', 'si', 's@@', 's@@', 'b@@', 'agli@@', 'a', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'vi@@', 'a.', '</s>']
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Hypothesis: Sapete, in in in cui e si si spera in in cui si ssbaglia in in in in in in in in in via.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - Example #4
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 17:59:40,663 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'mia', 'mia', 'f@@', 'igli@@', 'a', 'che', 'vi', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'che', 'è', 'il', '1@@', '0@@', '%', 'di', '1@@', '5', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 17:59:40,663 - INFO - joeynmt.training - 	Hypothesis: La mia mia mia figlia che vi vi mostra che vi mostra che è il 10% di 15 anni fa.
2025-05-29 17:59:53,206 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.633781, Batch Acc: 0.258379, Tokens per Sec:     5595, Lr: 0.000300
2025-05-29 18:00:06,570 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.691066, Batch Acc: 0.259920, Tokens per Sec:     5296, Lr: 0.000300
2025-05-29 18:00:18,778 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.566848, Batch Acc: 0.265197, Tokens per Sec:     6000, Lr: 0.000300
2025-05-29 18:00:31,166 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.400565, Batch Acc: 0.266079, Tokens per Sec:     5777, Lr: 0.000300
2025-05-29 18:00:43,628 - INFO - joeynmt.training - Epoch   1, Step:     4500, Batch Loss:     2.450178, Batch Acc: 0.272495, Tokens per Sec:     5611, Lr: 0.000300
2025-05-29 18:00:43,628 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:02:00,089 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.55, ppl:  12.75, acc:   0.27, generation: 76.4529[sec], evaluation: 0.0000[sec]
2025-05-29 18:02:00,090 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:02:00,177 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/2000.ckpt
2025-05-29 18:02:00,186 - INFO - joeynmt.training - Example #0
2025-05-29 18:02:00,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', "l'@@", 'anno', 'anno', 'anno', 's@@', 'per@@', 'o', 'di', 'questo', 's@@', 'an@@', 'o,', 'per', 'il', 'mio', 'p@@', 'ad@@', 'r@@', 'o,', 'per', 'il', 'm@@', 'ezzo', 'di', 'tre', 'milioni', 'di', 'anni', 'f@@', 'a,', 'per', 'tre', 'milioni', 'di', 'anni', 'f@@', 'a,', 'per', 'tre', 'milioni', 'di', 'anni', 'f@@', 'a,', 'e', 'il', '2@@', '0@@', '%', 'di', '3@@', '0', 'milioni', 'di', 'anni', 'a', '1@@', '0@@', '.', '</s>']
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Hypothesis: E l'anno anno anno spero di questo sano, per il mio padro, per il mezzo di tre milioni di anni fa, per tre milioni di anni fa, per tre milioni di anni fa, e il 20% di 30 milioni di anni a 10.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - Example #1
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'stess@@', 'a', 's@@', 'an@@', 'it@@', 'à,', 'non', 'è', 'la', 'stess@@', 'a', 'è', 'la', 'stess@@', 'a', 'cosa', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'la', 'stess@@', 'a', 's@@', 'an@@', 'da@@', '.', '</s>']
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Hypothesis: Ma non è la stessa sanità, non è la stessa è la stessa cosa non è il problema non è il problema non è la stessa sanda.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - Example #2
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'il', 's@@', 'ac@@', 'cor@@', 'so', 'è', 'la', 'stess@@', 'a', 's@@', 'an@@', 'al@@', 'ità', 'è', 'la', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'c@@', 'li@@', 'a.', '</s>']
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Hypothesis: In realtà il saccorso è la stessa sanalità è la nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra clia.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - Example #3
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:02:00,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'in', 'realt@@', 'à', 'in', 'gi@@', 'ro', 'e', 'la', 'sua', 's@@', 'per@@', 'anza', 'di', 's@@', 'b@@', 'agli@@', 'a.', '</s>']
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:02:00,187 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:02:00,188 - INFO - joeynmt.training - 	Hypothesis: Si chiama in realtà in giro e la sua speranza di sbaglia.
2025-05-29 18:02:00,188 - INFO - joeynmt.training - Example #4
2025-05-29 18:02:00,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:02:00,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:02:00,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'una', 'cosa', 'che', 'è', 'è', 'la', 'prima', 'volta', 'che', 'è', 'è', 'succ@@', 'esso', 'in', '1@@', '5', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 18:02:00,188 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:02:00,188 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:02:00,188 - INFO - joeynmt.training - 	Hypothesis: La prima prima volta che vi mostra che vi mostra una cosa che è è la prima volta che è è successo in 15 anni fa.
2025-05-29 18:02:12,431 - INFO - joeynmt.training - Epoch   1, Step:     4600, Batch Loss:     2.573536, Batch Acc: 0.271580, Tokens per Sec:     5837, Lr: 0.000300
2025-05-29 18:02:24,343 - INFO - joeynmt.training - Epoch   1, Step:     4700, Batch Loss:     2.513606, Batch Acc: 0.274771, Tokens per Sec:     5980, Lr: 0.000300
2025-05-29 18:02:25,201 - INFO - joeynmt.training - Epoch   1: total training loss 14360.17
2025-05-29 18:02:25,201 - INFO - joeynmt.training - EPOCH 2
2025-05-29 18:02:36,781 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.500665, Batch Acc: 0.287302, Tokens per Sec:     5813, Lr: 0.000300
2025-05-29 18:02:49,089 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.441442, Batch Acc: 0.284016, Tokens per Sec:     5735, Lr: 0.000300
2025-05-29 18:03:02,097 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.420719, Batch Acc: 0.291722, Tokens per Sec:     5398, Lr: 0.000300
2025-05-29 18:03:02,098 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:04:29,655 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.50, ppl:  12.14, acc:   0.28, generation: 87.5494[sec], evaluation: 0.0000[sec]
2025-05-29 18:04:29,657 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:04:29,741 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/2500.ckpt
2025-05-29 18:04:29,743 - INFO - joeynmt.training - Example #0
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'ens@@', 'avo', 'che', 'ho', 'fatto', 'questa', 'm@@', 'es@@', 'a', 'che', 'abbiamo', 'fatto', 'per', 'fare', 'il', 'modo', 'di', 'fare', 'la', 'stess@@', 'a', 'c@@', 'aus@@', 'a', 'di', 'cui', 'i', 'bambin@@', 'i', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'f@@', 'a,', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'anni', 'per', 'i', '4@@', '0', 'milioni', 'di', 'anni', "'@@", '9@@', '0', 'milioni', 'di', 'anni', "'@@", '9@@', '0', 'anni@@', ',', 'per', '4@@', '0', 'anni@@', ',', 'per', '4@@', '0', 'anni@@', ',', 'per', '4@@', '0', 'anni@@', '.', '</s>']
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Hypothesis: Pensavo che ho fatto questa mesa che abbiamo fatto per fare il modo di fare la stessa causa di cui i bambini per i tre milioni di anni fa, per tre milioni di anni per tre anni per i 40 milioni di anni '90 milioni di anni '90 anni, per 40 anni, per 40 anni, per 40 anni.
2025-05-29 18:04:29,743 - INFO - joeynmt.training - Example #1
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:04:29,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'il', 'nostro', 'sistema', 'di', 'in@@', 'forma@@', 'zione', 'che', 'ha', 'il', 'problem@@', 'a', 'di', 'questo', 'tipo', 'di', 'problem@@', 'a', 'che', 'il', 'problem@@', 'a', 'non', 'è', 'che', 'il', 'problem@@', 'a', 'non', 'è', 'che', 'la', 'cosa', 'non', 'è', 'che', 'il', 'problem@@', 'a', 'non', 'è', 'che', 'il', 'problem@@', 'a.', '</s>']
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:04:29,743 - INFO - joeynmt.training - 	Hypothesis: Ma non è che il nostro sistema di informazione che ha il problema di questo tipo di problema che il problema non è che il problema non è che la cosa non è che il problema non è che il problema.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - Example #2
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'il', 'nostro', 'sistema', 'di', 'in@@', 'forma@@', 'zione', 'è', 'la', 'c@@', 'ult@@', 'ura', 'di', 'E@@', 's@@', 's@@', 's@@', 's@@', 'ente', 'del', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Hypothesis: In realtà il nostro sistema di informazione è la cultura di Essssente del nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro sistema di climatico.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - Example #3
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'in', 'in', 'realt@@', 'à', 'nel', 'cor@@', 'so', 'e', 'la', 'sc@@', 'u@@', 'ola', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ett@@', 'o.', '</s>']
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Hypothesis: E' in in realtà nel corso e la scuola in un sacco di setto.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - Example #4
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:04:29,744 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'prima', 'prima', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'che', 'è', 'succ@@', 'esso', 'in', 'questo', 'mom@@', 'ento', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', 'questo', 'ulti@@', 'mo', '1@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:04:29,744 - INFO - joeynmt.training - 	Hypothesis: La prima prima prima che vi mostra che vi mostra che vi mostra che vi mostra che è successo in questo momento che è successo in cui è successo in questo ultimo 15 anni.
2025-05-29 18:04:42,288 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.458468, Batch Acc: 0.290924, Tokens per Sec:     5620, Lr: 0.000300
2025-05-29 18:04:54,641 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     2.365680, Batch Acc: 0.290999, Tokens per Sec:     5793, Lr: 0.000300
2025-05-29 18:05:07,440 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     2.105943, Batch Acc: 0.295992, Tokens per Sec:     5656, Lr: 0.000300
2025-05-29 18:05:20,531 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     2.408681, Batch Acc: 0.293978, Tokens per Sec:     5410, Lr: 0.000300
2025-05-29 18:05:33,249 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.444068, Batch Acc: 0.299028, Tokens per Sec:     5528, Lr: 0.000300
2025-05-29 18:05:33,250 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:07:06,028 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.46, ppl:  11.65, acc:   0.29, generation: 92.7708[sec], evaluation: 0.0000[sec]
2025-05-29 18:07:06,029 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:07:06,113 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/3000.ckpt
2025-05-29 18:07:06,114 - INFO - joeynmt.training - Example #0
2025-05-29 18:07:06,114 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:07:06,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:07:06,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', 'o', 'ann@@', 'o,', 'ho', 'lavor@@', 'ato', 'a', 'questi', 'due', 'anni', 'f@@', 'a,', 'per', 'mostr@@', 'ar@@', 'vi', 'che', 'la', 'stess@@', 'a', 'c@@', 'at@@', 'tiv@@', 'ità', 'di', 'cui', 'la', 'sc@@', 'ar@@', 'chit@@', 'ett@@', 'ura', 'per', 'il', '2@@', '5@@', '0@@', '%', 'di', 'anni', "'@@", '6@@', '0', 'milioni', 'di', 'anni', "'@@", '9@@', '0@@', ',', 'il', '4@@', '0@@', '%', 'del', '2@@', '5@@', '0@@', '%', 'del', '2@@', '5@@', '0@@', '%', 'del', '2@@', '5@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '2@@', '5@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '2@@', '5@@', '0@@', '.', '</s>']
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Hypothesis: Il primo anno, ho lavorato a questi due anni fa, per mostrarvi che la stessa cattività di cui la scarchitettura per il 250% di anni '60 milioni di anni '90, il 40% del 250% del 250% del 250% del 40% del 40% del 250% del 40% del 250.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - Example #1
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'modo', 'non', 'è', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a.', '</s>']
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Hypothesis: Ma non è il modo non è la cosa che la cosa che non è il problema che non è il problema che non è il problema non è il problema.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - Example #2
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'egn@@', 'o', 'è', 'la', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Hypothesis: In un sacco di segno è la clione di clione di clione di clione di clione di clione di clione di clione di climatico.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - Example #3
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:07:06,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['P@@', 'oi', 'si', 's@@', 'per@@', 'd@@', 'ono', 'e', 'la', 'par@@', 'ola', 'di', 's@@', 'an@@', 'it@@', 'à,', 'e', 'la', 'sc@@', 'u@@', 'ola', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - 	Hypothesis: Poi si sperdono e la parola di sanità, e la scuola in un sacco di sotto.
2025-05-29 18:07:06,115 - INFO - joeynmt.training - Example #4
2025-05-29 18:07:06,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:07:06,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:07:06,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'prima', 'prima', 'di', 'cui', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'prima', 'volta', 'che', 'è', 'una', 'cosa', 'che', 'è', 'stato', 'il', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:07:06,116 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:07:06,116 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:07:06,116 - INFO - joeynmt.training - 	Hypothesis: La prima prima prima di cui vi mostrerò la prima volta che è una cosa che è stato il 25 anni.
2025-05-29 18:07:18,253 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     2.374672, Batch Acc: 0.300031, Tokens per Sec:     5978, Lr: 0.000300
2025-05-29 18:07:30,339 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.330949, Batch Acc: 0.300938, Tokens per Sec:     5877, Lr: 0.000300
2025-05-29 18:07:42,684 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.326145, Batch Acc: 0.307022, Tokens per Sec:     5912, Lr: 0.000300
2025-05-29 18:07:55,433 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.489417, Batch Acc: 0.306385, Tokens per Sec:     5452, Lr: 0.000300
2025-05-29 18:08:08,432 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     2.325865, Batch Acc: 0.309350, Tokens per Sec:     5570, Lr: 0.000300
2025-05-29 18:08:08,432 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:09:18,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.41, ppl:  11.09, acc:   0.31, generation: 69.5598[sec], evaluation: 0.0000[sec]
2025-05-29 18:09:18,002 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:09:18,092 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/3500.ckpt
2025-05-29 18:09:18,095 - INFO - joeynmt.training - Example #0
2025-05-29 18:09:18,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:09:18,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:09:18,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'ho', 'fatto', 'questa', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'lavor@@', 'are', 'a', 'per', 'cui', 'è', 'che', 'la', 'stess@@', 'a', 'in@@', 'f@@', 'lu@@', 'enza', 'che', 'la', 'stess@@', 'a', 'c@@', 'arb@@', 'on@@', 'io', 'per', 'tre', 'milioni', 'di', 'persone', 'che', 'hanno', 'tre', 'milioni', 'di', 'anni', 'che', 'i', 'pa@@', 'es@@', 'e,', 'per', 'il', '4@@', '0', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0', 'anni@@', ',', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'cent@@', 'e.', '</s>']
2025-05-29 18:09:18,095 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:09:18,095 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:09:18,095 - INFO - joeynmt.training - 	Hypothesis: Lo ho fatto questa influenza di lavorare a per cui è che la stessa influenza che la stessa carbonio per tre milioni di persone che hanno tre milioni di anni che i paese, per il 40 milioni di anni per il 40% del 40 anni, per il 40% del 40 per per il 40 percento di 40 percente.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - Example #1
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'cosa', 'non', 'è', 'stato', 'il', 'suo', 'di@@', 'scor@@', 'so', 'di', 'questo', 'problem@@', 'a', 'che', 'questo', 'è', 'la', 'di@@', 'st@@', 'ori@@', 'a,', 'non', 'è', 'che', 'non', 'è', 'il', 'problem@@', 'a.', '</s>']
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Hypothesis: Ma non è la cosa non è stato il suo discorso di questo problema che questo è la distoria, non è che non è il problema.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - Example #2
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'in', 'realt@@', 'à', 'è', 'la', 's@@', 'ens@@', 'azione', 'di', 'E@@', 'p@@', 'p@@', 'p@@', 'p@@', 'sic@@', 'olog@@', 'ica', 'che', 'il', 'nostro', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Hypothesis: In realtà in realtà è la sensazione di Eppppsicologica che il nostro nostro climatico di climatico.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - Example #3
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'stesso', 'in', 'in', 'cui', 'si', 'trov@@', 'a', 'in', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ens@@', 'o.', '</s>']
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - 	Hypothesis: Lo stesso in in cui si trova in in un sacco di senso.
2025-05-29 18:09:18,096 - INFO - joeynmt.training - Example #4
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:09:18,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 18:09:18,097 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:09:18,097 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:09:18,097 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostrerò che vi mostrerò che è successo in 25 anni fa.
2025-05-29 18:09:30,362 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     2.539445, Batch Acc: 0.308791, Tokens per Sec:     5838, Lr: 0.000300
2025-05-29 18:09:42,995 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.378393, Batch Acc: 0.313518, Tokens per Sec:     5557, Lr: 0.000300
2025-05-29 18:09:55,587 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     2.374815, Batch Acc: 0.317298, Tokens per Sec:     5886, Lr: 0.000300
2025-05-29 18:10:08,340 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     2.491957, Batch Acc: 0.317104, Tokens per Sec:     5541, Lr: 0.000300
2025-05-29 18:10:21,231 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.404613, Batch Acc: 0.321290, Tokens per Sec:     5555, Lr: 0.000300
2025-05-29 18:10:21,232 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:11:31,946 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.37, ppl:  10.65, acc:   0.32, generation: 70.7056[sec], evaluation: 0.0000[sec]
2025-05-29 18:11:31,948 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:11:32,047 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/4000.ckpt
2025-05-29 18:11:32,049 - INFO - joeynmt.training - Example #0
2025-05-29 18:11:32,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:11:32,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'ann@@', 'o,', 'ho', 'fatto', 'questi', 'due', 'due', 'vol@@', 'te', 'di', 'm@@', 'em@@', 'o@@', 'zion@@', 'i,', 'per', 'la', 'ri@@', 'vol@@', 't@@', 'a,', 'che', 'la', 'f@@', 'ut@@', 'ur@@', 'a', 'che', 'la', 'f@@', 'ut@@', 'ur@@', 'a', 'di', 'tre', 'anni@@', ',', 'per', 'tre', 'anni@@', ',', 'per', 'tre', 'anni@@', ',', 'per', 'la', 'di@@', 're@@', 'zione', 'di', '4@@', '0', 'anni@@', '.', '</s>']
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Hypothesis: Lo anno, ho fatto questi due due volte di memozioni, per la rivolta, che la futura che la futura di tre anni, per tre anni, per tre anni, per la direzione di 40 anni.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - Example #1
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'la', 'pr@@', 'inci@@', 'p@@', 'ale', 'che', 'non', 'è', 'stato', 'il', 'ris@@', 'p@@', 'etto', 'di', 'questo', 'problem@@', 'a', 'di', 'problem@@', 'a', 'di', 'problem@@', 'a', 'del', 'problem@@', 'a.', '</s>']
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è la principale che non è stato il rispetto di questo problema di problema di problema del problema.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - Example #2
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'è', 'la', 's@@', 'ens@@', 'azione', 'è', 'la', 's@@', 'an@@', 'it@@', 'à,', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - 	Hypothesis: In realtà è la sensazione è la sanità, la climatica è il nostro climatico di climatico.
2025-05-29 18:11:32,050 - INFO - joeynmt.training - Example #3
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:11:32,050 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete,', 'in', 'realt@@', 'à', 'in', 'gi@@', 'ro', 'in', 'un', 'f@@', 'um@@', 'ore', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ett@@', 'o.', '</s>']
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Hypothesis: Sapete, in realtà in giro in un fumore in un sacco di setto.
2025-05-29 18:11:32,051 - INFO - joeynmt.training - Example #4
2025-05-29 18:11:32,051 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:11:32,051 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:11:32,051 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'a', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:11:32,051 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostrerò che vi mostrerò che vi mostra che è successo in 25 anni fa.
2025-05-29 18:11:44,467 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     2.300694, Batch Acc: 0.325830, Tokens per Sec:     5628, Lr: 0.000300
2025-05-29 18:11:57,852 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.387614, Batch Acc: 0.324924, Tokens per Sec:     5496, Lr: 0.000300
2025-05-29 18:12:10,701 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     2.161040, Batch Acc: 0.326532, Tokens per Sec:     5382, Lr: 0.000300
2025-05-29 18:12:22,805 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     2.301057, Batch Acc: 0.328564, Tokens per Sec:     5820, Lr: 0.000300
2025-05-29 18:12:34,774 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     2.267587, Batch Acc: 0.326923, Tokens per Sec:     5927, Lr: 0.000300
2025-05-29 18:12:34,774 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:13:54,471 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.34, ppl:  10.34, acc:   0.33, generation: 79.6894[sec], evaluation: 0.0000[sec]
2025-05-29 18:13:54,473 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:13:54,561 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/4500.ckpt
2025-05-29 18:13:54,563 - INFO - joeynmt.training - Example #0
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'vol@@', 'te', 'per', 'mostr@@', 'are', 'che', 'la', 'stess@@', 'a', 'che', 'la', 'stess@@', 'a', 'di', 'essere', 'i', 'p@@', 'es@@', 'c@@', 'at@@', 'ic@@', 'amente', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'f@@', 'a,', 'per', 'i', 'tre', 'anni@@', ',', 'per', 'i', '4@@', '0', 'milioni', 'di', 'anni', 'f@@', 'a,', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'cent@@', 'u@@', 'ale', 'per', '4@@', '0', 'per@@', 'cent@@', 'u@@', 'ale', 'per', 'il', '4@@', '0', 'per@@', 'cent@@', 'u@@', 'ale', 'per', '4@@', '0', 'per@@', 'cent@@', 'e.', '</s>']
2025-05-29 18:13:54,563 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:13:54,563 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:13:54,563 - INFO - joeynmt.training - 	Hypothesis: Lo scorso che ho mostrato questi due due volte per mostrare che la stessa che la stessa di essere i pescaticamente per i tre milioni di anni fa, per i tre anni, per i 40 milioni di anni fa, per il 40 percento di 40 percentuale per 40 percentuale per il 40 percentuale per 40 percente.
2025-05-29 18:13:54,563 - INFO - joeynmt.training - Example #1
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:13:54,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'il', 'f@@', 'ant@@', 'ast@@', 'ico', 'che', 'è', 'il', 'modo', 'di', 'questo', 'tipo', 'di', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'del', 'D@@', 'is@@', 'is@@', '.', '</s>']
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il fantastico che è il modo di questo tipo di problema di questo problema che non è il problema che non è il problema del Disis.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - Example #2
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti', 'è', 'la', 's@@', 'ort@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'a@@', 'y@@', 'p@@', 'is@@', 'ce', 'il', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'one', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Hypothesis: In effetti è la sorta di Eiskaypisce il nostro sistema di clione di clione di clione di climatico.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - Example #3
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete', 'in', 'un', 's@@', 'ac@@', 'co', 'di', 't@@', 'um@@', 'or@@', 'e.', '</s>']
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Hypothesis: Sapete in un sacco di tumore.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - Example #4
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:13:54,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:13:54,564 - INFO - joeynmt.training - 	Hypothesis: La prossima che vi mostrerò che vi mostrerò che è successo in cui è successo in 25 anni fa.
2025-05-29 18:14:05,957 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     2.324421, Batch Acc: 0.332153, Tokens per Sec:     6220, Lr: 0.000300
2025-05-29 18:14:18,375 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     2.341875, Batch Acc: 0.331494, Tokens per Sec:     5779, Lr: 0.000300
2025-05-29 18:14:30,911 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     2.361486, Batch Acc: 0.337078, Tokens per Sec:     5617, Lr: 0.000300
2025-05-29 18:14:44,411 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     2.205212, Batch Acc: 0.336164, Tokens per Sec:     5401, Lr: 0.000300
2025-05-29 18:14:56,829 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     2.317028, Batch Acc: 0.341293, Tokens per Sec:     5845, Lr: 0.000300
2025-05-29 18:14:56,829 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:16:01,140 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.30, ppl:   9.99, acc:   0.33, generation: 64.3039[sec], evaluation: 0.0000[sec]
2025-05-29 18:16:01,141 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:16:01,224 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/5000.ckpt
2025-05-29 18:16:01,226 - INFO - joeynmt.training - Example #0
2025-05-29 18:16:01,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:16:01,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:16:01,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questo', 'ho', 'mostr@@', 'ato', 'che', 'i', 'su@@', 'oi', 'lavor@@', 'are', 'per', 'i', 'su@@', 'oi', 'su@@', 'i', 'su@@', 'oi', 'li@@', 'p@@', 'ici', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'tre', 'anni', 'f@@', 'a,', 'per', 'i', 'tre', 'anni', "'@@", 'in@@', 'f@@', 'lu@@', 'enza', 'per', 'il', '4@@', '0@@', '%', 'dei', 'su@@', 'oi', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'post@@', 'i', 'per', 'i', 'per', 'i', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'in@@', 'f@@', 'lu@@', 'enz@@', 'i.', '</s>']
2025-05-29 18:16:01,226 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:16:01,226 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:16:01,226 - INFO - joeynmt.training - 	Hypothesis: Lo scorso ho mostrato questo ho mostrato che i suoi lavorare per i suoi sui suoi lipici di influenza di influenza di tre anni fa, per i tre anni 'influenza per il 40% dei suoi 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di sposti per i per i 40 percento di influenzi.
2025-05-29 18:16:01,226 - INFO - joeynmt.training - Example #1
2025-05-29 18:16:01,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:16:01,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'pr@@', 'at@@', 'ica', 'non', 'è', 'stato', 'il', 'di@@', 'scor@@', 'so', 'di', 'questo', 'tipo', 'di', 'es@@', 'peri@@', 'enza', 'di', 'questi', 'problem@@', 'i', 'di', 'problem@@', 'i', 'non', 'è', 'il', 'd@@', 'entro', 'il', 'D@@', 'is@@', 'is@@', 'ce', 'che', 'non', 'mostr@@', 'a', 'il', 'D@@', 'is@@', 'co@@', '.', '</s>']
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Hypothesis: Ma non è la pratica non è stato il discorso di questo tipo di esperienza di questi problemi di problemi non è il dentro il Disisce che non mostra il Disco.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - Example #2
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'S@@', 'in@@', 'e@@', 'ar@@', 'io', 'è', 'la', 's@@', 'ort@@', 'a', 'di', 'E@@', 'h@@', 'is@@', ',', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Hypothesis: Nel Sineario è la sorta di Ehis, il nostro climatico di climatico.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - Example #3
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'stesso', 'punto', 'in', 'cui', 'è', 'stato', 'in', 'e', 'la', 'sc@@', 'u@@', 'ola', 'e', 'in', 'un', 's@@', 'ac@@', 'r@@', 'o.', '</s>']
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Hypothesis: Lo stesso punto in cui è stato in e la scuola e in un sacro.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - Example #4
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:16:01,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prima', 'volta', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'una', 'sc@@', 'u@@', 'ola', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'fa', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:16:01,227 - INFO - joeynmt.training - 	Hypothesis: La prima volta che vi mostro che vi mostrerò una una scuola che è successo in 25 anni fa è successo.
2025-05-29 18:16:13,530 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.288928, Batch Acc: 0.339068, Tokens per Sec:     5677, Lr: 0.000300
2025-05-29 18:16:25,825 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     2.374241, Batch Acc: 0.340442, Tokens per Sec:     5851, Lr: 0.000300
2025-05-29 18:16:38,402 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     2.192166, Batch Acc: 0.340529, Tokens per Sec:     5764, Lr: 0.000300
2025-05-29 18:16:50,739 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     2.291893, Batch Acc: 0.343485, Tokens per Sec:     5571, Lr: 0.000300
2025-05-29 18:17:02,794 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     2.572910, Batch Acc: 0.347194, Tokens per Sec:     5801, Lr: 0.000300
2025-05-29 18:17:02,795 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:18:07,599 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.28, ppl:   9.75, acc:   0.34, generation: 64.7967[sec], evaluation: 0.0000[sec]
2025-05-29 18:18:07,600 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:18:07,687 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/5500.ckpt
2025-05-29 18:18:07,691 - INFO - joeynmt.training - Example #0
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questa', 'fot@@', 'ogra@@', 'f@@', 'ia', 'per', 'fare', 'la', 'stess@@', 'a', 'che', 'i', 'con@@', 'di@@', 'vi@@', 'si@@', ',', 'che', 'i', 'con@@', 'di@@', 'vi@@', 'si@@', ',', 'che', 'i', 'pa@@', 'esi', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'per', 'i', '4@@', '0', 'per', 'per', 'i', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per', 'per', 'per', 'il', '4@@', '0', 'per', 'per', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'per', 'per', 'la', 'fin@@', 'ire', 'il', '4@@', '0', 'per', 'per', 'i', '4@@', '0', 'per', 'per', 'i', 'pa@@', 'es@@', 'i.', '</s>']
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Hypothesis: Lo scorso che ho mostrato questa fotografia per fare la stessa che i condivisi, che i condivisi, che i paesi per i tre milioni di anni per i 40 per per i 40 per per i 40 per per il 40 per per il 40 per per il 40 percento di 40 per per il 40 per per per il 40 per per per per il 40 percento di 40 per per per la finire il 40 per per i 40 per per i paesi.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - Example #1
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:18:07,691 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'la', 'l@@', 'am@@', 'p@@', 'a', 'è', 'stato', 'd@@', 'ato', 'la', 'T@@', 'er@@', 'ra', 'è', 'la', 'cosa', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'che', 'non', 'è', 'la', 'di@@', 'men@@', 'sione', 'del', 'problem@@', 'a.', '</s>']
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è la lampa è stato dato la Terra è la cosa che non è il problema che non è la dimensione del problema.
2025-05-29 18:18:07,691 - INFO - joeynmt.training - Example #2
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 's@@', 'ac@@', 'co', 'di', 's@@', 'ott@@', 'o@@', 'co@@', ',', 'la', 's@@', 'an@@', 'it@@', 'à,', 'la', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Hypothesis: In un sacco di sottoco, la sanità, la nostra climatica.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - Example #3
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete', 'in', 'vi@@', 'a', 'in', 'vi@@', 'a', 'e', 'la', 'par@@', 'ola', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o.', '</s>']
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Hypothesis: Sapete in via in via e la parola in un certo senso.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - Example #4
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:18:07,692 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prim@@', 'o', 'è', 'una', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cosa', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:18:07,692 - INFO - joeynmt.training - 	Hypothesis: Il primo è una cosa che vi mostrerò una cosa cosa che è successo in 25 anni.
2025-05-29 18:18:19,904 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     2.282151, Batch Acc: 0.347155, Tokens per Sec:     5807, Lr: 0.000300
2025-05-29 18:18:31,964 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     2.214498, Batch Acc: 0.350775, Tokens per Sec:     5924, Lr: 0.000300
2025-05-29 18:18:43,859 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     2.297959, Batch Acc: 0.351110, Tokens per Sec:     6063, Lr: 0.000300
2025-05-29 18:18:55,680 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     2.198246, Batch Acc: 0.348694, Tokens per Sec:     5895, Lr: 0.000300
2025-05-29 18:19:07,873 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     2.281028, Batch Acc: 0.351469, Tokens per Sec:     5903, Lr: 0.000300
2025-05-29 18:19:07,873 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:20:13,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.25, ppl:   9.47, acc:   0.35, generation: 65.3867[sec], evaluation: 0.0000[sec]
2025-05-29 18:20:13,269 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:20:13,371 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/6000.ckpt
2025-05-29 18:20:13,374 - INFO - joeynmt.training - Example #0
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questo', 'due', 'f@@', 'is@@', 'ic@@', 'amente', 'il', 'f@@', 'oc@@', 'ale', 'per', 'la', 'stess@@', 'a', 's@@', 'fi@@', 'd@@', 'are', 'che', 'i', 'f@@', 'is@@', 'ic@@', 'i,', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'milioni', 'di', 'anni', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'fi@@', 'd@@', 'ati', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'anni', 'per', 'per', 'tre', 'anni@@', '.', '</s>']
2025-05-29 18:20:13,374 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:20:13,374 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:20:13,374 - INFO - joeynmt.training - 	Hypothesis: Lo scorso che ho mostrato questo due fisicamente il focale per la stessa sfidare che i fisici, per tre milioni di anni che i tre milioni di anni per i 40 per milioni di anni per 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di sfidati per 40 percento di anni per per tre anni.
2025-05-29 18:20:13,374 - INFO - joeynmt.training - Example #1
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:20:13,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'un', "po'", 'di', 's@@', 'ac@@', 'co', 'di', 'questa', 's@@', 'ort@@', 'a', 'di', 'questa', 's@@', 'ort@@', 'ort@@', 'a', 'di', 'problem@@', 'i', 'che', 'non', 'non', 'è', 'la', 'di@@', 'st@@', 'am@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'am@@', 'p@@', 'a', "dell'@@", 'E@@', 'is@@', 'ce', "l'@@", 'E@@', 'is@@', 'ce', 'la', 'di@@', 'st@@', 'ori@@', 'a.', '</s>']
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato un po' di sacco di questa sorta di questa sortorta di problemi che non non è la distama non è la distampa dell'Eisce l'Eisce la distoria.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - Example #2
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'è', 'la', 's@@', 'ort@@', 'a', 'di', 'es@@', 'pl@@', 'or@@', 'azione', 'glob@@', 'ale', 'è', 'la', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'della', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Hypothesis: In effetti, è la sorta di esplorazione globale è la nostra climatica globale della nostra climatica.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - Example #3
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete,', 'in', 'cui', 'si', 'trov@@', 'ano', 'il', 'p@@', 'es@@', 'c@@', 'at@@', 'ore', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o.', '</s>']
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Hypothesis: Sapete, in cui si trovano il pescatore in un certo senso.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - Example #4
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:20:13,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'cosa', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'una', 'c@@', 'aus@@', 'a', 'di', 'cui', 'vi', 'mostr@@', 'o', 'che', 'cosa', 'succ@@', 'essi@@', 'v@@', 'a.', '</s>']
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:20:13,375 - INFO - joeynmt.training - 	Hypothesis: La prossima cosa vi mostro che vi mostro una causa di cui vi mostro che cosa successiva.
2025-05-29 18:20:24,895 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     2.233834, Batch Acc: 0.354331, Tokens per Sec:     6034, Lr: 0.000300
2025-05-29 18:20:37,265 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     2.314291, Batch Acc: 0.359851, Tokens per Sec:     5924, Lr: 0.000300
2025-05-29 18:20:49,352 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     2.230879, Batch Acc: 0.360084, Tokens per Sec:     5878, Lr: 0.000300
2025-05-29 18:21:01,997 - INFO - joeynmt.training - Epoch   2, Step:     8900, Batch Loss:     2.301655, Batch Acc: 0.356471, Tokens per Sec:     5535, Lr: 0.000300
2025-05-29 18:21:14,583 - INFO - joeynmt.training - Epoch   2, Step:     9000, Batch Loss:     2.169459, Batch Acc: 0.361480, Tokens per Sec:     5651, Lr: 0.000300
2025-05-29 18:21:14,584 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:22:40,849 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.22, ppl:   9.23, acc:   0.36, generation: 86.2566[sec], evaluation: 0.0000[sec]
2025-05-29 18:22:40,851 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:22:40,943 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/6500.ckpt
2025-05-29 18:22:40,946 - INFO - joeynmt.training - Example #0
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'v@@', 'evo', 'questi', 'due', 'due', 'due', 'par@@', 'ti', 'di', 'questi', 'due', 'par@@', 'ti', 'di', 'fare', 'il', 'con@@', 'di@@', 'zion@@', 'e,', 'che', 'la', 'com@@', 'pas@@', 'sione', 'che', 'i', 'v@@', 'ec@@', 'chi@@', 'o', 'di', 'cui', 'i', 'pr@@', 'inci@@', 'p@@', 'ali', 'per', 'i', 'mi@@', 'ei', 'anni', 'di', 'anni', 'di', '4@@', '0', 'per', 'anni', 'per', 'i', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'questi', 'due', 'anni', 'f@@', 'a.', '</s>']
2025-05-29 18:22:40,946 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:22:40,946 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:22:40,946 - INFO - joeynmt.training - 	Hypothesis: Avevo questi due due due parti di questi due parti di fare il condizione, che la compassione che i vecchio di cui i principali per i miei anni di anni di 40 per anni per i 40 percento di 40 percento di 40 percento di 40 percento di cento di cento di 40 percento di cento di questi due anni fa.
2025-05-29 18:22:40,946 - INFO - joeynmt.training - Example #1
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:22:40,946 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'la', 'for@@', 'za', 'di', 'ri@@', 'vol@@', 'te', 'la', 'ter@@', 'ra', 'la', 'ter@@', 'ra', 'la', 'cosa', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'D@@', 'el@@', '.', '</s>']
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è la forza di rivolte la terra la terra la cosa di questo problema di questo problema di questo problema che non è che non è la distanza del Del.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - Example #2
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'realt@@', 'à', 'è', 'la', 's@@', 'ens@@', 'azione', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'della', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'glob@@', 'ale.', '</s>']
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Hypothesis: In realtà è la sensazione è la climatica è la climatica globale della climatica globale globale.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - Example #3
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'W@@', 'in@@', 'st@@', 'all@@', 'o', 'e', 'la', 'par@@', 'ol@@', 'a,', 'e', 'la', 'l@@', 'um@@', 'in@@', 'a.', '</s>']
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Hypothesis: Si chiama Winstallo e la parola, e la lumina.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - Example #4
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:22:40,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'o', 'una', 'c@@', 'aus@@', 'a', 'di', 'cui', 'vi', 'mostr@@', 'er@@', 'ò', 'in', 'ulti@@', 'mo', 'in@@', 'contr@@', 'o', 'la', 'cosa', 'cosa', 'succ@@', 'ede', 'in', 'ulti@@', 'mo', '2@@', '5', 'anni', 'fa', 'succ@@', 'e@@', 'de.', '</s>']
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:22:40,947 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostro una causa di cui vi mostrerò in ultimo incontro la cosa cosa succede in ultimo 25 anni fa succede.
2025-05-29 18:22:53,805 - INFO - joeynmt.training - Epoch   2, Step:     9100, Batch Loss:     2.094147, Batch Acc: 0.365632, Tokens per Sec:     5618, Lr: 0.000300
2025-05-29 18:23:06,960 - INFO - joeynmt.training - Epoch   2, Step:     9200, Batch Loss:     2.393708, Batch Acc: 0.364447, Tokens per Sec:     5354, Lr: 0.000300
2025-05-29 18:23:19,708 - INFO - joeynmt.training - Epoch   2, Step:     9300, Batch Loss:     2.285392, Batch Acc: 0.366484, Tokens per Sec:     5604, Lr: 0.000300
2025-05-29 18:23:32,832 - INFO - joeynmt.training - Epoch   2, Step:     9400, Batch Loss:     2.162184, Batch Acc: 0.363445, Tokens per Sec:     5494, Lr: 0.000300
2025-05-29 18:23:34,009 - INFO - joeynmt.training - Epoch   2: total training loss 10917.35
2025-05-29 18:23:34,009 - INFO - joeynmt.training - EPOCH 3
2025-05-29 18:23:45,245 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     2.255631, Batch Acc: 0.377398, Tokens per Sec:     5559, Lr: 0.000300
2025-05-29 18:23:45,245 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:25:02,867 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.19, ppl:   8.97, acc:   0.37, generation: 77.6142[sec], evaluation: 0.0000[sec]
2025-05-29 18:25:02,869 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:25:02,962 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/7000.ckpt
2025-05-29 18:25:02,963 - INFO - joeynmt.training - Example #0
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', "l'@@", 'anno', 'scor@@', 'so', 'che', "l'@@", 'anno', 'scor@@', 'so', 'di', 'fare', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'con@@', 'si@@', 'der@@', 'are', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '3@@', '0', 'per@@', 'per@@', 'c@@', 'e@@', 'zion@@', 'e,', 'che', 'la', 's@@', 'per@@', 'anza', 'di', 'con@@', 'to', 'che', 'i', 'pr@@', 'inci@@', 'p@@', 'ali', 'che', 'i', 'con@@']
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Hypothesis: Lo scorso l'anno scorso che l'anno scorso di fare il 40 percento di considerare che i considerano che i tre milioni di anni che i 40 milioni di anni che i 40 per per il 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di questo per per il 40 percento di 30 perpercezione, che la speranza di conto che i principali che i con
2025-05-29 18:25:02,963 - INFO - joeynmt.training - Example #1
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:25:02,963 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'stata', 'stata', 'in@@', 'credi@@', 'bile', 'che', 'questo', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'il', 'D@@', 'io', 'è', 'che', 'il', 'D@@', 'io', 'del', 'D@@', 'io', 'non', 'è', 'che', 'il', 'D@@', 'io', 'di', 'de@@', 'ci@@', 'sion@@', 'e.', '</s>']
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:25:02,963 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il problema non è stata stata incredibile che questo è il problema di questo problema di questo problema che non è che non è che non è che il Dio è che il Dio del Dio non è che il Dio di decisione.
2025-05-29 18:25:02,963 - INFO - joeynmt.training - Example #2
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'comun@@', 'ità', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'di', 'questi', 'sistem@@', 'i', 'glob@@', 'ali', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la comunità di influenza di questi sistemi globali di climatico globale.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - Example #3
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'W@@', 'in@@', ',', 'in', 'vi@@', 'a', 'e', 's@@', 'ett@@', 'a', 'e', 's@@', 'ett@@', 'a', 'in', 's@@', 'ett@@', 'a.', '</s>']
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Hypothesis: Si chiama Win, in via e setta e setta in setta.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - Example #4
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:25:02,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'spec@@', 'ie', 'di', 'in@@', 'contr@@', 'ar@@', 'si', 'in', 'ulti@@', 'ma', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:25:02,964 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostrerò una specie di incontrarsi in ultima è successo in 25 anni.
2025-05-29 18:25:15,272 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     2.154693, Batch Acc: 0.381827, Tokens per Sec:     5809, Lr: 0.000300
2025-05-29 18:25:27,342 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     2.012780, Batch Acc: 0.382974, Tokens per Sec:     5920, Lr: 0.000300
2025-05-29 18:25:39,654 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     2.315470, Batch Acc: 0.379744, Tokens per Sec:     5936, Lr: 0.000300
2025-05-29 18:25:52,230 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     2.148528, Batch Acc: 0.380862, Tokens per Sec:     5635, Lr: 0.000300
2025-05-29 18:26:04,693 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     2.134259, Batch Acc: 0.382003, Tokens per Sec:     5713, Lr: 0.000300
2025-05-29 18:26:04,693 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:27:01,091 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.17, ppl:   8.80, acc:   0.37, generation: 56.3906[sec], evaluation: 0.0000[sec]
2025-05-29 18:27:01,092 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:27:01,182 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/7500.ckpt
2025-05-29 18:27:01,186 - INFO - joeynmt.training - Example #0
2025-05-29 18:27:01,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:27:01,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'v@@', 'evo', 'che', 'ho', 'mostr@@', 'ato', 'questa', 'sono', 'st@@', 'ati', 'per', 'mostr@@', 'are', 'che', 'i', 'su@@', 'oi', 'lavor@@', 'are', 'per', 'fare', 'la', 'po@@', 'pol@@', 'azione', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'con@@', 'di@@', 'vi@@', 'de', 'per', 'i', '4@@', '0', 'milioni', 'di', 'anni', 'per', '4@@', '0', 'per', 'anni@@', '.', '</s>']
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Hypothesis: Avevo che ho mostrato questa sono stati per mostrare che i suoi lavorare per fare la popolazione che i considerano che i condivide per i 40 milioni di anni per 40 per anni.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - Example #1
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'diff@@', 'ici@@', 'le', 'di', 'es@@', 'peri@@', 'enz@@', 'e', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'è', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'am@@', 'p@@', 'a', 'del', 'D@@', 'D@@', 'io', 'del', 'D@@', 'io', 'del', 'D@@', 'D@@', 'io', '</s>']
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza difficile di esperienze di questo problema di questo problema è che non è la distampa del DDio del Dio del DDio
2025-05-29 18:27:01,187 - INFO - joeynmt.training - Example #2
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sistema', 's@@', 'ac@@', 'co', 'di', 'sol@@', 't@@', 'anto', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ico', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'è', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Hypothesis: In un sistema sacco di soltanto è la climatico di climatico globale è il nostro climatico globale.
2025-05-29 18:27:01,187 - INFO - joeynmt.training - Example #3
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:27:01,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'W@@', 'in@@', ',', 'in', 'cui', 'si', 'trov@@', 'a', 'in', 'b@@', 'at@@', 'to', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o.', '</s>']
2025-05-29 18:27:01,187 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:27:01,188 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:27:01,188 - INFO - joeynmt.training - 	Hypothesis: Si chiama Win, in cui si trova in batto in un certo senso.
2025-05-29 18:27:01,188 - INFO - joeynmt.training - Example #4
2025-05-29 18:27:01,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:27:01,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:27:01,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'è', 'una', 'cell@@', 'u@@', 'le', 'che', 'è', 'succ@@', 'esso', 'in', 'cui', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:27:01,188 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:27:01,188 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:27:01,188 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima prossima è una cellule che è successo in cui è successo in 25 anni.
2025-05-29 18:27:12,947 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     2.397961, Batch Acc: 0.385257, Tokens per Sec:     5983, Lr: 0.000300
2025-05-29 18:27:24,765 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     2.064162, Batch Acc: 0.389335, Tokens per Sec:     5874, Lr: 0.000300
2025-05-29 18:27:35,836 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     2.102823, Batch Acc: 0.383915, Tokens per Sec:     6410, Lr: 0.000300
2025-05-29 18:27:47,756 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     2.318903, Batch Acc: 0.382837, Tokens per Sec:     6007, Lr: 0.000300
2025-05-29 18:27:59,482 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.991114, Batch Acc: 0.385727, Tokens per Sec:     5888, Lr: 0.000300
2025-05-29 18:27:59,482 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:28:59,921 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.16, ppl:   8.67, acc:   0.37, generation: 60.4318[sec], evaluation: 0.0000[sec]
2025-05-29 18:28:59,923 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:29:00,007 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/8000.ckpt
2025-05-29 18:29:00,011 - INFO - joeynmt.training - Example #0
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'anno', 'anno', 'mostr@@', 'ato', 'queste', 'due', 'f@@', 'o@@', 'to', 'che', 'i', 'fi@@', 'or@@', 'i,', 'per', 'fare', 'per', 'fare', 'il', 'modo', 'che', 'i', 'p@@', 'an@@', 'o,', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ati', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'per', 'milioni', 'di', 'anni', 'di', 'pr@@', 'inci@@', 'p@@', 'ali', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'in@@', 'f@@', 'ett@@', 'o.', '</s>']
2025-05-29 18:29:00,011 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:29:00,011 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:29:00,011 - INFO - joeynmt.training - 	Hypothesis: Nel anno anno mostrato queste due foto che i fiori, per fare per fare il modo che i pano, che i considerati per i tre milioni di anni che i 40 per milioni di anni di principali per 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di questo per 40 percento di infetto.
2025-05-29 18:29:00,011 - INFO - joeynmt.training - Example #1
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:29:00,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'modo', 'in', 'cui', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pr@@', 'inci@@', 'p@@', 'ale', 'che', 'non', 'è', 'la', 'di@@', 'men@@', 'sione', 'di', 'questi', 'problem@@', 'i', 'che', 'non', 'è', 'la', 'D@@', 'ick@@', 'ick@@', 'e', 'e', "l'@@", 'E@@', 'is@@', 'm@@', 'o.', '</s>']
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Hypothesis: Ma non è il modo in cui non è abbastanza principale che non è la dimensione di questi problemi che non è la Dickicke e l'Eismo.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - Example #2
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'for@@', 'tun@@', 'a,', 'la', 'for@@', 'ma', 'di', 'bas@@', 'so', 'di', 's@@', 'fi@@', 'da', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la fortuna, la forma di basso di sfida del nostro climatico globale.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - Example #3
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'chiam@@', 'a', 'il', 'b@@', 'us@@', 'in@@', 'es@@', 's', 'e', 'la', 'm@@', 'att@@', 'ina', 'e', 'la', 'p@@', 'ell@@', 'a.', '</s>']
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Hypothesis: Si chiama il business e la mattina e la pella.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - Example #4
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:29:00,012 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'c@@', 'aus@@', 'a', 'di', 'quello', 'che', 'sta', 'succ@@', 'e@@', 'den@@', 'do', 'in', '2@@', '5', 'anni', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'di', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:29:00,012 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostrerò una causa di quello che sta succedendo in 25 anni che è successo in 25 anni di 25 anni.
2025-05-29 18:29:12,140 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     2.181952, Batch Acc: 0.384133, Tokens per Sec:     5691, Lr: 0.000300
2025-05-29 18:29:24,616 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     2.159432, Batch Acc: 0.388270, Tokens per Sec:     5710, Lr: 0.000300
2025-05-29 18:29:36,642 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     2.099098, Batch Acc: 0.389720, Tokens per Sec:     6043, Lr: 0.000300
2025-05-29 18:29:48,255 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     2.212857, Batch Acc: 0.387324, Tokens per Sec:     6020, Lr: 0.000300
2025-05-29 18:30:00,186 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     2.173658, Batch Acc: 0.389384, Tokens per Sec:     6147, Lr: 0.000300
2025-05-29 18:30:00,187 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:30:50,491 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.13, ppl:   8.43, acc:   0.38, generation: 50.2969[sec], evaluation: 0.0000[sec]
2025-05-29 18:30:50,493 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:30:50,581 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/8500.ckpt
2025-05-29 18:30:50,583 - INFO - joeynmt.training - Example #0
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'questa', 'cos@@', 'a,', 'per', 'mostr@@', 'are', 'che', 'i', 'comp@@', 'ag@@', 'n@@', 'ati@@', ',', 'per', "l'@@", 'ar@@', 'e@@', 'a', 'che', 'i', 'con@@', 'si@@', 'der@@', 'at@@', 'ori', 'che', 'i', 'gi@@', 'ov@@', 'an@@', 'e', 'per', 'i', '4@@', '0', 'anni@@', ',', 'per', 'il', '4@@', '0@@', '%', 'delle', 'di@@', 'men@@', 'sion@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'questo', 'per', 'c@@', 'ento', 'di', 'questo', '4@@', '0@@', '%', 'di', 'questo', 'per', 'per', 's@@', 'é', 'per', 'il', '4@@', '0@@', '%', 'di', 'c@@', 'ento', 'di', 'questi', 'due', 'per', 'per', 'c@@', 'ento', 'di', 'in@@', 'fin@@', 'e', 'per', 'per', 'per', 's@@', 'cont@@', 'are', 'il', '4@@', '0@@', '%', 'di', 'in@@', 'cor@@', 'aggi@@', 'o.', '</s>']
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno, ho mostrato questa cosa, per mostrare che i compagnati, per l'area che i consideratori che i giovane per i 40 anni, per il 40% delle dimensioni di 40 percento di cento di questo per cento di questo 40% di questo per per sé per il 40% di cento di questi due per per cento di infine per per per scontare il 40% di incoraggio.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - Example #1
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'più', 'for@@', 'te', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pr@@', 'om@@', 'u@@', 'o@@', 'vere', 'questo', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'di@@', 'st@@', 'am@@', 'o.', '</s>']
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Hypothesis: Ma non è il più forte non è abbastanza promuovere questo problema di questo specifico di questo problema di questo distamo.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - Example #2
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'eff@@', 'etti@@', ',', 'in', 'un', 'sistema', 'sistema', 'di', 'in@@', 'f@@', 'lu@@', 'enz@@', 'a,', "l'@@", 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'a', 'del', 'nostro', 'sistema', 'soci@@', 'ale.', '</s>']
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - 	Hypothesis: In effetti, in un sistema sistema di influenza, l'Eiskappa del nostro sistema sociale.
2025-05-29 18:30:50,584 - INFO - joeynmt.training - Example #3
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:30:50,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'di', 'W@@', 'in@@', ',', 'e', 'la', 'p@@', 'ell@@', 'a', 's@@', 'ens@@', 'a.', '</s>']
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Hypothesis: Si tratta di di Win, e la pella sensa.
2025-05-29 18:30:50,585 - INFO - joeynmt.training - Example #4
2025-05-29 18:30:50,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:30:50,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:30:50,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'o', 'una', 'di@@', 'ta', 'di', 'una', 'c@@', 'aus@@', 'a', 'di', 'circa', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:30:50,585 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostro una dita di una causa di circa 25 anni.
2025-05-29 18:31:02,460 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     2.074957, Batch Acc: 0.393033, Tokens per Sec:     5740, Lr: 0.000300
2025-05-29 18:31:14,733 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.916508, Batch Acc: 0.394526, Tokens per Sec:     5739, Lr: 0.000300
2025-05-29 18:31:27,349 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     2.021481, Batch Acc: 0.395273, Tokens per Sec:     5715, Lr: 0.000300
2025-05-29 18:31:40,153 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     2.084865, Batch Acc: 0.391874, Tokens per Sec:     5440, Lr: 0.000300
2025-05-29 18:31:52,822 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     2.259500, Batch Acc: 0.397678, Tokens per Sec:     5561, Lr: 0.000300
2025-05-29 18:31:52,822 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:32:55,860 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.30, acc:   0.39, generation: 63.0308[sec], evaluation: 0.0000[sec]
2025-05-29 18:32:55,861 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:32:55,957 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/9000.ckpt
2025-05-29 18:32:55,958 - INFO - joeynmt.training - Example #0
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'd@@', 'esso', 'ho', 'mostr@@', 'ato', 'questa', 'due', 'f@@', 'ec@@', 'i', 'di', 'mostr@@', 'are', 'che', 'i', 'su@@', 'oi', 'fi@@', 'gli', 'per', 'la', 'b@@', 'att@@', 'u@@', 'ale', 'che', 'i', 'p@@', 'ap@@', 'i', 'che', 'i', 'sono', 'i', 'tre', 'milioni', 'di', 'anni@@', ',', 'che', 'i', 'gi@@', 'ov@@', 'ani', 'per', 'il', '4@@', '0@@', '%', 'delle', 'b@@', 'at@@', 'tiv@@', 'e', 'per', 'il', '4@@', '0@@', '%', 'di', 'st@@', 'ati', 'per', 'c@@', 'ento', 'di', 'un', "po'", 'di', 'b@@', 'att@@', 'o.', '</s>']
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Hypothesis: Adesso ho mostrato questa due feci di mostrare che i suoi figli per la battuale che i papi che i sono i tre milioni di anni, che i giovani per il 40% delle battive per il 40% di stati per cento di un po' di batto.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - Example #1
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'fel@@', 'ic@@', 'ità', 'di', 'abb@@', 'ast@@', 'anza', 'pr@@', 'ec@@', 'ed@@', 'ent@@', 'i,', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'D@@', 'ick@@', 'e', 'non', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'am@@', 'a.', '</s>']
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Hypothesis: Ma non è la felicità di abbastanza precedenti, non è la distanza di questo problema di questo problema che non è la distanza del Dicke non mostra la distanza di questo che non è la distama.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - Example #2
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'b@@', 'at@@', 'tiv@@', 'a', 'è', 'la', 'b@@', 'al@@', 'im@@', 'ent@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la battiva è la balimenta del nostro climatico globale del nostro climatico globale.
2025-05-29 18:32:55,959 - INFO - joeynmt.training - Example #3
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:32:55,959 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'sc@@', 'u@@', 'p@@', 'e@@', 'o', 'e', 'p@@', 'eg@@', 'gi@@', 'o', 'in', 'S@@', 'ett@@', 'e.', '</s>']
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Hypothesis: Lo scupeo e peggio in Sette.
2025-05-29 18:32:55,960 - INFO - joeynmt.training - Example #4
2025-05-29 18:32:55,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:32:55,960 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:32:55,960 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'f@@', 'ol@@', 'tre', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'a', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'succ@@', 'eder@@', 'à', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:32:55,960 - INFO - joeynmt.training - 	Hypothesis: Il prossimo foltre che vi mostro che vi mostra che vi mostra cosa succederà in 25 anni.
2025-05-29 18:33:07,794 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     2.275480, Batch Acc: 0.394680, Tokens per Sec:     5844, Lr: 0.000300
2025-05-29 18:33:20,360 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     2.176946, Batch Acc: 0.395565, Tokens per Sec:     5613, Lr: 0.000300
2025-05-29 18:33:32,793 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     2.160736, Batch Acc: 0.399146, Tokens per Sec:     5880, Lr: 0.000300
2025-05-29 18:33:45,996 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     2.134073, Batch Acc: 0.394211, Tokens per Sec:     5396, Lr: 0.000300
2025-05-29 18:33:59,397 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     2.123087, Batch Acc: 0.395834, Tokens per Sec:     5219, Lr: 0.000300
2025-05-29 18:33:59,398 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:35:02,456 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.10, ppl:   8.14, acc:   0.39, generation: 63.0521[sec], evaluation: 0.0000[sec]
2025-05-29 18:35:02,457 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:35:02,535 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/9500.ckpt
2025-05-29 18:35:02,538 - INFO - joeynmt.training - Example #0
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'cre@@', 'are', 'che', 'la', 'po@@', 'pol@@', 'azione', 'che', 'le', 'ar@@', 'e@@', 'e', 'che', 'gli', 'ar@@', 'g@@', 'om@@', 'enti', 'che', 'gli', 'u@@', 'ov@@', 'a', 'per', 'la', 'di@@', 'ec@@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', 'di', '4@@', '0', 'per', 'per', 'il', '4@@', '0@@', '%', 'di', 'un', 'proc@@', 'esso', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'il', '4@@', '4@@', '0@@', '%', 'per', 'il', '4@@', '0@@', '%', 'di', 'questo', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'per', 'il', '4@@', '0@@', '%', 'per', 'per', 'il', 'per@@', 'met@@', 'tere', 'di', 'questo', '4@@', '0@@', '%', 'per', 'il', '4@@', '4@@', '0@@', '%', 'di', 'questo', 'per', 'il', '4@@', '4@@', '0@@', '%', 'di', 'questo', 'per', 'il', '4@@', '0@@', '%', 'di']
2025-05-29 18:35:02,538 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:35:02,538 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:35:02,538 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno, ho mostrato queste due volte per creare che la popolazione che le aree che gli argomenti che gli uova per la dieci di tre milioni di anni di 40 per per il 40% di un processo di 40 percento per il 440% per il 40% di questo 40 percento per per il 40% per per il permettere di questo 40% per il 440% di questo per il 440% di questo per il 40% di
2025-05-29 18:35:02,538 - INFO - joeynmt.training - Example #1
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:35:02,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'punto', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'diff@@', 'ici@@', 'le', 'che', 'non', 'è', 'la', 'di@@', 'stri@@', 'bu@@', 'zione', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Hypothesis: Ma non è il punto che non è abbastanza difficile che non è la distribuzione di questo problema di questo problema che non è che non è che mostra la distanza.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - Example #2
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'co@@', 'pi@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'a', 'che', 'il', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'glob@@', 'ale.', '</s>']
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Hypothesis: In certo senso, la copia di Eiskappa che il nostro climatico globale globale.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - Example #3
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'p@@', 'ò', 'e', 'la', 'p@@', 'eg@@', 'gi@@', 'or@@', 'e.', '</s>']
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un pò e la peggiore.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - Example #4
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:35:02,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ra', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:35:02,539 - INFO - joeynmt.training - 	Hypothesis: La prossima fra vi mostro che vi mostro che vi mostro che è successo in 25 anni.
2025-05-29 18:35:16,498 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     2.198186, Batch Acc: 0.397964, Tokens per Sec:     5115, Lr: 0.000300
2025-05-29 18:35:30,719 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     2.032818, Batch Acc: 0.398918, Tokens per Sec:     5031, Lr: 0.000300
2025-05-29 18:35:44,214 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     2.038739, Batch Acc: 0.394310, Tokens per Sec:     5296, Lr: 0.000300
2025-05-29 18:35:58,155 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     2.055839, Batch Acc: 0.400793, Tokens per Sec:     5102, Lr: 0.000300
2025-05-29 18:36:11,878 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.966308, Batch Acc: 0.404188, Tokens per Sec:     5266, Lr: 0.000300
2025-05-29 18:36:11,879 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:37:21,398 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.01, acc:   0.40, generation: 69.5124[sec], evaluation: 0.0000[sec]
2025-05-29 18:37:21,400 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:37:21,479 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/10000.ckpt
2025-05-29 18:37:21,480 - INFO - joeynmt.training - Example #0
2025-05-29 18:37:21,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:37:21,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'anno', 'scor@@', 'so', 'questo', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'far@@', 'lo', 'per', 'far@@', 'lo', "l'@@", 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'a', 'che', 'i', 'con@@', 'v@@', 'in@@', 'ti', 'di', 'questi', 'sono', 'tre', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'per', 'cent@@', 'in@@', 'a@@', 'ia', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'un', "po'", 'di', 's@@', 'ac@@', 'co', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'un', "po'", 'di', 's@@', 'egn@@', 'o', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'è', 'stato', 'un', 'prog@@', 'ett@@', 'o.', '</s>']
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Hypothesis: Nel anno scorso questo anno ho mostrato queste due volte per farlo per farlo l'Eiskappa che i convinti di questi sono tre milioni di anni che i 40 per centinaia di anni per il 40 per per per il 40 percento di un po' di sacco di 40 percento di un po' di segno 40 percento di questo è stato un progetto.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - Example #1
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'un', "po'", 'più', 'diff@@', 'ici@@', 'le', 'che', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'la', 'd@@', 'ot@@', 'ta', 'di', 'D@@', 'ick@@', 'e', 'che', 'non', 'mostr@@', 'a', 'il', 'D@@', 'ick@@', 'e', 'del', 'D@@', 'D@@', 'ick@@', 'e', 'del', 'D@@', 'ick@@', 'e', 'del', 'D@@', 'ick@@', 'e', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'un', 'problem@@', 'a.', '</s>']
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato un po' più difficile che è il problema di questo problema di questo problema non è la dotta di Dicke che non mostra il Dicke del DDicke del Dicke del Dicke che non è la distanza di un problema.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - Example #2
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'co@@', 'p@@', 'pi@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'glob@@', 'ale.', '</s>']
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la coppia di ghiaccio globale del nostro sistema globale.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - Example #3
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:37:21,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'stato', 'un', "po'", 'di', 'in@@', 'cor@@', 'so', 'e', 'la', 'sc@@', 'at@@', 'ola', 'e', 's@@', 'an@@', 'gu@@', 'e.', '</s>']
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:37:21,481 - INFO - joeynmt.training - 	Hypothesis: E' stato un po' di incorso e la scatola e sangue.
2025-05-29 18:37:21,482 - INFO - joeynmt.training - Example #4
2025-05-29 18:37:21,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:37:21,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:37:21,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'un', 'mom@@', 'ento', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'la', 'di@@', 're@@', 'zione', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:37:21,482 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:37:21,482 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:37:21,482 - INFO - joeynmt.training - 	Hypothesis: Il prossimo mostro che vi mostrerò un momento che vi mostrerò la direzione è successo in 25 anni.
2025-05-29 18:37:35,003 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     2.145956, Batch Acc: 0.398653, Tokens per Sec:     5219, Lr: 0.000300
2025-05-29 18:37:48,814 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     2.083105, Batch Acc: 0.406069, Tokens per Sec:     5309, Lr: 0.000300
2025-05-29 18:38:02,101 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     2.158339, Batch Acc: 0.404475, Tokens per Sec:     5406, Lr: 0.000300
2025-05-29 18:38:15,509 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     2.027527, Batch Acc: 0.399725, Tokens per Sec:     5536, Lr: 0.000300
2025-05-29 18:38:28,776 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     2.207709, Batch Acc: 0.405570, Tokens per Sec:     5329, Lr: 0.000300
2025-05-29 18:38:28,776 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:39:53,180 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.86, acc:   0.40, generation: 84.3970[sec], evaluation: 0.0000[sec]
2025-05-29 18:39:53,183 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:39:53,263 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/10500.ckpt
2025-05-29 18:39:53,264 - INFO - joeynmt.training - Example #0
2025-05-29 18:39:53,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:39:53,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'il', 'fatto', 'che', 'la', 'parte', 'di', "l'@@", 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'es@@', 'o', 'di', 'in@@', 'f@@', 'lu@@', 'enza', 'che', 'i', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', '4@@', '0', 'per', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'b@@', 'agli@@', 'o.', '</s>']
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due volte per ridurre il fatto che la parte di l'Eiskappeso di influenza che i per tre milioni di anni di anni di tre milioni di anni di anni di 40 per per cento dei 40 per per il 40 percento per il 40 percento per il 40 percento per il 40 percento di sbaglio.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - Example #1
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'la', 'for@@', 'za', 'non', 'è', 'la', 'più', 'for@@', 'te', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'a.', '</s>']
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Hypothesis: Ma non è la forza non è la più forte di questo problema di questo problema di questo problema che non è la destina.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - Example #2
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'parte', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'il', 'sistema', 'del', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'o.', '</s>']
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la parte è la climatica è il sistema del nostro sistema globale del nostro climato.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - Example #3
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:39:53,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'in@@', 'ser@@', 'ito', 'in', 'in@@', 'ver@@', 's@@', 'o.', '</s>']
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:39:53,265 - INFO - joeynmt.training - 	Hypothesis: Si è inserito in inverso.
2025-05-29 18:39:53,266 - INFO - joeynmt.training - Example #4
2025-05-29 18:39:53,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:39:53,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:39:53,266 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ec@@', 'e', 'mostr@@', 'ar@@', 'vi', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cell@@', 'u@@', 'la', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'in', '2@@', '5', 'anni', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:39:53,266 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:39:53,266 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:39:53,266 - INFO - joeynmt.training - 	Hypothesis: La prossima fece mostrarvi vi mostrerò è una cellula che è successo in 25 anni in 25 anni in 25 anni.
2025-05-29 18:40:06,575 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     2.107532, Batch Acc: 0.403681, Tokens per Sec:     5335, Lr: 0.000300
2025-05-29 18:40:20,025 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     1.997282, Batch Acc: 0.406179, Tokens per Sec:     5259, Lr: 0.000300
2025-05-29 18:40:32,847 - INFO - joeynmt.training - Epoch   3, Step:    13300, Batch Loss:     2.092096, Batch Acc: 0.409202, Tokens per Sec:     5514, Lr: 0.000300
2025-05-29 18:40:46,170 - INFO - joeynmt.training - Epoch   3, Step:    13400, Batch Loss:     1.918870, Batch Acc: 0.409379, Tokens per Sec:     5316, Lr: 0.000300
2025-05-29 18:40:58,808 - INFO - joeynmt.training - Epoch   3, Step:    13500, Batch Loss:     2.087881, Batch Acc: 0.404395, Tokens per Sec:     5581, Lr: 0.000300
2025-05-29 18:40:58,808 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:42:20,698 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.83, acc:   0.40, generation: 81.8831[sec], evaluation: 0.0000[sec]
2025-05-29 18:42:20,700 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:42:20,782 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/11000.ckpt
2025-05-29 18:42:20,784 - INFO - joeynmt.training - Example #0
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'questi', 'due', 'due', 'vol@@', 'te', 'di', 'mostr@@', 'are', 'che', 'il', 'con@@', 'cor@@', 'so', 'che', 'le', 'ar@@', 'e@@', 'e', 'che', 'le', 'con@@', 'di@@', 'zioni', 'che', 'le', 'in@@', 'forma@@', 'zioni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'i', '4@@', '0', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'per', 'il', '4@@', '0', 'per', 'per', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'per', 'c@@', 'ento', 'di', 'cui', 'av@@', 'ev@@', 'amo', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'con@@', 'v@@', 'in@@', 'to', 'che', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'cui', "l'@@", 'anno', 'per', 'con@@', 'ver@@', 's@@', 'azion@@', 'e.', '</s>']
2025-05-29 18:42:20,784 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:42:20,784 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:42:20,784 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno questi due due volte di mostrare che il concorso che le aree che le condizioni che le informazioni per i tre milioni di anni che per i 40 milioni di anni che avevano per il 40 per per per cento dei 40 percento di 40 percento di cento per cento di cui avevamo 40 percento di convinto che il 40 percento di cui l'anno per conversazione.
2025-05-29 18:42:20,784 - INFO - joeynmt.training - Example #1
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:42:20,784 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'tun@@', 'at@@', 'amente', "l'@@", 'in@@', 'st@@', 'in@@', 'a,', 'che', 'non', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'il', 'de@@', 'st@@', 'in@@', 'o.', '</s>']
2025-05-29 18:42:20,784 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunatamente l'instina, che non è il problema di questo non è il problema non è il destino.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - Example #2
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'è', 'il', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'è', 'il', 'nostro', 'sistema', 'glob@@', 'ale.', '</s>']
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia è il climatico globale è il nostro sistema globale.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - Example #3
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 's@@', 'ens@@', 'o,', 'e', 'si', 's@@', 'b@@', 'agli@@', 'ano', 'in', 's@@', 'ens@@', 'o.', '</s>']
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Hypothesis: Si tratta di senso, e si sbagliano in senso.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - Example #4
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:42:20,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cell@@', 'u@@', 'le', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:42:20,785 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostrerò è una cellule che è successo in 25 anni.
2025-05-29 18:42:34,088 - INFO - joeynmt.training - Epoch   3, Step:    13600, Batch Loss:     2.112939, Batch Acc: 0.412989, Tokens per Sec:     5427, Lr: 0.000300
2025-05-29 18:42:48,055 - INFO - joeynmt.training - Epoch   3, Step:    13700, Batch Loss:     2.061687, Batch Acc: 0.408686, Tokens per Sec:     5176, Lr: 0.000300
2025-05-29 18:43:01,915 - INFO - joeynmt.training - Epoch   3, Step:    13800, Batch Loss:     1.973112, Batch Acc: 0.414093, Tokens per Sec:     5144, Lr: 0.000300
2025-05-29 18:43:16,024 - INFO - joeynmt.training - Epoch   3, Step:    13900, Batch Loss:     2.131119, Batch Acc: 0.411931, Tokens per Sec:     4891, Lr: 0.000300
2025-05-29 18:43:29,871 - INFO - joeynmt.training - Epoch   3, Step:    14000, Batch Loss:     1.969051, Batch Acc: 0.412544, Tokens per Sec:     4949, Lr: 0.000300
2025-05-29 18:43:29,872 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:44:30,982 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.04, ppl:   7.71, acc:   0.40, generation: 61.1033[sec], evaluation: 0.0000[sec]
2025-05-29 18:44:30,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:44:31,061 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/11500.ckpt
2025-05-29 18:44:31,064 - INFO - joeynmt.training - Example #0
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'anno', 'questi', 'due', 'due', 'vol@@', 'te', 'ho', 'mostr@@', 'ato', 'che', 'la', 'con@@', 'di@@', 'zione', 'per', 'con@@', 'si@@', 'der@@', 'are', 'il', 'p@@', 'es@@', 'o', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'che', 'i', 'pr@@', 'ec@@', 'is@@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'per', 'milioni', 'di', 'anni', 'che', 'sono', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per@@', 'cent@@', 'o.', '</s>']
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno questi due due volte ho mostrato che la condizione per considerare il peso di questi due milioni di anni che i precisi di tre milioni di anni che i 40 per milioni di anni che sono 40 per cento dei 40 percento.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - Example #1
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:44:31,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'questo', 'è', 'un', "po'", 'più', 'fel@@', 'ic@@', 'e', 'di', 'questo', 'punto', 'di', 'vi@@', 'sta', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'di', 'questo', 'pun@@', 't@@', 'o.', '</s>']
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - 	Hypothesis: Ma non questo è un po' più felice di questo punto di vista di questo specifico di questo punto.
2025-05-29 18:44:31,064 - INFO - joeynmt.training - Example #2
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'co@@', 'p@@', 'pi@@', 'a', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'è', 'il', 'nostro', 'sistema', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la coppia è la climatica globale è il nostro sistema globale del nostro climatico.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - Example #3
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['C@@', 'on@@', 'os@@', 'c@@', 'ete', 'in', 'un', 'cer@@', 'to', 'e', 'la', 'p@@', 'eg@@', 'gi@@', 'a', 'in', 'S@@', 'ic@@', 'it@@', 'a.', '</s>']
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Hypothesis: Conoscete in un certo e la peggia in Sicita.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - Example #4
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:44:31,065 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ec@@', 'ed@@', 'ent@@', 'i,', 'che', 'vi', 'mostr@@', 'o', 'una', 'giorn@@', 'ata', 'di', 'una', 'giorn@@', 'ata', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:44:31,065 - INFO - joeynmt.training - 	Hypothesis: La prossima precedenti, che vi mostro una giornata di una giornata di quello che è successo in 25 anni.
2025-05-29 18:44:43,580 - INFO - joeynmt.training - Epoch   3, Step:    14100, Batch Loss:     2.108594, Batch Acc: 0.406726, Tokens per Sec:     5620, Lr: 0.000300
2025-05-29 18:44:47,671 - INFO - joeynmt.training - Epoch   3: total training loss 9782.62
2025-05-29 18:44:47,672 - INFO - joeynmt.training - EPOCH 4
2025-05-29 18:44:56,987 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.841598, Batch Acc: 0.428523, Tokens per Sec:     5388, Lr: 0.000300
2025-05-29 18:45:10,099 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     2.025882, Batch Acc: 0.428262, Tokens per Sec:     5394, Lr: 0.000300
2025-05-29 18:45:23,556 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     2.106225, Batch Acc: 0.426216, Tokens per Sec:     5329, Lr: 0.000300
2025-05-29 18:45:36,869 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     2.051508, Batch Acc: 0.432863, Tokens per Sec:     5328, Lr: 0.000300
2025-05-29 18:45:36,870 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:46:32,182 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.59, acc:   0.41, generation: 55.3057[sec], evaluation: 0.0000[sec]
2025-05-29 18:46:32,183 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:46:32,265 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/12000.ckpt
2025-05-29 18:46:32,267 - INFO - joeynmt.training - Example #0
2025-05-29 18:46:32,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:46:32,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:46:32,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'questi', 'due', 'due', 'vol@@', 'te', 'per', 'fare', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'di@@', 'zioni', 'che', 'la', 'con@@', 'di@@', 'zione', 'di', 'con@@', 'si@@', 'der@@', 'are', 'il', 'con@@', 'di@@', 'vi@@', 'den@@', 'do', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'milioni', 'di', 'anni', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'per@@', 'met@@', 'ter@@', 'e.', '</s>']
2025-05-29 18:46:32,267 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:46:32,267 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno questi due due volte per fare queste due volte per condizioni che la condizione di considerare il condividendo di tre milioni di anni che avevano per i 40 per cento dei 40 milioni di anni per 40 per cento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di permettere.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - Example #1
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'un', 'grande', 'grande', 'grande', 'pr@@', 'ec@@', 'ed@@', 'ent@@', 'i@@', 'va', 'il', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'è', 'la', 'd@@', 'ann@@', 'a.', '</s>']
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato un grande grande grande precedentiva il problema di questo specifico problema di questo problema è la danna.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - Example #2
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'è', 'il', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia è il nostro sistema di climatico globale del nostro climatico globale.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - Example #3
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'in@@', 'ver@@', 's@@', 'o.', '</s>']
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un inverso.
2025-05-29 18:46:32,268 - INFO - joeynmt.training - Example #4
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:46:32,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'delle', 'F@@', 'ol@@', 'i@@', 'e,', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'in', 'modo', 'che', 'succ@@', 'ede', 'in', 'cui', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 18:46:32,268 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:46:32,269 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:46:32,269 - INFO - joeynmt.training - 	Hypothesis: La prossima delle Folie, è una divisione di quello che è successo in modo che succede in cui è successo.
2025-05-29 18:46:44,572 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.920951, Batch Acc: 0.426893, Tokens per Sec:     5666, Lr: 0.000300
2025-05-29 18:46:57,886 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.952730, Batch Acc: 0.425797, Tokens per Sec:     5372, Lr: 0.000300
2025-05-29 18:47:10,737 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.904459, Batch Acc: 0.427760, Tokens per Sec:     5729, Lr: 0.000300
2025-05-29 18:47:23,744 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     2.014837, Batch Acc: 0.431167, Tokens per Sec:     5291, Lr: 0.000300
2025-05-29 18:47:36,599 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.878067, Batch Acc: 0.426776, Tokens per Sec:     5440, Lr: 0.000300
2025-05-29 18:47:36,599 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:48:43,946 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.54, acc:   0.41, generation: 67.3401[sec], evaluation: 0.0000[sec]
2025-05-29 18:48:43,948 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:48:44,025 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/12500.ckpt
2025-05-29 18:48:44,025 - INFO - joeynmt.training - Example #0
2025-05-29 18:48:44,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:48:44,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'queste', 'due', 'vol@@', 'te', 'sono', 'due', 'vol@@', 'te', 'per', 'con@@', 'si@@', 'der@@', 'are', 'il', 'li@@', 'vello', 'di', 's@@', 'an@@', 'gu@@', 'ig@@', 'no', 'per', 'i', 'li@@', 'br@@', 'i', 'di', 'questi', 'li@@', 'br@@', 'i', 'di', '3@@', '0', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'om@@', 'ma', 'che', 'i', 'li@@', 'br@@', 'i', 'di', 's@@', 'ov@@', 'ra@@', 'p@@']
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno queste due volte sono due volte per considerare il livello di sanguigno per i libri di questi libri di 30 milioni di anni per tre milioni di anni per il 40 per cento dei 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di 40 percento di somma che i libri di sovrap
2025-05-29 18:48:44,026 - INFO - joeynmt.training - Example #1
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'pr@@', 'em@@', 'io', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'sp@@', 'eci@@', 'fic@@', 'o', 'di', 'questo', 't@@', 'ess@@', 'uto', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Hypothesis: Ma non è il premio non è abbastanza specifico di questo tessuto di questo problema di questo problema che non mostra la distanza.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - Example #2
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'di', 'comun@@', 'e', 'è', 'il', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'che', 'sia', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cattiva di comune è il climatico globale che sia il nostro sistema clima.
2025-05-29 18:48:44,026 - INFO - joeynmt.training - Example #3
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:48:44,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'in@@', 'ver@@', 's@@', 'o.', '</s>']
2025-05-29 18:48:44,026 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:48:44,027 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:48:44,027 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un inverso.
2025-05-29 18:48:44,027 - INFO - joeynmt.training - Example #4
2025-05-29 18:48:44,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:48:44,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:48:44,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'di@@', 'sc@@', 'us@@', 'sione', 'di', 'quello', 'che', 'succ@@', 'ede', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:48:44,027 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:48:44,027 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:48:44,027 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima che vi mostrerò una discussione di quello che succede in 25 anni.
2025-05-29 18:48:57,162 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.793158, Batch Acc: 0.427525, Tokens per Sec:     5558, Lr: 0.000300
2025-05-29 18:49:10,316 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     2.084227, Batch Acc: 0.426246, Tokens per Sec:     5409, Lr: 0.000300
2025-05-29 18:49:23,740 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.785656, Batch Acc: 0.424701, Tokens per Sec:     5211, Lr: 0.000300
2025-05-29 18:49:36,745 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.910023, Batch Acc: 0.430546, Tokens per Sec:     5602, Lr: 0.000300
2025-05-29 18:49:50,428 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.975608, Batch Acc: 0.430475, Tokens per Sec:     5308, Lr: 0.000300
2025-05-29 18:49:50,429 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:51:00,768 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.01, ppl:   7.44, acc:   0.42, generation: 70.3317[sec], evaluation: 0.0000[sec]
2025-05-29 18:51:00,769 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:51:00,845 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/13000.ckpt
2025-05-29 18:51:00,845 - INFO - joeynmt.training - Example #0
2025-05-29 18:51:00,845 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'questi', 'due', 'due', 'due', 'comp@@', 'ag@@', 'ni@@', ',', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'è', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'è', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'questo', 'è', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno questi due due due compagni, per considerare che i considerano che i considerano che i considerano i tre milioni di anni che i 40 per cento di 40 per cento di 40 percento di 40 percento di 40 percento di 40 percento di questo è il 40 percento di questo è il 40 percento di questo è il 40 percento di sottopo.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - Example #1
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'ma', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza forma di questo speciale non è la distanza non è la distanza.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - Example #2
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'è', 'la', 'b@@', 'att@@', 'u@@', 'ale', 'della', 'nostra', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia è la battuale della nostra climatica.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - Example #3
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:51:00,846 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'una', 's@@', 'ort@@', 'a', 'di', 's@@', 'ott@@', 'o@@', 'per@@', 'a', 'in', 'una', 's@@', 'f@@', 'era', 'in', 'una', 's@@', 'ort@@', 'a.', '</s>']
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:51:00,846 - INFO - joeynmt.training - 	Hypothesis: E' una sorta di sottopera in una sfera in una sorta.
2025-05-29 18:51:00,847 - INFO - joeynmt.training - Example #4
2025-05-29 18:51:00,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:51:00,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:51:00,847 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'è', 'una', 'delle', 'di@@', 'men@@', 'sion@@', 'i', 'è', 'una', 'giorn@@', 'ata', 'di', 'una', 'giorn@@', 'ale', 'di', 'quello', 'che', 'succ@@', 'essi@@', 'vo', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:51:00,847 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:51:00,847 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:51:00,847 - INFO - joeynmt.training - 	Hypothesis: La prossima è una delle dimensioni è una giornata di una giornale di quello che successivo negli ultimi 25 anni.
2025-05-29 18:51:13,911 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.971328, Batch Acc: 0.431601, Tokens per Sec:     5354, Lr: 0.000300
2025-05-29 18:51:27,454 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.900345, Batch Acc: 0.431692, Tokens per Sec:     5354, Lr: 0.000300
2025-05-29 18:51:40,987 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.958649, Batch Acc: 0.432622, Tokens per Sec:     5478, Lr: 0.000300
2025-05-29 18:51:54,257 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     2.004407, Batch Acc: 0.427767, Tokens per Sec:     5288, Lr: 0.000300
2025-05-29 18:52:07,748 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     2.043107, Batch Acc: 0.426897, Tokens per Sec:     5154, Lr: 0.000300
2025-05-29 18:52:07,749 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:53:06,099 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.40, acc:   0.42, generation: 58.3432[sec], evaluation: 0.0000[sec]
2025-05-29 18:53:06,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:53:06,177 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/13500.ckpt
2025-05-29 18:53:06,178 - INFO - joeynmt.training - Example #0
2025-05-29 18:53:06,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'di', 'queste', 'due', 'vol@@', 'te', 'per', 'f@@', 'ar', 'ri@@', 'par@@', 'ti@@', 're', 'che', 'le', 'ar@@', 'te', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'd@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'i', 'gi@@', 'o@@', 'chi', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '8', 'anni@@', '.', '</s>']
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due volte di queste due volte per far ripartire che le arte di ghiaccio che i dati per tre milioni di anni che i giochi che avevano tre milioni di anni che avevano tre milioni di anni per il 48 anni.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - Example #1
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'questa', 'sp@@', 'eci@@', 'e,', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a,', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza forse questa specie, non è la distanza, non è la distanza.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - Example #2
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'for@@', 'ma', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale.', '</s>']
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la forma di ghiaccio di ghiaccio globale.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - Example #3
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:53:06,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'vent@@', 'o', 'e', 'ri@@', 'p@@', 'et@@', 'e.', '</s>']
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:53:06,179 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:53:06,180 - INFO - joeynmt.training - 	Hypothesis: Si tratta di vento e ripete.
2025-05-29 18:53:06,180 - INFO - joeynmt.training - Example #4
2025-05-29 18:53:06,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:53:06,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:53:06,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ant@@', 'ast@@', 'ica', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ata', 'di', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:53:06,180 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:53:06,180 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:53:06,180 - INFO - joeynmt.training - 	Hypothesis: La prossima fantastica che vi mostro è una giornata di una cosa che è successo negli ultimi 25 anni.
2025-05-29 18:53:18,599 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     2.021512, Batch Acc: 0.428762, Tokens per Sec:     5705, Lr: 0.000300
2025-05-29 18:53:31,094 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.923397, Batch Acc: 0.430175, Tokens per Sec:     5575, Lr: 0.000300
2025-05-29 18:53:44,585 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     2.087937, Batch Acc: 0.428731, Tokens per Sec:     5361, Lr: 0.000300
2025-05-29 18:53:58,237 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.811998, Batch Acc: 0.433897, Tokens per Sec:     5313, Lr: 0.000300
2025-05-29 18:54:11,460 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.864961, Batch Acc: 0.432011, Tokens per Sec:     5227, Lr: 0.000300
2025-05-29 18:54:11,461 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:55:15,396 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.37, acc:   0.42, generation: 63.9281[sec], evaluation: 0.0000[sec]
2025-05-29 18:55:15,397 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:55:15,474 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/14000.ckpt
2025-05-29 18:55:15,475 - INFO - joeynmt.training - Example #0
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'per', 'far@@', 'lo', 'mostr@@', 'are', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 'ri@@', 'l@@', 'ev@@', 'are', 'che', 'la', 'for@@', 'ma', 'di', 'b@@', 'atter@@', 'io', 'che', 'la', 'b@@', 'att@@', 'u@@', 'ale', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'il', '4@@', '0', 'per', 'per', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'per', 'c@@', 'ento', 'per', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'po@@', 'ter', 'ri@@', 'dur@@', 're', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'po@@', 'ter@@', 'i.', '</s>']
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno per farlo mostrare queste due dimensioni per rilevare che la forma di batterio che la battuale per tre milioni di anni che per tre milioni di anni che per il 40 per per per il 40 per cento di 40 per per cento per il 40% per il 40 per cento di poter ridurre il 40% per il 40 per cento di poteri.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - Example #1
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'il', 'sistema', 'di', 'es@@', 'er@@', 'c@@', 'ito', 'la', 'st@@', 'am@@', 'p@@', 'a', 'questo', 'punto', 'di', 'vi@@', 'sta', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato il sistema di esercito la stampa questo punto di vista di questo problema del ghiaccio del ghiaccio.
2025-05-29 18:55:15,475 - INFO - joeynmt.training - Example #2
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:55:15,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ic@@', 'ica', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'ali', 'glob@@', 'ali', 'del', 'nostro', 'sistema', 'glob@@', 'ale.', '</s>']
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la climaticica di climaticali globali del nostro sistema globale.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - Example #3
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'stato', 'in', 'un', 'vent@@', 'ur@@', 'o', 'e', 'si', 'è', 's@@', 'post@@', 'at@@', 'a.', '</s>']
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Hypothesis: E' stato in un venturo e si è spostata.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - Example #4
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:55:15,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'è', 'una', 'di@@', 'st@@', 'anz@@', 'a,', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'in', '2@@', '5', 'anni', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:55:15,476 - INFO - joeynmt.training - 	Hypothesis: La prossima è una distanza, è una stampa è una stampa che è successo negli ultimi 25 anni in 25 anni è successo.
2025-05-29 18:55:27,911 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     2.047691, Batch Acc: 0.425194, Tokens per Sec:     5776, Lr: 0.000300
2025-05-29 18:55:41,101 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.907660, Batch Acc: 0.431909, Tokens per Sec:     5297, Lr: 0.000300
2025-05-29 18:55:54,914 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.967515, Batch Acc: 0.427639, Tokens per Sec:     5100, Lr: 0.000300
2025-05-29 18:56:07,809 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     1.863341, Batch Acc: 0.428468, Tokens per Sec:     5463, Lr: 0.000300
2025-05-29 18:56:21,383 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     1.871168, Batch Acc: 0.432785, Tokens per Sec:     5266, Lr: 0.000300
2025-05-29 18:56:21,383 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:57:26,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 64.7954[sec], evaluation: 0.0000[sec]
2025-05-29 18:57:26,187 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:57:26,280 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/14500.ckpt
2025-05-29 18:57:26,281 - INFO - joeynmt.training - Example #0
2025-05-29 18:57:26,281 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:57:26,281 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:57:26,281 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', "l'@@", 'anno', 'scor@@', 'so', 'di', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'le', 'ar@@', 'e@@', 'e', 'che', 'le', 'ar@@', 'e@@', 'e', 'che', 'le', 'sc@@', 'al@@', 'a', 'che', 'i', 'gi@@', 'ov@@', 'an@@', 'e', 'di', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'pr@@', 'ot@@', 'eg@@', 'g@@', 'ere', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Hypothesis: Lo scorso l'anno scorso di queste due volte per considerare che le aree che le aree che le scala che i giovane di 48 Stati Uniti per tre milioni di anni di proteggere il 40 per cento di 40 percento di 40 percento di 40 percento di cento di 40 percento di sottopo.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - Example #1
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'la', 'pr@@', 'em@@', 'i@@', 'zione', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'è', 'che', 'non', 'è', 'il', 'd@@', 'oc@@', 'um@@', 'ent@@', 'o.', '</s>']
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse la premizione di questo problema di questo problema di questo problema è che non è il documento.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - Example #2
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'c@@', 'at@@', 'tiv@@', 'ità', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la cattività di ghiaccio globale di climatica.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - Example #3
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'in@@', 'ver@@', 's@@', 'ato', 'in', 'in@@', 'ver@@', 's@@', 'o.', '</s>']
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - 	Hypothesis: Si tratta di inversato in inverso.
2025-05-29 18:57:26,282 - INFO - joeynmt.training - Example #4
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:57:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'la', 'pr@@', 'ossi@@', 'ma', 'tra@@', 'c@@', 'ci@@', 'a', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 18:57:26,283 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:57:26,283 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:57:26,283 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima prossima la prossima traccia è una cosa che è successo in 25 anni è successo.
2025-05-29 18:57:39,664 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.816312, Batch Acc: 0.436755, Tokens per Sec:     5387, Lr: 0.000300
2025-05-29 18:57:53,179 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     1.856679, Batch Acc: 0.433672, Tokens per Sec:     5346, Lr: 0.000300
2025-05-29 18:58:07,284 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.986824, Batch Acc: 0.433257, Tokens per Sec:     5136, Lr: 0.000300
2025-05-29 18:58:21,802 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     1.838982, Batch Acc: 0.430975, Tokens per Sec:     4871, Lr: 0.000300
2025-05-29 18:58:35,601 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     1.828098, Batch Acc: 0.434252, Tokens per Sec:     5209, Lr: 0.000300
2025-05-29 18:58:35,601 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 18:59:46,334 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.18, acc:   0.42, generation: 70.7264[sec], evaluation: 0.0000[sec]
2025-05-29 18:59:46,336 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 18:59:46,417 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/15000.ckpt
2025-05-29 18:59:46,418 - INFO - joeynmt.training - Example #0
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'mom@@', 'ento', 'di', 'questi', 'due', 'due', 'vol@@', 'te', 'di', 'di@@', 'mostr@@', 'are', 'che', 'la', 'di@@', 'mostr@@', 'a', 'che', 'la', 'car@@', 'ica', 'è', 'che', 'la', 'car@@', 'ica', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'che', 'gli', 'st@@', 'ati', 'sono', 'st@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'per', 'fare', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'cui', 'è', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Hypothesis: Nel momento di questi due due volte di dimostrare che la dimostra che la carica è che la carica di ghiacciaio che gli stati sono stati per tre milioni di anni che avevano per fare 40 per cento di 40 per cento di 40 per cento di 40 per cento di cui è il 40% dei sottopo.
2025-05-29 18:59:46,418 - INFO - joeynmt.training - Example #1
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 18:59:46,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'for@@', 'se', 'la', 'for@@', 'za', 'di', 'questa', 'es@@', 'peri@@', 'enza', 'di', 'questa', 'sp@@', 'eci@@', 'e,', 'questo', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 18:59:46,418 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è forse la forza di questa esperienza di questa specie, questo problema non è la distanza di questo problema del ghiaccio.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - Example #2
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 's@@', 'ens@@', 'o,', "l'@@", 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'è', 'il', 'c@@', 'li@@', 'mat@@', 'ico', 'è', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Hypothesis: In certo senso, l'Eiskappe è il climatico è il nostro sistema climatico globale.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - Example #3
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'sc@@', 'ar@@', 'ic@@', 'ato', 'in', 'vent@@', 'o', 'e', 'si', 'ri@@', 'es@@', 'ce', 'nel', 's@@', 'ett@@', 'o.', '</s>']
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Hypothesis: Lo scaricato in vento e si riesce nel setto.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - Example #4
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 18:59:46,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'stra@@', 'da', 'di', 'quello', 'che', 'succ@@', 'ede', 'in', 'ulti@@', 'mo', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 18:59:46,419 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima di dimostrarvi è una strada di quello che succede in ultimo 25 anni.
2025-05-29 19:00:00,274 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     2.025910, Batch Acc: 0.435432, Tokens per Sec:     5287, Lr: 0.000300
2025-05-29 19:00:13,915 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     1.866908, Batch Acc: 0.439588, Tokens per Sec:     5262, Lr: 0.000300
2025-05-29 19:00:27,980 - INFO - joeynmt.training - Epoch   4, Step:    17800, Batch Loss:     2.204181, Batch Acc: 0.436233, Tokens per Sec:     4939, Lr: 0.000300
2025-05-29 19:00:41,685 - INFO - joeynmt.training - Epoch   4, Step:    17900, Batch Loss:     1.988086, Batch Acc: 0.426788, Tokens per Sec:     5155, Lr: 0.000300
2025-05-29 19:00:55,687 - INFO - joeynmt.training - Epoch   4, Step:    18000, Batch Loss:     1.812991, Batch Acc: 0.440797, Tokens per Sec:     4997, Lr: 0.000300
2025-05-29 19:00:55,687 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:02:22,500 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.18, acc:   0.42, generation: 86.8062[sec], evaluation: 0.0000[sec]
2025-05-29 19:02:22,502 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:02:22,579 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/15500.ckpt
2025-05-29 19:02:22,579 - INFO - joeynmt.training - Example #0
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questa', 'è', 'la', 'di@@', 'sc@@', 'ut@@', 'a', 'per', 'con@@', 'si@@', 'der@@', 'are', 'il', 'f@@', 'ant@@', 'ast@@', 'ico', 'che', 'le', 'ar@@', 'e@@', 'e', 'che', 'le', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'i', 'di@@', 'rit@@', 'ti', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'con@@', 'temp@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'un', 'proc@@', 'esso', 'di', 's@@', 'f@@', 'um@@', 'o', 'per', 's@@', 'post@@', 'ar@@', 'l@@', 'o.', '</s>']
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questa è la discuta per considerare il fantastico che le aree che le ghiaccio per i diritti di ghiaccio per i tre milioni di anni per i contempi di 40 percento dei 40 percento di 40 percento di 40 percento di un processo di sfumo per spostarlo.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - Example #1
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'sp@@', 'eci@@', 'almente', 'la', 'di@@', 'st@@', 'anza', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza specialmente la distanza speciale non è la distanza che non è la distanza.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - Example #2
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la climatica è la climatica del nostro sistema climatico globale.
2025-05-29 19:02:22,580 - INFO - joeynmt.training - Example #3
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:02:22,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'stato', 'in', 'un', 'vent@@', 'ar@@', 'io', 'e', 'la', 'sua', 'in@@', 'ver@@', 'n@@', 'a', 'nel', 'm@@', 'are.', '</s>']
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Hypothesis: E' stato in un ventario e la sua inverna nel mare.
2025-05-29 19:02:22,581 - INFO - joeynmt.training - Example #4
2025-05-29 19:02:22,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:02:22,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:02:22,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ra', 'la', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ra', 'è', 'una', 'giorn@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'in', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:02:22,581 - INFO - joeynmt.training - 	Hypothesis: La prossima fra la prossima fra è una giornale che è successo in una cosa che è successo in 25 anni.
2025-05-29 19:02:35,052 - INFO - joeynmt.training - Epoch   4, Step:    18100, Batch Loss:     2.019870, Batch Acc: 0.437288, Tokens per Sec:     5810, Lr: 0.000300
2025-05-29 19:02:48,127 - INFO - joeynmt.training - Epoch   4, Step:    18200, Batch Loss:     1.756657, Batch Acc: 0.433986, Tokens per Sec:     5327, Lr: 0.000300
2025-05-29 19:03:00,975 - INFO - joeynmt.training - Epoch   4, Step:    18300, Batch Loss:     1.786575, Batch Acc: 0.440192, Tokens per Sec:     5666, Lr: 0.000300
2025-05-29 19:03:13,634 - INFO - joeynmt.training - Epoch   4, Step:    18400, Batch Loss:     2.016430, Batch Acc: 0.438449, Tokens per Sec:     5509, Lr: 0.000300
2025-05-29 19:03:27,296 - INFO - joeynmt.training - Epoch   4, Step:    18500, Batch Loss:     1.875553, Batch Acc: 0.437896, Tokens per Sec:     5337, Lr: 0.000300
2025-05-29 19:03:27,296 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:04:32,833 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.08, acc:   0.43, generation: 65.5302[sec], evaluation: 0.0000[sec]
2025-05-29 19:04:32,834 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:04:32,911 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/16000.ckpt
2025-05-29 19:04:32,913 - INFO - joeynmt.training - Example #0
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'anno', 'anno', 'anno', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 's@@', 'é', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'p@@', 'es@@', 'c@@', 'at@@', 'ori', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'che', 'per', 'i', 'di@@', 'rit@@', 'ti', 'di', '3@@', '0', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'per', '4@@', '8', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'otto', 'milioni', 'di', 'anni', 'di', 'anni@@', '.', '</s>']
2025-05-29 19:04:32,913 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:04:32,913 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:04:32,913 - INFO - joeynmt.training - 	Hypothesis: Nel anno anno anno mostrato queste due volte per sé che i considerano che i pescatori di Eiskappe, che per i diritti di 30 milioni di anni che avevano per 48 milioni di anni per il 40 per cento di 40 per cento di 40 per cento di 40 per cento di sotto milioni di anni di anni.
2025-05-29 19:04:32,913 - INFO - joeynmt.training - Example #1
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:04:32,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'sp@@', 'eci@@', 'fic@@', 'ato', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'è', 'mostr@@', 'ato.', '</s>']
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza specificato questo specifico non è la distanza che non è la distanza che è mostrato.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - Example #2
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la climatica è la climatica globale del nostro climatico.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - Example #3
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'ed@@', 'uto', 'nel', 'vent@@', 'o', 'e', 'si', 's@@', 'v@@', 'egli@@', 'ano', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Hypothesis: Si è seduto nel vento e si svegliano in estate in estate estate in estate sotto.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - Example #4
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:04:32,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'giorn@@', 'ata', 'di', 'una', 'giorn@@', 'ale', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:04:32,914 - INFO - joeynmt.training - 	Hypothesis: La prossima di dimostrarvi è una giornata di una giornale di quello che è successo negli ultimi 25 anni.
2025-05-29 19:04:46,080 - INFO - joeynmt.training - Epoch   4, Step:    18600, Batch Loss:     1.792799, Batch Acc: 0.439590, Tokens per Sec:     5332, Lr: 0.000300
2025-05-29 19:04:59,894 - INFO - joeynmt.training - Epoch   4, Step:    18700, Batch Loss:     1.695445, Batch Acc: 0.433639, Tokens per Sec:     5261, Lr: 0.000300
2025-05-29 19:05:13,731 - INFO - joeynmt.training - Epoch   4, Step:    18800, Batch Loss:     1.936471, Batch Acc: 0.435164, Tokens per Sec:     5152, Lr: 0.000300
2025-05-29 19:05:18,267 - INFO - joeynmt.training - Epoch   4: total training loss 9123.40
2025-05-29 19:05:18,267 - INFO - joeynmt.training - EPOCH 5
2025-05-29 19:05:27,511 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     2.062597, Batch Acc: 0.456604, Tokens per Sec:     5022, Lr: 0.000300
2025-05-29 19:05:41,472 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.870036, Batch Acc: 0.461258, Tokens per Sec:     5145, Lr: 0.000300
2025-05-29 19:05:41,473 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:06:46,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.99, acc:   0.43, generation: 64.8151[sec], evaluation: 0.0000[sec]
2025-05-29 19:06:46,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:06:46,373 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/16500.ckpt
2025-05-29 19:06:46,374 - INFO - joeynmt.training - Example #0
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'ver@@', 's@@', 'are', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'o', 'che', "l'@@", 'ar@@', 'ia', 'in@@', 'cu@@', 'ri@@', 'os@@', 'a', 'che', 'i', 'gi@@', 'ov@@', 'an@@', 'i,', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'av@@', 'evano', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 'li@@', 'ber@@', 'i.', '</s>']
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno ho mostrato queste due volte per conversare che i ghiaccio che l'aria incuriosa che i giovani, che per tre milioni di anni che avevano per i tre milioni di anni per il 40% dei liberi.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - Example #1
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'la', 'ri@@', 'vol@@', 'u@@', 'zione', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forse la rivoluzione di questo speciale non è la distanza che non è la distanza non la distanza di ghiaccio.
2025-05-29 19:06:46,374 - INFO - joeynmt.training - Example #2
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:06:46,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la causa di ghiaccio di ghiaccio globale del nostro climatico.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - Example #3
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'in@@', 'ver@@', 's@@', 'are', 'in', 'in@@', 'ver@@', 's@@', 'o.', '</s>']
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Hypothesis: Si tratta di inversare in inverso.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - Example #4
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:06:46,375 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'di@@', 'mostr@@', 'a', 'cosa', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'cosa', 'è', 'succ@@', 'esso', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:06:46,375 - INFO - joeynmt.training - 	Hypothesis: La prossima di dimostrarvi è una dimostra cosa che vi mostrerò cosa è successo in 25 anni.
2025-05-29 19:06:59,839 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     2.040235, Batch Acc: 0.456332, Tokens per Sec:     5293, Lr: 0.000300
2025-05-29 19:07:13,211 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.811095, Batch Acc: 0.454461, Tokens per Sec:     5293, Lr: 0.000300
2025-05-29 19:07:27,019 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.940074, Batch Acc: 0.449988, Tokens per Sec:     5104, Lr: 0.000300
2025-05-29 19:07:40,818 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.925293, Batch Acc: 0.451974, Tokens per Sec:     5022, Lr: 0.000300
2025-05-29 19:07:53,853 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.969217, Batch Acc: 0.453034, Tokens per Sec:     5364, Lr: 0.000300
2025-05-29 19:07:53,853 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:09:08,661 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.03, acc:   0.43, generation: 74.8008[sec], evaluation: 0.0000[sec]
2025-05-29 19:09:08,736 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/17000.ckpt
2025-05-29 19:09:08,738 - INFO - joeynmt.training - Example #0
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['A@@', 'v@@', 'evo', 'mostr@@', 'are', 'questo', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'questo', 'è', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'b@@', 'agli@@', 'are', 'il', '4@@', '0', 'milioni', 'di', 'anni', 'che', 'la', 'ra@@', 'gi@@', 'one', 'per', 'cui', 'i', 'sono', 'st@@', 'ati', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'vol@@', 'um@@', 'i', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'v@@', 'egli@@', 'er@@', 'e.', '</s>']
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Hypothesis: Avevo mostrare questo due volte per ridurre questo è il 40 per cento di sbagliare il 40 milioni di anni che la ragione per cui i sono stati tre milioni di anni per il 40 per cento di 40 per cento di 40 percento di 40 percento di 40 percento di 40 percento di 40 per cento di 40 percento di volumi per il 40 percento di svegliere.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - Example #1
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'è', 'il', 'di@@', 'st@@', 'im@@', 'ol@@', 'ato', 'del', 'li@@', 'vello', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forse la distanza di questo specifico di questo specifico è il distimolato del livello di ghiaccio.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - Example #2
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:09:08,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'ia', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la cattiva è la causa di climaticia globale del nostro sistema climatico.
2025-05-29 19:09:08,738 - INFO - joeynmt.training - Example #3
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'una', 's@@', 'f@@', 'era', 'in', 'un', 'in@@', 'ver@@', 'n@@', 'o.', '</s>']
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Hypothesis: E' una sfera in un inverno.
2025-05-29 19:09:08,739 - INFO - joeynmt.training - Example #4
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:09:08,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'temp@@', 'or@@', 'ale', 'temp@@', 'or@@', 'ale', 'di', 'quello', 'che', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:09:08,739 - INFO - joeynmt.training - 	Hypothesis: La prossima di dimostrarvi è una temporale temporale di quello che è successo.
2025-05-29 19:09:22,389 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.941613, Batch Acc: 0.452848, Tokens per Sec:     5170, Lr: 0.000300
2025-05-29 19:09:35,591 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.893440, Batch Acc: 0.452870, Tokens per Sec:     5342, Lr: 0.000300
2025-05-29 19:09:48,911 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.773943, Batch Acc: 0.454183, Tokens per Sec:     5335, Lr: 0.000300
2025-05-29 19:10:02,887 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.939715, Batch Acc: 0.450773, Tokens per Sec:     5094, Lr: 0.000300
2025-05-29 19:10:16,381 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.819265, Batch Acc: 0.447435, Tokens per Sec:     5249, Lr: 0.000300
2025-05-29 19:10:16,381 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:11:19,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.43, generation: 63.1829[sec], evaluation: 0.0000[sec]
2025-05-29 19:11:19,572 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:11:19,648 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/17500.ckpt
2025-05-29 19:11:19,649 - INFO - joeynmt.training - Example #0
2025-05-29 19:11:19,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ap@@', 'ete,', "l'@@", 'anno', 'scor@@', 'so', 'anno', 'questi', 'due', 'vol@@', 'te', 'per', 'mostr@@', 'are', 'che', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'sc@@', 'ap@@', 'p@@', 'a', 'che', 'la', 'c@@', 'ap@@', 'i', 'che', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'vol@@', 't@@', 'a.', '</s>']
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Hypothesis: Sapete, l'anno scorso anno questi due volte per mostrare che la causa di ghiaccio che la scappa che la capi che per i tre milioni di anni che hanno avuto 40 per cento di 40 percento di 40 per cento di 40 per cento di 40 percento di svolta.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - Example #1
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'la', 'sc@@', 'ar@@', 'ica', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'ale', 'non', 'la', 'di@@', 'sc@@', 'us@@', 'a', 'il', 'di@@', 'st@@', 'in@@', 'to', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forse la scarica speciale di questo problema speciale non la discusa il distinto del ghiaccio.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - Example #2
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'della', 'nostra', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la cattiva di ghiaccio globale della nostra clima.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - Example #3
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:11:19,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'ur@@', 'o', 'e', 's@@', 'an@@', 'o,', 'e', 'si', 's@@', 'post@@', 'ano', 'nel', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un venturo e sano, e si spostano nel estate.
2025-05-29 19:11:19,650 - INFO - joeynmt.training - Example #4
2025-05-29 19:11:19,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:11:19,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:11:19,651 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a', 'la', 'di@@', 'men@@', 'sione', 'che', 'vi', 'mostr@@', 'a', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'che', 'succ@@', 'essi@@', 'va', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:11:19,651 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:11:19,651 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:11:19,651 - INFO - joeynmt.training - 	Hypothesis: La prossima dia la dimensione che vi mostra è una stampa che successiva negli ultimi 25 anni.
2025-05-29 19:11:33,328 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.892637, Batch Acc: 0.454554, Tokens per Sec:     5165, Lr: 0.000300
2025-05-29 19:11:47,528 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.809288, Batch Acc: 0.453035, Tokens per Sec:     4967, Lr: 0.000300
2025-05-29 19:12:01,836 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.674064, Batch Acc: 0.453535, Tokens per Sec:     4892, Lr: 0.000300
2025-05-29 19:12:15,633 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.791886, Batch Acc: 0.454998, Tokens per Sec:     5225, Lr: 0.000300
2025-05-29 19:12:29,804 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.897077, Batch Acc: 0.449027, Tokens per Sec:     4970, Lr: 0.000300
2025-05-29 19:12:29,804 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:13:35,649 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.44, generation: 65.8387[sec], evaluation: 0.0000[sec]
2025-05-29 19:13:35,650 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:13:35,727 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/18000.ckpt
2025-05-29 19:13:35,727 - INFO - joeynmt.training - Example #0
2025-05-29 19:13:35,727 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:13:35,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:13:35,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'ver@@', 's@@', 'are', 'che', 'la', 'ver@@', 'a', 'con@@', 'si@@', 'der@@', 'are', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'gi@@', 'ap@@', 'pon@@', 'e,', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'la', 'gi@@', 'u@@', 'di@@', 't@@', 'à', 'di', '4@@', '0', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'alt@@', 'o.', '</s>']
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno ho mostrato queste due volte per conversare che la vera considerare il ghiaccio che la giappone, per tre milioni di anni che la giudità di 40 milioni di anni per il 40 per cento di 40 percento di 40 percento di 40 percento di salto.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - Example #1
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'una', 'cosa', 'che', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pr@@', 'ec@@', 'ed@@', 'ente', 'questo', 'sp@@', 'eci@@', 'ale', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a,', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Hypothesis: Ma non è una cosa che non è abbastanza precedente questo speciale è la distanza, non è la distanza.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - Example #2
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'della', 'nostra', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di ghiaccio globale della nostra clima.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - Example #3
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'la', 'p@@', 'au@@', 'ra', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - 	Hypothesis: Si tratta di in inverno, e la paura in estate in estate in estate in estate sotto.
2025-05-29 19:13:35,728 - INFO - joeynmt.training - Example #4
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:13:35,728 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ra', 'la', 'pr@@', 'ossi@@', 'ma', 'f@@', 'ra', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'cosa', 'succ@@', 'ede', 'in', 'ulti@@', 'ma', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:13:35,729 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:13:35,729 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:13:35,729 - INFO - joeynmt.training - 	Hypothesis: La prossima fra la prossima fra è una stampa cosa succede in ultima 25 anni.
2025-05-29 19:13:49,438 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.840741, Batch Acc: 0.446009, Tokens per Sec:     5217, Lr: 0.000300
2025-05-29 19:14:02,692 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.806806, Batch Acc: 0.453365, Tokens per Sec:     5439, Lr: 0.000300
2025-05-29 19:14:16,261 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.982782, Batch Acc: 0.452794, Tokens per Sec:     5217, Lr: 0.000300
2025-05-29 19:14:29,943 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.756348, Batch Acc: 0.459961, Tokens per Sec:     5243, Lr: 0.000300
2025-05-29 19:14:43,847 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.834385, Batch Acc: 0.454969, Tokens per Sec:     5019, Lr: 0.000300
2025-05-29 19:14:43,847 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:16:00,629 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.44, generation: 76.7747[sec], evaluation: 0.0000[sec]
2025-05-29 19:16:00,630 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:16:00,706 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/18500.ckpt
2025-05-29 19:16:00,707 - INFO - joeynmt.training - Example #0
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'questi', 'due', 'vol@@', 'te', 'sono', 'questi', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'pol@@', 'i@@', 'zi@@', 'a', 'che', 'i', 'col@@', 'p@@', 'is@@', 'c@@', 'e,', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'i', 'gi@@', 'u@@', 'di@@', 'ti', 'di', '4@@', '0', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'cent@@', 'o.', '</s>']
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno questi due volte sono questi due volte per ridurre il ghiaccio che la polizia che i colpisce, per tre milioni di anni che i giuditi di 40 milioni di anni per il 40 per cento di 40 percento.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - Example #1
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'la', 'for@@', 'za', 'di', 'una', 'cosa', 'che', 'non', 'è', 'la', 'cosa', 'sp@@', 'eci@@', 'almente', 'la', 'cosa', 'sp@@', 'eci@@', 'almente', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato la forza di una cosa che non è la cosa specialmente la cosa specialmente non è la distanza non è la distanza non è la distanza del ghiaccio.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - Example #2
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'at@@', 'tiv@@', 'ità', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la cattività di ghiaccio del nostro sistema di climatico globale.
2025-05-29 19:16:00,708 - INFO - joeynmt.training - Example #3
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:16:00,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'ente', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'r@@', 'ot@@', 'or@@', 'ia', 'e', 'r@@', 'ur@@', 'g@@', 'a.', '</s>']
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Hypothesis: Si sente in inverno, e rotoria e rurga.
2025-05-29 19:16:00,709 - INFO - joeynmt.training - Example #4
2025-05-29 19:16:00,709 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:16:00,709 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:16:00,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'st@@', 'im@@', 'a', 'di', 'una', 'st@@', 'im@@', 'a', 'cosa', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:16:00,709 - INFO - joeynmt.training - 	Hypothesis: La prossima di dimostrarvi è una stima di una stima cosa succede negli ultimi 25 anni.
2025-05-29 19:16:14,388 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.888075, Batch Acc: 0.454810, Tokens per Sec:     4993, Lr: 0.000300
2025-05-29 19:16:29,199 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.794947, Batch Acc: 0.451911, Tokens per Sec:     4884, Lr: 0.000300
2025-05-29 19:16:42,531 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.741509, Batch Acc: 0.454612, Tokens per Sec:     5242, Lr: 0.000300
2025-05-29 19:16:56,064 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.921749, Batch Acc: 0.457429, Tokens per Sec:     5361, Lr: 0.000300
2025-05-29 19:17:09,971 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.847023, Batch Acc: 0.452734, Tokens per Sec:     5104, Lr: 0.000300
2025-05-29 19:17:09,971 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:18:21,984 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.84, acc:   0.44, generation: 72.0064[sec], evaluation: 0.0000[sec]
2025-05-29 19:18:21,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:18:22,062 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/19500.ckpt
2025-05-29 19:18:22,063 - INFO - joeynmt.training - Example #0
2025-05-29 19:18:22,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:18:22,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:18:22,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'vol@@', 'te', 'sono', 'st@@', 'ati', 'per', 'in@@', 'cor@@', 'aggi@@', 'are', 'che', 'le', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'le', 'ra@@', 'gion@@', 'i', 'per', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'cent@@', 'o.', '</s>']
2025-05-29 19:18:22,063 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno ho mostrato queste due due volte sono stati per incoraggiare che le ghiacciaio per tre milioni di anni che le ragioni per tre milioni di anni, per tre milioni di anni, per tre milioni di anni, per 40 percento di 40 percento di 40 percento.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - Example #1
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'tun@@', 'ato', 'da', 'abb@@', 'ast@@', 'anza', 'sp@@', 'eci@@', 'fic@@', 'a,', 'non', 'è', 'la', 'cosa', 'sp@@', 'eci@@', 'fic@@', 'a,', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'di@@', 'st@@', 'a.', '</s>']
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortunato da abbastanza specifica, non è la cosa specifica, non è la distanza è la distanza del dista.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - Example #2
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'at@@', 'tiv@@', 'ità', 'di', 'E@@', 'k@@', 'ap@@', 'p@@', 'e', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cattività di Ekappe del nostro sistema climatico.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - Example #3
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'stato', 'in', 'vent@@', 'ur@@', 'o', 'e', 's@@', 'otto', 'il', 'vent@@', 'o.', '</s>']
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - 	Hypothesis: E' stato in venturo e sotto il vento.
2025-05-29 19:18:22,064 - INFO - joeynmt.training - Example #4
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:18:22,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'st@@', 'anz@@', 'a,', 'è', 'una', 'st@@', 'anza', 'di', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:18:22,065 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:18:22,065 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:18:22,065 - INFO - joeynmt.training - 	Hypothesis: La prossima dia che vi mostrerò è una stanza, è una stanza di successo negli ultimi 25 anni.
2025-05-29 19:18:35,824 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.901676, Batch Acc: 0.453900, Tokens per Sec:     5218, Lr: 0.000300
2025-05-29 19:18:49,549 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.907957, Batch Acc: 0.450574, Tokens per Sec:     5187, Lr: 0.000300
2025-05-29 19:19:03,132 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     1.766904, Batch Acc: 0.459772, Tokens per Sec:     5115, Lr: 0.000300
2025-05-29 19:19:16,840 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     1.760217, Batch Acc: 0.457241, Tokens per Sec:     5398, Lr: 0.000300
2025-05-29 19:19:30,636 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     1.798508, Batch Acc: 0.452852, Tokens per Sec:     4945, Lr: 0.000300
2025-05-29 19:19:30,636 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:20:42,513 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.80, acc:   0.44, generation: 71.8694[sec], evaluation: 0.0000[sec]
2025-05-29 19:20:42,514 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:20:42,590 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/19000.ckpt
2025-05-29 19:20:42,591 - INFO - joeynmt.training - Example #0
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'rit@@', 'ti', 'di', 'con@@', 'ver@@', 's@@', 'are', 'che', 'la', 'c@@', 'at@@', 'tiv@@', 'ità', 'ar@@', 'e@@', 'a', 'che', 'il', '4@@', '0', 'milioni', 'di', 'anni', 'che', 'il', '4@@', '0@@', '%', 'dei', 'mo@@', 'di', 'per', 'cui', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '8@@', '%', 'di', 'questi', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'più', 'di', 'c@@', 'ento', 'di', 'questo', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questo', 'è', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'cui', 'sono', 'st@@', 'ati', 'in', 'questo', 'mom@@', 'ent@@', 'o.', '</s>']
2025-05-29 19:20:42,591 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:20:42,591 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:20:42,591 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno ho mostrato questi due diritti di conversare che la cattività area che il 40 milioni di anni che il 40% dei modi per cui il 40 per cento di 48% di questi 40 per cento di 40 per cento di cento di cento di cento di più di cento di questo 40 per cento di questo è il 40 per cento di cento di cui sono stati in questo momento.
2025-05-29 19:20:42,591 - INFO - joeynmt.training - Example #1
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:20:42,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'il', 'p@@', 'etr@@', 'ol@@', 'io', 'non', 'è', 'il', 'problem@@', 'a', 'part@@', 'icol@@', 'are', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'sp@@', 'eci@@', 'ali', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'in@@', 'a.', '</s>']
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato il petrolio non è il problema particolare di questo particolare problemi speciali non è la distanza che non è la distina.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - Example #2
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la climatica è il cuore del nostro sistema climatico globale del nostro sistema climatico.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - Example #3
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'in', 'un', 'vent@@', 'o', 'in', 'vent@@', 'o', 'e', 's@@', 'an@@', 'gu@@', 'e.', '</s>']
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Hypothesis: Si è in un vento in vento e sangue.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - Example #4
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:20:42,592 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'di@@', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di', 'temp@@', 'est@@', 'a', 'di', 'cui', 'vi', 'mostr@@', 'er@@', 'ò', 'cosa', 'succ@@', 'ede', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:20:42,592 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dimostro che vi mostrerò è una di tempesta di cui vi mostrerò cosa succede in 25 anni.
2025-05-29 19:20:55,761 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     2.000229, Batch Acc: 0.451469, Tokens per Sec:     5217, Lr: 0.000300
2025-05-29 19:21:09,088 - INFO - joeynmt.training - Epoch   5, Step:    22200, Batch Loss:     1.810443, Batch Acc: 0.462321, Tokens per Sec:     5400, Lr: 0.000300
2025-05-29 19:21:23,293 - INFO - joeynmt.training - Epoch   5, Step:    22300, Batch Loss:     1.744558, Batch Acc: 0.451526, Tokens per Sec:     4894, Lr: 0.000300
2025-05-29 19:21:37,879 - INFO - joeynmt.training - Epoch   5, Step:    22400, Batch Loss:     1.738996, Batch Acc: 0.451671, Tokens per Sec:     4865, Lr: 0.000300
2025-05-29 19:21:52,009 - INFO - joeynmt.training - Epoch   5, Step:    22500, Batch Loss:     1.881153, Batch Acc: 0.453145, Tokens per Sec:     4962, Lr: 0.000300
2025-05-29 19:21:52,010 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:23:17,577 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.77, acc:   0.44, generation: 85.5593[sec], evaluation: 0.0000[sec]
2025-05-29 19:23:17,578 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:23:17,656 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/20000.ckpt
2025-05-29 19:23:17,657 - INFO - joeynmt.training - Example #0
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'si@@', 'der@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'ra@@', 'gi@@', 'one', 'per', 'cui', 'i', 'sono', 'st@@', 'ati', 'in', 'gra@@', 'do', 'di', 's@@', 'ott@@', 'o@@', '-@@', '4@@', '8@@', '%', 'dei', 'dei', 'dei', 'mo@@', 'di', 'per', 'cui', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 's@@', 'otto', 'il', '4@@', '0@@', '%', 'di', 's@@', 'post@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'di@@', 'men@@', 'sion@@', 'i', 'di', 's@@', 'otto', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'cui', 'sono', 'st@@', 'ati', 'in', 'questo', 'mom@@', 'ento', 'per', 'cui', 'il', '4@@', '0@@', '%', 'dei', 'mo@@', 'ti@@', 'vi', 'per', 'cui', 'il', '4@@', '0', 'per@@', 'c@@', 'ento']
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due volte ho mostrato queste due volte per considerare il 40 percento di ghiaccio che la ragione per cui i sono stati in grado di sotto-48% dei dei dei modi per cui il 40 percento di sotto il 40% di spostare il 40 percento di dimensioni di sotto il 40 percento di cui sono stati in questo momento per cui il 40% dei motivi per cui il 40 percento
2025-05-29 19:23:17,657 - INFO - joeynmt.training - Example #1
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'il', 'p@@', 'etr@@', 'ol@@', 'io', 'non', 'è', 'il', 'pr@@', 'inci@@', 'p@@', 'ale', 'che', 'questo', 'sp@@', 'eci@@', 'ale', 'è', 'il', 'di@@', 'scor@@', 'so', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'è', 'il', 'di@@', 'st@@', 'in@@', 'o.', '</s>']
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:23:17,657 - INFO - joeynmt.training - 	Hypothesis: Ma non è il petrolio non è il principale che questo speciale è il discorso che non è la distanza che non è la distanza che è il distino.
2025-05-29 19:23:17,657 - INFO - joeynmt.training - Example #2
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:23:17,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'del', 'nostro', 'sistema', 'ar@@', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia del nostro sistema arghiaccio globale del nostro sistema climatico globale.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - Example #3
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'sc@@', 'ar@@', 'd@@', 'ò', 'in', 'vent@@', 'o', 'e', 'r@@', 'om@@', 'per@@', 'e', 'in', 'una', 's@@', 'ort@@', 'a', 'di', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Hypothesis: Lo scardò in vento e rompere in una sorta di estate.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - Example #4
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:23:17,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'volta', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ata', 'di', 'tempo', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:23:17,658 - INFO - joeynmt.training - 	Hypothesis: La prossima volta che vi mostro è una giornata di tempo è successo negli ultimi 25 anni.
2025-05-29 19:23:30,509 - INFO - joeynmt.training - Epoch   5, Step:    22600, Batch Loss:     1.842293, Batch Acc: 0.451399, Tokens per Sec:     5501, Lr: 0.000300
2025-05-29 19:23:43,301 - INFO - joeynmt.training - Epoch   5, Step:    22700, Batch Loss:     1.862266, Batch Acc: 0.456087, Tokens per Sec:     5579, Lr: 0.000300
2025-05-29 19:23:56,191 - INFO - joeynmt.training - Epoch   5, Step:    22800, Batch Loss:     1.833311, Batch Acc: 0.452426, Tokens per Sec:     5625, Lr: 0.000300
2025-05-29 19:24:09,122 - INFO - joeynmt.training - Epoch   5, Step:    22900, Batch Loss:     1.942342, Batch Acc: 0.457535, Tokens per Sec:     5465, Lr: 0.000300
2025-05-29 19:24:21,998 - INFO - joeynmt.training - Epoch   5, Step:    23000, Batch Loss:     1.941164, Batch Acc: 0.455020, Tokens per Sec:     5554, Lr: 0.000300
2025-05-29 19:24:21,999 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:25:20,421 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.70, acc:   0.44, generation: 58.4155[sec], evaluation: 0.0000[sec]
2025-05-29 19:25:20,422 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:25:20,497 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/20500.ckpt
2025-05-29 19:25:20,499 - INFO - joeynmt.training - Example #0
2025-05-29 19:25:20,499 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:25:20,499 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:25:20,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'le', 'di@@', 'mostr@@', 'a', 'che', 'la', 'di@@', 'sc@@', 'us@@', 'sione', 'che', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'che', 'la', 'ra@@', 'gi@@', 'one', 'per', 'cui', 'i', 'di@@', 'scor@@', 'si', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '8@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'per', 'il', '4@@', '0@@', '%', 'dei', 'di@@', 'rit@@', 'ti', 'di', 'di@@', 'mostr@@', 'are', 'che', 'il', '4@@', '0@@', '%', 'dei', 'di@@', 'rit@@', 'ti', 'di', 's@@', 'ac@@', 'r@@', 'i', 'di', 'p@@', 'es@@', 'o', 'di', 's@@', 'otto', 'milioni', 'di', 'anni', 'per', 'la']
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due volte per ridurre le dimostra che la discussione che la cattiva che la ragione per cui i discorsi per tre milioni di anni per i 480 per cento di 480 per cento di 480 per cento di 40 per cento di cento di discussioni per il 40% dei diritti di dimostrare che il 40% dei diritti di sacri di peso di sotto milioni di anni per la
2025-05-29 19:25:20,500 - INFO - joeynmt.training - Example #1
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'questa', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza forse questa speciale non è la distanza che non è la distanza che non è la distanza.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - Example #2
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'della', 'g@@', 'hi@@', 'acci@@', 'a', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia della ghiaccia del nostro sistema climatico.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - Example #3
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:25:20,500 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'en@@', 'a', 'in', 'vent@@', 'o', 'e', 'la', 'p@@', 'elle', 'in', 'est@@', 'at@@', 'a.', '</s>']
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - 	Hypothesis: Si scena in vento e la pelle in estata.
2025-05-29 19:25:20,500 - INFO - joeynmt.training - Example #4
2025-05-29 19:25:20,501 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:25:20,501 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:25:20,501 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'volta', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ale', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'cosa', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:25:20,501 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:25:20,501 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:25:20,501 - INFO - joeynmt.training - 	Hypothesis: La prossima volta che vi mostro è una giornale che vi mostrerò cosa succede negli ultimi 25 anni.
2025-05-29 19:25:33,621 - INFO - joeynmt.training - Epoch   5, Step:    23100, Batch Loss:     1.951216, Batch Acc: 0.455076, Tokens per Sec:     5475, Lr: 0.000300
2025-05-29 19:25:46,886 - INFO - joeynmt.training - Epoch   5, Step:    23200, Batch Loss:     1.781093, Batch Acc: 0.456832, Tokens per Sec:     5537, Lr: 0.000300
2025-05-29 19:26:00,427 - INFO - joeynmt.training - Epoch   5, Step:    23300, Batch Loss:     1.769873, Batch Acc: 0.456515, Tokens per Sec:     5407, Lr: 0.000300
2025-05-29 19:26:13,593 - INFO - joeynmt.training - Epoch   5, Step:    23400, Batch Loss:     1.838249, Batch Acc: 0.452744, Tokens per Sec:     5320, Lr: 0.000300
2025-05-29 19:26:26,822 - INFO - joeynmt.training - Epoch   5, Step:    23500, Batch Loss:     1.697852, Batch Acc: 0.452294, Tokens per Sec:     5381, Lr: 0.000300
2025-05-29 19:26:26,823 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:27:29,537 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.44, generation: 62.7065[sec], evaluation: 0.0000[sec]
2025-05-29 19:27:29,538 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:27:29,612 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/21000.ckpt
2025-05-29 19:27:29,614 - INFO - joeynmt.training - Example #0
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', "l'@@", 'anno', 'scor@@', 'so', 'di', 'queste', 'due', 'due', 'vol@@', 'te', 'le', 'due', 'vol@@', 'te', 'per', 'con@@', 'di@@', 'zioni', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i@@', 'che', 'che', 'le', 'g@@', 'hi@@', 'acci@@', 'ate', 'che', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'questi', 'g@@', 'hi@@', 'acci@@', 'i', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'p@@', 'es@@', 'c@@', 'e.', '</s>']
2025-05-29 19:27:29,614 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:27:29,614 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:27:29,614 - INFO - joeynmt.training - 	Hypothesis: E l'anno scorso di queste due due volte le due volte per condizioni argomentiche che le ghiacciate che le dimensioni di questi ghiaccii per tre milioni di anni per il 40 per cento di 40 per cento di 40 percento di 40 percento per il 40 percento di pesce.
2025-05-29 19:27:29,614 - INFO - joeynmt.training - Example #1
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:27:29,614 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'più', 'for@@', 'te', 'la', 'for@@', 't@@', 'una', 'di', 'di@@', 'st@@', 'anz@@', 'a,', 'perché', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a,', 'perché', 'non', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è più forte la fortuna di distanza, perché non è la distanza, perché non mostra la distanza.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - Example #2
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ent@@', 'ico', 'e', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore argomentico e il cuore globale del nostro sistema climatico.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - Example #3
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'una', 's@@', 'ort@@', 'a', 'di', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'la', 'di@@', 'et@@', 'a', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Hypothesis: E' una sorta di inverno, e la dieta sotto.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - Example #4
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:27:29,615 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'f@@', 'era', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'una', 'giorn@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:27:29,615 - INFO - joeynmt.training - 	Hypothesis: La prossima sfera che vi mostro è una divisione di una giornale che è successo negli ultimi 25 anni 25 anni.
2025-05-29 19:27:37,353 - INFO - joeynmt.training - Epoch   5: total training loss 8766.47
2025-05-29 19:27:37,354 - INFO - joeynmt.training - EPOCH 6
2025-05-29 19:27:42,477 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.699845, Batch Acc: 0.473768, Tokens per Sec:     5381, Lr: 0.000300
2025-05-29 19:27:56,052 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.780233, Batch Acc: 0.474188, Tokens per Sec:     5233, Lr: 0.000300
2025-05-29 19:28:09,233 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.837059, Batch Acc: 0.477370, Tokens per Sec:     5628, Lr: 0.000300
2025-05-29 19:28:22,460 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.908672, Batch Acc: 0.474202, Tokens per Sec:     5269, Lr: 0.000300
2025-05-29 19:28:35,872 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.484062, Batch Acc: 0.469983, Tokens per Sec:     5294, Lr: 0.000300
2025-05-29 19:28:35,872 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:29:40,540 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.44, generation: 64.6612[sec], evaluation: 0.0000[sec]
2025-05-29 19:29:40,616 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/21500.ckpt
2025-05-29 19:29:40,618 - INFO - joeynmt.training - Example #0
2025-05-29 19:29:40,618 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:29:40,618 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:29:40,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'mom@@', 'ento', 'in', 'cui', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'che', 'mostr@@', 'o', 'per', 'ri@@', 'dur@@', 're', 'i', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'questi', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'che', 'si', 'sono', 'st@@', 'ati', 'in', 'cui', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'pi@@', 'utt@@', 'o@@', 'sto', 't@@', 'anto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'anni', 'di', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Hypothesis: Nel momento in cui ho mostrato queste due volte che mostro per ridurre i ghiaccio che la ghiacciaio di questi ghiacciaio che si sono stati in cui il 40 per cento di tre milioni di anni per il 40 per cento di piuttosto tanto per tre milioni di anni di anni di anni di sottopo.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - Example #1
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'ale', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza forte di questo problema speciale che non è la distanza che non è la distanza che mostra la distanza del ghiaccio.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - Example #2
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'il', 'sen@@', 'so', "dell'@@", 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è il senso dell'Eiskappe del nostro sistema climatico.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - Example #3
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'em@@', 'br@@', 'a', 'in', 'vent@@', 'o', 'e', 'si', 's@@', 'alt@@', 'ano', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - 	Hypothesis: Sembra in vento e si saltano in estate.
2025-05-29 19:29:40,619 - INFO - joeynmt.training - Example #4
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:29:40,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'pr@@', 'ossi@@', 'ma', 'di', 'di@@', 'mostr@@', 'are', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'di', 'una', 'giorn@@', 'ale', 'che', 'succ@@', 'e@@', 'de@@', 'va', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:29:40,620 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:29:40,620 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:29:40,620 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima di dimostrare è una stampa di una giornale che succedeva in 25 anni.
2025-05-29 19:29:53,892 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.715400, Batch Acc: 0.468659, Tokens per Sec:     5474, Lr: 0.000300
2025-05-29 19:30:06,930 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.791563, Batch Acc: 0.474845, Tokens per Sec:     5344, Lr: 0.000300
2025-05-29 19:30:20,553 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.757582, Batch Acc: 0.467722, Tokens per Sec:     5272, Lr: 0.000300
2025-05-29 19:30:34,291 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.867697, Batch Acc: 0.468495, Tokens per Sec:     5034, Lr: 0.000300
2025-05-29 19:30:47,746 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.741692, Batch Acc: 0.470257, Tokens per Sec:     5173, Lr: 0.000300
2025-05-29 19:30:47,746 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:31:43,372 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.44, generation: 55.6185[sec], evaluation: 0.0000[sec]
2025-05-29 19:31:43,374 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:31:43,460 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/22000.ckpt
2025-05-29 19:31:43,464 - INFO - joeynmt.training - Example #0
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'vol@@', 'te', 'per', 'con@@', 'di@@', 'zioni', 'po@@', 'ver@@', 'i', 'che', 'la', 'p@@', 'au@@', 'ra', 'che', 'la', 'p@@', 'au@@', 'ra', 'di', 'p@@', 'es@@', 'c@@', 'a,', 'che', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'ha', 'fatto', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '3@@', '0', 'per@@', 'c@@', 'ento', 'dei', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'su@@', 'oi', 'di@@', 'sp@@', 'oni@@', 'bi@@', 'li', 'per', 'i', 'loro', 'f@@', 're@@', 'qu@@', 'ent@@', 'i.', '</s>']
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Hypothesis: Nel anno scorso che ho mostrato questi due volte per condizioni poveri che la paura che la paura di pesca, che per i tre milioni di anni che ha fatto per i 40 per cento dei tre milioni di anni per il 40 per cento dei 40 percento di 40 percento di 30 percento dei tre milioni di anni per il 40 per cento dei suoi disponibili per i loro frequenti.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - Example #1
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:31:43,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'p@@', 'etr@@', 'ol@@', 'io', 'la', 'sua', 'n@@', 'as@@', 'cit@@', 'a', 'di', 'questo', 'problem@@', 'a', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'quest@@', 'o.', '</s>']
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato petrolio la sua nascita di questo problema particolare problemi di questo problema non è la distanza di questo.
2025-05-29 19:31:43,464 - INFO - joeynmt.training - Example #2
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'car@@', 'ica', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cattiva carica di Eiskappe il nostro sistema climatico globale.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - Example #3
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['St@@', 'anno', 'sc@@', 'el@@', 'to', 'nel', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Hypothesis: Stanno scelto nel vento e sotto.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - Example #4
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:31:43,465 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'ser@@', 'ie', 'di', 'pr@@', 'ossi@@', 'mo', '2@@', '5', 'anni', 'è', 'una', 'giorn@@', 'ale', 'di', 'temp@@', 'or@@', 'ale', 'che', 'succ@@', 'e@@', 'de.', '</s>']
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:31:43,465 - INFO - joeynmt.training - 	Hypothesis: La prossima serie di prossimo 25 anni è una giornale di temporale che succede.
2025-05-29 19:31:57,046 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.815866, Batch Acc: 0.470676, Tokens per Sec:     5278, Lr: 0.000300
2025-05-29 19:32:10,308 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.761879, Batch Acc: 0.470501, Tokens per Sec:     5242, Lr: 0.000300
2025-05-29 19:32:23,543 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.719576, Batch Acc: 0.469680, Tokens per Sec:     5614, Lr: 0.000300
2025-05-29 19:32:36,711 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.740739, Batch Acc: 0.468419, Tokens per Sec:     5388, Lr: 0.000300
2025-05-29 19:32:50,521 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.823985, Batch Acc: 0.470600, Tokens per Sec:     5165, Lr: 0.000300
2025-05-29 19:32:50,522 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:34:17,012 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.58, acc:   0.45, generation: 86.4831[sec], evaluation: 0.0000[sec]
2025-05-29 19:34:17,014 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:34:17,094 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/22500.ckpt
2025-05-29 19:34:17,098 - INFO - joeynmt.training - Example #0
2025-05-29 19:34:17,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:34:17,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:34:17,098 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'due', 'vol@@', 'te', 'di', 'cui', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'di', 'con@@', 'ver@@', 's@@', 'are', 'che', 'la', 'c@@', 'att@@', 'ura', 'ar@@', 'ia', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'più', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'di@@', 'rit@@', 'ti', 'po@@', 'ver@@', 'i', 'di', 'cui', "l'@@", 'et@@', 'à', 'dei', 'di@@', 'rit@@', 'ti', 'i', 'po@@', 'ver@@', 'i', 'di', 's@@', 'egn@@', 'i', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i,', 'per', 'il', '4@@', '0@@', '%', 'di', 'cui']
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due due due volte di cui ho mostrato queste due volte di conversare che la cattura aria di ghiaccio che per tre milioni di anni che per i 40 per cento di 40 per cento di 40 per cento di 40 per cento dei 40 per cento di 40 per cento dei più di 40 per cento dei diritti poveri di cui l'età dei diritti i poveri di segni argomenti, per il 40% di cui
2025-05-29 19:34:17,099 - INFO - joeynmt.training - Example #1
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pr@@', 'ec@@', 'ed@@', 'ente', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza precedente questo speciale non è la distanza che non è la distanza che non è la distanza.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - Example #2
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'il', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di Eiskappe il nostro sistema climatico.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - Example #3
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'att@@', 'ano', 'nel', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'po@@', 'sta', 'nel', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - 	Hypothesis: Si scattano nel vento e sottoposta nel estate.
2025-05-29 19:34:17,099 - INFO - joeynmt.training - Example #4
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:34:17,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'vi@@', 'de@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'giorn@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 19:34:17,100 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:34:17,100 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:34:17,100 - INFO - joeynmt.training - 	Hypothesis: La prossima video che vi mostrerò è una giornale che è successo negli ultimi 25 anni è successo.
2025-05-29 19:34:30,414 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.634223, Batch Acc: 0.465636, Tokens per Sec:     5308, Lr: 0.000300
2025-05-29 19:34:44,336 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.748544, Batch Acc: 0.467608, Tokens per Sec:     5207, Lr: 0.000300
2025-05-29 19:34:58,333 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.825199, Batch Acc: 0.466156, Tokens per Sec:     4989, Lr: 0.000300
2025-05-29 19:35:11,959 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.654519, Batch Acc: 0.467715, Tokens per Sec:     5234, Lr: 0.000300
2025-05-29 19:35:26,467 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.827563, Batch Acc: 0.475167, Tokens per Sec:     5178, Lr: 0.000300
2025-05-29 19:35:26,468 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:36:30,968 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.45, generation: 64.4926[sec], evaluation: 0.0000[sec]
2025-05-29 19:36:30,969 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:36:31,049 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/23000.ckpt
2025-05-29 19:36:31,052 - INFO - joeynmt.training - Example #0
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'si@@', 'der@@', 'are', 'che', 'la', 'di@@', 'sc@@', 'us@@', 'sione', 'che', 'la', 'sc@@', 'al@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'sono', 'st@@', 'ati', 'in', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'é', 'che', 'è', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'dei', 'ser@@', 'vi@@', 'zi@@', 'o', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ec@@', 'ol@@', 'o.', '</s>']
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Hypothesis: Nel anno scorso che ho mostrato queste due volte per considerare che la discussione che la scala di ghiaccio che sono stati in tre milioni di anni che per tre milioni di anni per il 40% dei 40 per cento di 40 per cento dei 40 per cento di 40 per cento di sé che è il 40% del 40% dei servizio per il 40 per cento di secolo.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - Example #1
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'è', 'la', 'cosa', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la distanza di questo problema di questo problema che non è la cosa che non è la distanza che non è la distanza.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - Example #2
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'cu@@', 'ore', 'glob@@', 'ale.', '</s>']
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la ghiaccia di ghiaccio del nostro cuore globale.
2025-05-29 19:36:31,053 - INFO - joeynmt.training - Example #3
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:36:31,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'sc@@', 'egli@@', 'ere', 'in', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'in@@', 'ar@@', 'ono', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Hypothesis: Si è scegliere in vento e sottoinarono in estate.
2025-05-29 19:36:31,054 - INFO - joeynmt.training - Example #4
2025-05-29 19:36:31,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:36:31,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:36:31,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'vi@@', 'sione', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'in', '2@@', '5', 'è', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:36:31,054 - INFO - joeynmt.training - 	Hypothesis: La prossima divisione che vi mostrerò è una cosa che succede negli ultimi 25 anni in 25 è successo.
2025-05-29 19:36:43,685 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.858149, Batch Acc: 0.472928, Tokens per Sec:     5714, Lr: 0.000300
2025-05-29 19:36:57,243 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.975330, Batch Acc: 0.473911, Tokens per Sec:     5215, Lr: 0.000300
2025-05-29 19:37:11,093 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.887346, Batch Acc: 0.462443, Tokens per Sec:     5140, Lr: 0.000300
2025-05-29 19:37:23,902 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.695218, Batch Acc: 0.469539, Tokens per Sec:     5499, Lr: 0.000300
2025-05-29 19:37:38,069 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.767291, Batch Acc: 0.465854, Tokens per Sec:     5077, Lr: 0.000300
2025-05-29 19:37:38,069 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:38:39,013 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.52, acc:   0.45, generation: 60.9360[sec], evaluation: 0.0000[sec]
2025-05-29 19:38:39,015 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:38:39,096 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/24000.ckpt
2025-05-29 19:38:39,099 - INFO - joeynmt.training - Example #0
2025-05-29 19:38:39,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:38:39,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:38:39,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'vol@@', 'te', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'che', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'po@@', 'ver@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'per', 'per', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'dei', 'po@@', 'pol@@', 'i', 'di', 'cui', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'di', 's@@']
2025-05-29 19:38:39,099 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:38:39,099 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:38:39,099 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due due volte ho mostrato questi due due volte per ridurre che i poveri arghiaccio che i poveri di ghiacciaio di milioni di anni per i 40 per cento dei 40 milioni di anni per il 40 per cento dei 40 per cento dei 40 per cento dei 40 per cento dei 40 per cento di questi due milioni di anni per per per il 40% del 40% dei popoli di cui i poveri che i poveri di s
2025-05-29 19:38:39,100 - INFO - joeynmt.training - Example #1
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'questo', 'problem@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Hypothesis: Ma non è forse non è abbastanza forse questo problema di questo particolare problemi di questo problema del ghiaccio del ghiaccio del ghiaccio.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - Example #2
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'li@@', 'sta', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'm@@', 'ezzo', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la clista di ghiacciaio di mezzo di climatico globale.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - Example #3
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'po@@', 'sta', 'nel', 'vent@@', 'o', 'e', 's@@', 'an@@', 'gu@@', 'e.', '</s>']
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Hypothesis: Si sposta nel vento e sangue.
2025-05-29 19:38:39,100 - INFO - joeynmt.training - Example #4
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:38:39,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ale', 'di', 'una', 'giorn@@', 'ale', 'di', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:38:39,100 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:38:39,101 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:38:39,101 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una giornale di una giornale di cui è successo negli ultimi 25 anni.
2025-05-29 19:38:52,442 - INFO - joeynmt.training - Epoch   6, Step:    26100, Batch Loss:     1.959719, Batch Acc: 0.466866, Tokens per Sec:     5272, Lr: 0.000300
2025-05-29 19:39:06,767 - INFO - joeynmt.training - Epoch   6, Step:    26200, Batch Loss:     1.830181, Batch Acc: 0.467473, Tokens per Sec:     5018, Lr: 0.000300
2025-05-29 19:39:20,855 - INFO - joeynmt.training - Epoch   6, Step:    26300, Batch Loss:     1.759651, Batch Acc: 0.466743, Tokens per Sec:     5013, Lr: 0.000300
2025-05-29 19:39:35,102 - INFO - joeynmt.training - Epoch   6, Step:    26400, Batch Loss:     1.899091, Batch Acc: 0.470453, Tokens per Sec:     4995, Lr: 0.000300
2025-05-29 19:39:49,213 - INFO - joeynmt.training - Epoch   6, Step:    26500, Batch Loss:     1.785589, Batch Acc: 0.467424, Tokens per Sec:     5119, Lr: 0.000300
2025-05-29 19:39:49,215 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:41:10,283 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.54, acc:   0.45, generation: 81.0605[sec], evaluation: 0.0000[sec]
2025-05-29 19:41:10,382 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/23500.ckpt
2025-05-29 19:41:10,383 - INFO - joeynmt.training - Example #0
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'di', 'con@@', 'su@@', 'mat@@', 'ori', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i,', 'per', 'i', 'qual@@', 'i', 'sono', 'st@@', 'ati', 'in', 'cui', 'i', 'gi@@', 'à', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'fare', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'fare', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'fare', 'il', '4@@', '0@@', '%', 'per', 'c@@', 'ento', 'di', 'fare', 'il', '4@@', '0', 'per@@', 'cent@@', 'o.', '</s>']
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Hypothesis: Lo scorso che ho mostrato questi due due discussioni di consumatori argomenti, per i quali sono stati in cui i già i tre milioni di anni per i 40 per cento di 40 percento di fare il 40 percento di fare il 40% per il 40 percento di fare il 40% per cento di fare il 40 percento.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - Example #1
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'pr@@', 'ot@@', 'e@@', 'zione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Hypothesis: Ma non è forse non è abbastanza forte la protezione di questo particolare problemi di questo problema del ghiaccio del ghiaccio.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - Example #2
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:41:10,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'E@@', 'is@@', 'c@@', 'le@@', 'a@@', 'der@@', 's@@', 'hi@@', 'p@@', 'a', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di Eiscleadershipa globale del nostro sistema climatico globale.
2025-05-29 19:41:10,384 - INFO - joeynmt.training - Example #3
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'po@@', 'sta', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'la', 's@@', 'ens@@', 'azione', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno, e la sensazione in estate.
2025-05-29 19:41:10,385 - INFO - joeynmt.training - Example #4
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:41:10,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'temp@@', 'or@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:41:10,385 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una temporale che è successo negli ultimi 25 anni.
2025-05-29 19:41:24,116 - INFO - joeynmt.training - Epoch   6, Step:    26600, Batch Loss:     1.750525, Batch Acc: 0.470664, Tokens per Sec:     5196, Lr: 0.000300
2025-05-29 19:41:38,098 - INFO - joeynmt.training - Epoch   6, Step:    26700, Batch Loss:     1.722324, Batch Acc: 0.470612, Tokens per Sec:     5227, Lr: 0.000300
2025-05-29 19:41:52,082 - INFO - joeynmt.training - Epoch   6, Step:    26800, Batch Loss:     1.593320, Batch Acc: 0.470565, Tokens per Sec:     5178, Lr: 0.000300
2025-05-29 19:42:05,472 - INFO - joeynmt.training - Epoch   6, Step:    26900, Batch Loss:     1.902008, Batch Acc: 0.468488, Tokens per Sec:     5296, Lr: 0.000300
2025-05-29 19:42:19,978 - INFO - joeynmt.training - Epoch   6, Step:    27000, Batch Loss:     1.606876, Batch Acc: 0.472969, Tokens per Sec:     4939, Lr: 0.000300
2025-05-29 19:42:19,978 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:43:18,591 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.49, acc:   0.45, generation: 58.6061[sec], evaluation: 0.0000[sec]
2025-05-29 19:43:18,594 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:43:18,678 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/24500.ckpt
2025-05-29 19:43:18,679 - INFO - joeynmt.training - Example #0
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'scor@@', 'so', 'questi', 'due', 'di@@', 'p@@', 'es@@', 'ci', 'che', 'le', 'di@@', 're@@', 'zioni', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i,', 'che', 'la', 'c@@', 'at@@', 'en@@', 'a', 'che', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'hi@@', 'acci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'su@@', 'oi', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'su@@', 'oi', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'su@@', 'oi', 'li@@', 'ber@@', 'i.', '</s>']
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno scorso questi due dipesci che le direzioni argomenti, che la catena che i poveri arghiacciati per tre milioni di anni che per i 40 per cento dei suoi 40 per cento dei suoi 40 per cento dei suoi liberi.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - Example #1
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'pro@@', 'b@@', 'abil@@', 'ità', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'non', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anza', 'non', 'mostr@@', 'a', 'il', 'di@@', 'scor@@', 'so', "dell'@@", 'em@@', 'is@@', 'sion@@', 'e.', '</s>']
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza probabilità di questo problema non è il problema del ghiaccio che non mostra la distanza non mostra il discorso dell'emissione.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - Example #2
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:43:18,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'il', 'cu@@', 'ore', 'ar@@', 'an@@', 'co', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è il cuore aranco di ghiaccio del nostro sistema di climatico globale.
2025-05-29 19:43:18,679 - INFO - joeynmt.training - Example #3
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ar@@', 'ebbe', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 's@@', 'otto', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Hypothesis: Sarebbe in inverno, e sotto in estate.
2025-05-29 19:43:18,680 - INFO - joeynmt.training - Example #4
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:43:18,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:43:18,680 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una divisione di ciò che è successo negli ultimi 25 anni.
2025-05-29 19:43:31,979 - INFO - joeynmt.training - Epoch   6, Step:    27100, Batch Loss:     1.841132, Batch Acc: 0.469779, Tokens per Sec:     5176, Lr: 0.000300
2025-05-29 19:43:44,943 - INFO - joeynmt.training - Epoch   6, Step:    27200, Batch Loss:     1.881719, Batch Acc: 0.469449, Tokens per Sec:     5419, Lr: 0.000300
2025-05-29 19:43:58,999 - INFO - joeynmt.training - Epoch   6, Step:    27300, Batch Loss:     1.932003, Batch Acc: 0.462020, Tokens per Sec:     5002, Lr: 0.000300
2025-05-29 19:44:12,724 - INFO - joeynmt.training - Epoch   6, Step:    27400, Batch Loss:     1.833123, Batch Acc: 0.471121, Tokens per Sec:     5364, Lr: 0.000300
2025-05-29 19:44:25,561 - INFO - joeynmt.training - Epoch   6, Step:    27500, Batch Loss:     1.612463, Batch Acc: 0.469501, Tokens per Sec:     5497, Lr: 0.000300
2025-05-29 19:44:25,561 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:45:23,160 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.50, acc:   0.45, generation: 57.5911[sec], evaluation: 0.0000[sec]
2025-05-29 19:45:23,253 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/25000.ckpt
2025-05-29 19:45:23,254 - INFO - joeynmt.training - Example #0
2025-05-29 19:45:23,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'i', 'con@@', 'si@@', 'der@@', 'are', 'che', 'la', 'c@@', 'ur@@', 'v@@', 'an@@', 'a', 'che', 'la', 'c@@', 'ur@@', 'v@@', 'an@@', 'a', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', '4@@', '8', 'milioni', 'di', 'anni', 'per', '4@@', '8@@', '.', '</s>']
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno, ho mostrato queste due volte per ridurre i considerare che la curvana che la curvana che per tre milioni di anni che hanno avuto 48 milioni di anni per 48.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - Example #1
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'nostra', 'sp@@', 'eci@@', 'fic@@', 'azione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anz@@', 'a.', '</s>']
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la nostra specificazione di questo particolare problema non è la distanza non è la dimostra la distanza.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - Example #2
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia di Eiskappe del nostro clima.
2025-05-29 19:45:23,255 - INFO - joeynmt.training - Example #3
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:45:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sottopo.
2025-05-29 19:45:23,256 - INFO - joeynmt.training - Example #4
2025-05-29 19:45:23,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:45:23,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:45:23,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'f@@', 'era', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ale', 'che', 'vi', 'mostr@@', 'o', 'cosa', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:45:23,256 - INFO - joeynmt.training - 	Hypothesis: La prossima sfera che vi mostro è una giornale che vi mostro cosa negli ultimi 25 anni.
2025-05-29 19:45:37,618 - INFO - joeynmt.training - Epoch   6, Step:    27600, Batch Loss:     1.693972, Batch Acc: 0.466472, Tokens per Sec:     4992, Lr: 0.000300
2025-05-29 19:45:50,800 - INFO - joeynmt.training - Epoch   6, Step:    27700, Batch Loss:     1.878848, Batch Acc: 0.468033, Tokens per Sec:     5379, Lr: 0.000300
2025-05-29 19:46:04,331 - INFO - joeynmt.training - Epoch   6, Step:    27800, Batch Loss:     1.731093, Batch Acc: 0.472889, Tokens per Sec:     5428, Lr: 0.000300
2025-05-29 19:46:17,998 - INFO - joeynmt.training - Epoch   6, Step:    27900, Batch Loss:     1.961550, Batch Acc: 0.473315, Tokens per Sec:     5165, Lr: 0.000300
2025-05-29 19:46:31,815 - INFO - joeynmt.training - Epoch   6, Step:    28000, Batch Loss:     1.917230, Batch Acc: 0.468030, Tokens per Sec:     5229, Lr: 0.000300
2025-05-29 19:46:31,815 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:47:38,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.46, acc:   0.45, generation: 67.1585[sec], evaluation: 0.0000[sec]
2025-05-29 19:47:38,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:47:39,062 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/25500.ckpt
2025-05-29 19:47:39,063 - INFO - joeynmt.training - Example #0
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', "l'@@", 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'con@@', 'di@@', 'vi@@', 'dere', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'gli', 'ar@@', 'g@@', 'om@@', 'ento', 'dei', 'g@@', 'hi@@', 'acci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 'mo@@', 'ti@@', 'vi', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'del', '4@@', '0@@', '%', 'per', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'fare', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0@@', '%', 'dei', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'il', '4@@', '0@@', '%', 'di', 'g@@', 'hi@@', 'acci@@']
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso l'anno scorso che ho mostrato queste due volte per condividere che i poveri che i poveri che gli argomento dei ghiacciati per tre milioni di anni per il 40% dei motivi per 40 percento di 40 percento del 40% per 40 percento di 40 percento dei livelli di ghiaccio per fare il 40% per il 40% dei poveri che i poveri che il 40% di ghiacci
2025-05-29 19:47:39,063 - INFO - joeynmt.training - Example #1
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:47:39,063 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'sp@@', 'eci@@', 'f@@', 'ica', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:47:39,063 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte la specifica di questo problema di questo problema di questo problema di questo problema del ghiaccio del ghiaccio del ghiaccio.
2025-05-29 19:47:39,063 - INFO - joeynmt.training - Example #2
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', "l'@@", 'g@@', 'hi@@', 'acci@@', 'o', 'è', "l'@@", 'i@@', 'b@@', 'a', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, l'ghiaccio è l'iba del nostro clima.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - Example #3
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'otto', 'in', 'v@@', 'in@@', 'o.', '</s>']
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sotto in vino.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - Example #4
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:47:39,064 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ale', 'di', 'mostr@@', 'are', 'cosa', 'che', 'vi', 'mostr@@', 'a', 'cosa', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:47:39,064 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro è una giornale di mostrare cosa che vi mostra cosa negli ultimi 25 anni.
2025-05-29 19:47:52,909 - INFO - joeynmt.training - Epoch   6, Step:    28100, Batch Loss:     1.932201, Batch Acc: 0.468272, Tokens per Sec:     5125, Lr: 0.000300
2025-05-29 19:48:05,987 - INFO - joeynmt.training - Epoch   6, Step:    28200, Batch Loss:     1.945220, Batch Acc: 0.468950, Tokens per Sec:     5406, Lr: 0.000300
2025-05-29 19:48:14,133 - INFO - joeynmt.training - Epoch   6: total training loss 8433.72
2025-05-29 19:48:14,134 - INFO - joeynmt.training - EPOCH 7
2025-05-29 19:48:19,768 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.778114, Batch Acc: 0.490794, Tokens per Sec:     4964, Lr: 0.000300
2025-05-29 19:48:33,566 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.812627, Batch Acc: 0.489397, Tokens per Sec:     5086, Lr: 0.000300
2025-05-29 19:48:47,017 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.575712, Batch Acc: 0.490727, Tokens per Sec:     5288, Lr: 0.000300
2025-05-29 19:48:47,017 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:49:45,203 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.46, generation: 58.1779[sec], evaluation: 0.0000[sec]
2025-05-29 19:49:45,205 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:49:45,287 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/26500.ckpt
2025-05-29 19:49:45,288 - INFO - joeynmt.training - Example #0
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'due', 'milioni', 'di', 'anni', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'per', 'la', 'loro', 'ar@@', 'e@@', 'a', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'pi@@', 'u@@', "'", 'di', 'cui', 'il', '4@@', '0@@', '%', 'di', 'cui', 'il', '4@@', '0@@', '%', 'di', 'm@@', 'ezz@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'po@@', 'ver@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o']
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due due due milioni di anni ho mostrato queste due discussioni per la loro area che i poveri che i poveri che i poveri che i poveri per 40 per cento di 40 per cento dei 40 per cento di 40 per cento di 40 per cento di 40 per cento di 40 per cento di piu' di cui il 40% di cui il 40% di mezza di ghiaccio che i poveri di ghiaccio
2025-05-29 19:49:45,288 - INFO - joeynmt.training - Example #1
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:49:45,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questa', 'sp@@', 'eci@@', 'ale', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:49:45,288 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la distanza di questa speciale speciale di questo speciale non è la distanza che non è la distanza del ghiaccio.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - Example #2
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'è', 'la', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale.', '</s>']
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia è la causa di ghiaccio globale.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - Example #3
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'in', 'gi@@', 'ro', 'in', 'vent@@', 'o', 'e', 'r@@', 'om@@', 'per@@', 'e', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'at@@', 'e.', '</s>']
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Hypothesis: Si è in giro in vento e rompere in estate in estate in estate in estate in estate in estate ate.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - Example #4
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:49:45,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'st@@', 'am@@', 'p@@', 'a', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:49:45,289 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una stampa che è successo negli ultimi 25 anni.
2025-05-29 19:49:58,209 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.749722, Batch Acc: 0.485297, Tokens per Sec:     5549, Lr: 0.000300
2025-05-29 19:50:11,119 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.919073, Batch Acc: 0.487820, Tokens per Sec:     5473, Lr: 0.000300
2025-05-29 19:50:24,706 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.677665, Batch Acc: 0.492593, Tokens per Sec:     5371, Lr: 0.000300
2025-05-29 19:50:38,125 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.750348, Batch Acc: 0.487598, Tokens per Sec:     5146, Lr: 0.000300
2025-05-29 19:50:52,001 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.689972, Batch Acc: 0.480376, Tokens per Sec:     5200, Lr: 0.000300
2025-05-29 19:50:52,001 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:52:01,118 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.42, acc:   0.45, generation: 69.1098[sec], evaluation: 0.0000[sec]
2025-05-29 19:52:01,197 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/26000.ckpt
2025-05-29 19:52:01,199 - INFO - joeynmt.training - Example #0
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'e', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'per', 'ri@@', 'dur@@', 're', 'questi', 'due', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'ar@@', 'd@@', 'ini', 'ar@@', 'ar@@', 'ono', 'che', 'i', 'gi@@', 'u@@', 'sto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'di@@', 'rit@@', 'ti', 'di', 'questi', 'due', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 'di@@', 'a@@', 'si@@', '.', '</s>']
2025-05-29 19:52:01,199 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:52:01,199 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:52:01,199 - INFO - joeynmt.training - 	Hypothesis: Ne ho mostrato questi due discussioni per ridurre questi due discussioni ardini ararono che i giusto per tre milioni di anni che per tre milioni di anni per tre milioni di anni per i 40 per cento dei 40 per cento di 40 per cento di 40 per cento dei diritti di questi due milioni di anni per il 40% dei diasi.
2025-05-29 19:52:01,199 - INFO - joeynmt.training - Example #1
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:52:01,199 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'questa', 'sp@@', 'eci@@', 'e,', 'questo', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forse non è abbastanza di questa specie, questo non è il problema non è la distanza che non è la dimostra il ghiaccio.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - Example #2
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di ghiaccio del nostro cuore globale del nostro sistema climatico.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - Example #3
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sotto.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - Example #4
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:52:01,200 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'di@@', 'mostr@@', 'ar@@', 'vi', 'è', 'una', 'vi@@', 'sione', 'di', 'tempo', 'è', 'una', 'vi@@', 'sta', 'vi@@', 'a', 'in', 'un', 'mom@@', 'ento', 'di', 'tempo', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:52:01,200 - INFO - joeynmt.training - 	Hypothesis: Il prossimo dimostrarvi è una visione di tempo è una vista via in un momento di tempo negli ultimi 25 anni.
2025-05-29 19:52:14,259 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.709659, Batch Acc: 0.479355, Tokens per Sec:     5371, Lr: 0.000300
2025-05-29 19:52:27,766 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.845230, Batch Acc: 0.484279, Tokens per Sec:     5096, Lr: 0.000300
2025-05-29 19:52:41,077 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.623810, Batch Acc: 0.486026, Tokens per Sec:     5369, Lr: 0.000300
2025-05-29 19:52:55,089 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.735676, Batch Acc: 0.482583, Tokens per Sec:     4862, Lr: 0.000300
2025-05-29 19:53:08,427 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.778922, Batch Acc: 0.484308, Tokens per Sec:     5361, Lr: 0.000300
2025-05-29 19:53:08,427 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:54:09,002 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.40, acc:   0.46, generation: 60.5688[sec], evaluation: 0.0000[sec]
2025-05-29 19:54:09,004 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:54:09,082 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/27500.ckpt
2025-05-29 19:54:09,083 - INFO - joeynmt.training - Example #0
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'cor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'it@@', 'e,', 'per', 'con@@', 'v@@', 'in@@', 'cer@@', 'ti', 'che', 'la', 'po@@', 'ver@@', 'a', 'po@@', 'ver@@', 'a', 'che', 'gli', 'st@@', 'ati', 'po@@', 'i,', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'i', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 'di@@', 'rit@@', 'ti', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 'di@@', 'rit@@', 'ti', 'di', 'po@@', 'ter', 'fare', 'il', '4@@', '0@@', '%', 'per', 'c@@', 'ento', 'dei', 'di@@', 'rit@@', 'ti', 'po@@', 'ver@@', 'i.', '</s>']
2025-05-29 19:54:09,083 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:54:09,083 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:54:09,083 - INFO - joeynmt.training - 	Hypothesis: Nel corso che ho mostrato queste due dibattite, per convincerti che la povera povera che gli stati poi, che per tre milioni di anni per tre milioni di anni per i tre milioni di anni per per i 40 percento dei diritti di 40 percento dei diritti di poter fare il 40% per cento dei diritti poveri.
2025-05-29 19:54:09,083 - INFO - joeynmt.training - Example #1
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:54:09,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'for@@', 'tun@@', 'ato', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'che', 'non', 'è', 'il', 'di@@', 'st@@', 'im@@', 'ol@@', 'ato', 'non', 'è', 'il', 'di@@', 'mostr@@', 'o.', '</s>']
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato fortunato non è abbastanza forte di questo particolare problemi che non è il distimolato non è il dimostro.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - Example #2
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Hypothesis: In certo senso, il senso è la ghiaccia di ghiaccio di climatica.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - Example #3
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'po@@', 'sta', 'nel', 'vent@@', 'o', 'e', 'p@@', 'ur@@', 'e,', 'e', 's@@', 'po@@', 'sta', 'nel', 'v@@', 'in@@', 'o.', '</s>']
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Hypothesis: Si sposta nel vento e pure, e sposta nel vino.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - Example #4
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:54:09,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'vi@@', 'sione', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:54:09,084 - INFO - joeynmt.training - 	Hypothesis: La prossima divisione che vi mostrerò è una divisione di quello che è successo negli ultimi 25 anni.
2025-05-29 19:54:23,126 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.628063, Batch Acc: 0.483534, Tokens per Sec:     5055, Lr: 0.000300
2025-05-29 19:54:37,321 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.668323, Batch Acc: 0.482281, Tokens per Sec:     5250, Lr: 0.000300
2025-05-29 19:54:50,974 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.803042, Batch Acc: 0.480751, Tokens per Sec:     5154, Lr: 0.000300
2025-05-29 19:55:04,577 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.711440, Batch Acc: 0.479834, Tokens per Sec:     5200, Lr: 0.000300
2025-05-29 19:55:17,921 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.802297, Batch Acc: 0.482503, Tokens per Sec:     5435, Lr: 0.000300
2025-05-29 19:55:17,921 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:56:20,247 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.38, acc:   0.46, generation: 62.3195[sec], evaluation: 0.0000[sec]
2025-05-29 19:56:20,248 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 19:56:20,323 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/27000.ckpt
2025-05-29 19:56:20,325 - INFO - joeynmt.training - Example #0
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 's@@', 'ott@@', "'@@", 'ann@@', 'o,', 'per', 's@@', 'ott@@', 'o@@', 'po@@', 'ca', 'per', 'la', 'b@@', 'att@@', 'agli@@', 'a', 'che', 'la', 'po@@', 'ver@@', 'a', 'che', 'la', 'po@@', 'ver@@', 'a', 'che', 'ha', 'av@@', 'uto', 'la', 'ra@@', 'gi@@', 'one', 'di', '3@@', '0', 'per', 'c@@', 'ento', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'i', 'di', 'po@@', 'ter@@', 'e.', '</s>']
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due dimensioni per sott'anno, per sottopoca per la battaglia che la povera che la povera che ha avuto la ragione di 30 per cento milioni di anni per per il 40% dei segni di potere.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - Example #1
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problem@@', 'a', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'il', 'problem@@', 'a', 'non', 'è', 'la', 'cosa', 'che', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'mostr@@', 'a', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte di questo problema abbastanza di questo problema non è il problema non è la cosa che mostra la distanza che non è la distanza che mostra la distanza di ghiaccio.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - Example #2
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:56:20,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'è', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:56:20,325 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la climatica è la climatica globale del nostro clima.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - Example #3
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'in', 'vent@@', 'o', 'e', 'r@@', 'ur@@', 'o', 'e', 's@@', 'an@@', 'o.', '</s>']
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Hypothesis: Si tratta in vento e ruro e sano.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - Example #4
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:56:20,326 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'f@@', 'o@@', 'to', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di', 'temp@@', 'or@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:56:20,326 - INFO - joeynmt.training - 	Hypothesis: La prossima foto che vi mostrerò è una di temporale che è successo negli ultimi 25 anni.
2025-05-29 19:56:34,653 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.713756, Batch Acc: 0.482960, Tokens per Sec:     4838, Lr: 0.000300
2025-05-29 19:56:48,665 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.686331, Batch Acc: 0.476809, Tokens per Sec:     5097, Lr: 0.000300
2025-05-29 19:57:03,146 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.741921, Batch Acc: 0.480446, Tokens per Sec:     4888, Lr: 0.000300
2025-05-29 19:57:17,413 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.762876, Batch Acc: 0.482487, Tokens per Sec:     4861, Lr: 0.000300
2025-05-29 19:57:31,787 - INFO - joeynmt.training - Epoch   7, Step:    30500, Batch Loss:     1.800009, Batch Acc: 0.478478, Tokens per Sec:     4865, Lr: 0.000300
2025-05-29 19:57:31,787 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 19:58:44,694 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.86, ppl:   6.40, acc:   0.46, generation: 72.8999[sec], evaluation: 0.0000[sec]
2025-05-29 19:58:44,771 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/28000.ckpt
2025-05-29 19:58:44,772 - INFO - joeynmt.training - Example #0
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'pr@@', 'ev@@', 'en@@', 'i@@', 'bi@@', 'li@@', ',', 'che', 'la', 'pr@@', 'ev@@', 'en@@', 'i@@', 'bi@@', 'a', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'ott@@', 'o@@', 'ter@@', 'ra.', '</s>']
2025-05-29 19:58:44,772 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 19:58:44,772 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 19:58:44,772 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due dimensioni di queste due dimensioni di ghiaccio che la prevenibili, che la prevenibia che per tre milioni di anni per per tre milioni di anni per per il 40% dei sottoterra.
2025-05-29 19:58:44,772 - INFO - joeynmt.training - Example #1
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 19:58:44,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'più', 'for@@', 'te', 'il', 'di@@', 'st@@', 'ing@@', 'u@@', 'aggio', 'di', 'questo', 'problem@@', 'a', 'è', 'il', 'nostro', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'non', 'è', 'la', 'm@@', 'and@@', 'a', 'che', 'non', 'è', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Hypothesis: Ma non è più forte il distinguaggio di questo problema è il nostro ghiaccio che non è la manda che non è il ghiaccio del ghiaccio.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - Example #2
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ento', 'ar@@', 'ci@@', 'o', 'glob@@', 'ale.', '</s>']
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è la ghiaccio è il cuore argomento arcio globale.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - Example #3
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'in', 'vent@@', 'o', 'e', 'r@@', 'ot@@', 'ta', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'ol@@', 'o.', '</s>']
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Hypothesis: Si tratta di in vento e rotta in estate in estate in estate in estate in estate in estate in estate e rotolo.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - Example #4
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 19:58:44,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'f@@', 'era', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'macch@@', 'ina', 'di', 'temp@@', 'or@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 19:58:44,773 - INFO - joeynmt.training - 	Hypothesis: La prossima sfera che vi mostro è una macchina di temporale che è successo negli ultimi 25 anni.
2025-05-29 19:58:58,191 - INFO - joeynmt.training - Epoch   7, Step:    30600, Batch Loss:     1.776060, Batch Acc: 0.476779, Tokens per Sec:     5123, Lr: 0.000300
2025-05-29 19:59:11,743 - INFO - joeynmt.training - Epoch   7, Step:    30700, Batch Loss:     1.811061, Batch Acc: 0.486273, Tokens per Sec:     5150, Lr: 0.000300
2025-05-29 19:59:25,740 - INFO - joeynmt.training - Epoch   7, Step:    30800, Batch Loss:     1.649298, Batch Acc: 0.480247, Tokens per Sec:     4984, Lr: 0.000300
2025-05-29 19:59:39,716 - INFO - joeynmt.training - Epoch   7, Step:    30900, Batch Loss:     1.755727, Batch Acc: 0.483169, Tokens per Sec:     5144, Lr: 0.000300
2025-05-29 19:59:53,779 - INFO - joeynmt.training - Epoch   7, Step:    31000, Batch Loss:     1.687104, Batch Acc: 0.475108, Tokens per Sec:     4958, Lr: 0.000300
2025-05-29 19:59:53,780 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:01:08,183 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.34, acc:   0.46, generation: 74.3957[sec], evaluation: 0.0000[sec]
2025-05-29 20:01:08,184 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:01:08,262 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/29000.ckpt
2025-05-29 20:01:08,263 - INFO - joeynmt.training - Example #0
2025-05-29 20:01:08,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:01:08,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:01:08,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'questi', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 's@@', 'ott@@', 'om@@', 'ar@@', 'in@@', 'are', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'po@@', 'tr@@', 'à', 'milioni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'i.', '</s>']
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due dimensioni di questi due dimensioni per sottomarinare che i ghiaccio che i potrà milioni di ghiaccio per tre milioni di anni per tre milioni di anni, per tre milioni di anni, per il 40 per cento dei livelli di 40 per cento dei livelli di ghiaccio per tre milioni di ghiacciai.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - Example #1
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'for@@', 't@@', 'una', 'di', 'p@@', 'ell@@', 'a', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problem@@', 'a', 'che', 'non', 'lo', 'mostr@@', 'a', 'il', 'di@@', 'st@@', 'in@@', 'o.', '</s>']
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato fortuna di pella abbastanza di questo problema è la distanza di questo problema che non lo mostra il distino.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - Example #2
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia di Eiskappe del nostro clima.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - Example #3
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'po@@', 'ca', 'in', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sottopoca in estate estate in estate estate in estate estate.
2025-05-29 20:01:08,264 - INFO - joeynmt.training - Example #4
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:01:08,264 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:01:08,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cam@@', 'pag@@', 'n@@', 'a', 'di', 'una', 'cam@@', 'pag@@', 'n@@', 'a', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:01:08,265 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:01:08,265 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:01:08,265 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una campagna di una campagna che è successo negli ultimi 25 anni.
2025-05-29 20:01:21,556 - INFO - joeynmt.training - Epoch   7, Step:    31100, Batch Loss:     1.674223, Batch Acc: 0.481732, Tokens per Sec:     5519, Lr: 0.000300
2025-05-29 20:01:35,232 - INFO - joeynmt.training - Epoch   7, Step:    31200, Batch Loss:     1.869632, Batch Acc: 0.483959, Tokens per Sec:     5285, Lr: 0.000300
2025-05-29 20:01:49,014 - INFO - joeynmt.training - Epoch   7, Step:    31300, Batch Loss:     1.692431, Batch Acc: 0.482650, Tokens per Sec:     5142, Lr: 0.000300
2025-05-29 20:02:02,806 - INFO - joeynmt.training - Epoch   7, Step:    31400, Batch Loss:     1.672677, Batch Acc: 0.478993, Tokens per Sec:     5187, Lr: 0.000300
2025-05-29 20:02:16,245 - INFO - joeynmt.training - Epoch   7, Step:    31500, Batch Loss:     1.775630, Batch Acc: 0.480747, Tokens per Sec:     5429, Lr: 0.000300
2025-05-29 20:02:16,245 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:03:29,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.31, acc:   0.46, generation: 73.0893[sec], evaluation: 0.0000[sec]
2025-05-29 20:03:29,343 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:03:29,420 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/28500.ckpt
2025-05-29 20:03:29,421 - INFO - joeynmt.training - Example #0
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'cui', "l'@@", 'is@@', 'co@@', 'sto', 'che', 'la', 'ra@@', 'gi@@', 'one', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'i', 'di', '3@@', '%@@', '.', '</s>']
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due dimensioni per ridurre il ghiaccio per cui l'iscosto che la ragione di ghiaccio per tre milioni di anni per i tre milioni di anni per il 40% dei segni di 3%.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - Example #1
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 't@@', 'una', 'di', 'queste', 'sp@@', 'eci@@', 'e,', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'il', 'di@@', 'st@@', 'es@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza fortuna di queste specie, questo problema speciale di questo speciale non è il distesa del ghiaccio del ghiaccio.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - Example #2
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'sen@@', 'so', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il senso di ghiaccio del nostro sistema del nostro sistema climatico.
2025-05-29 20:03:29,422 - INFO - joeynmt.training - Example #3
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:03:29,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'v@@', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'in', 'in@@', 'ver@@', 'n@@', 'o.', '</s>']
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vinverno, e in inverno.
2025-05-29 20:03:29,423 - INFO - joeynmt.training - Example #4
2025-05-29 20:03:29,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:03:29,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:03:29,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'quello', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:03:29,423 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una divisione di quello che è successo negli ultimi 25 anni.
2025-05-29 20:03:42,654 - INFO - joeynmt.training - Epoch   7, Step:    31600, Batch Loss:     1.735351, Batch Acc: 0.479770, Tokens per Sec:     5327, Lr: 0.000300
2025-05-29 20:03:55,703 - INFO - joeynmt.training - Epoch   7, Step:    31700, Batch Loss:     1.564015, Batch Acc: 0.482199, Tokens per Sec:     5580, Lr: 0.000300
2025-05-29 20:04:08,872 - INFO - joeynmt.training - Epoch   7, Step:    31800, Batch Loss:     1.713073, Batch Acc: 0.481177, Tokens per Sec:     5400, Lr: 0.000300
2025-05-29 20:04:22,222 - INFO - joeynmt.training - Epoch   7, Step:    31900, Batch Loss:     1.681811, Batch Acc: 0.481632, Tokens per Sec:     5367, Lr: 0.000300
2025-05-29 20:04:35,891 - INFO - joeynmt.training - Epoch   7, Step:    32000, Batch Loss:     1.831094, Batch Acc: 0.480594, Tokens per Sec:     5210, Lr: 0.000300
2025-05-29 20:04:35,892 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:05:35,488 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.27, acc:   0.46, generation: 59.5899[sec], evaluation: 0.0000[sec]
2025-05-29 20:05:35,489 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:05:35,563 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/29500.ckpt
2025-05-29 20:05:35,565 - INFO - joeynmt.training - Example #0
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'questi', 'due', 'di@@', 'scor@@', 'si', 'per', 'ri@@', 'dur@@', 're', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'po@@', 'tr@@', 'em@@', 'mo', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'la', 'di@@', 'sc@@', 'ut@@', 'a', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0@@', '%', 'di', 'di@@', 'f@@', 'es@@', 'a', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ur@@', 'o', 'di', 'questo', 'tipo', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:05:35,565 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:05:35,565 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:05:35,565 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due dimensioni di questi due discorsi per ridurre che i considerano che i potremmo tre milioni di anni di ghiaccio per tre milioni di anni per la discuta per tre milioni di anni per per il 40% di difesa per il 40% del 40 percento di curo di questo tipo di ghiaccio.
2025-05-29 20:05:35,565 - INFO - joeynmt.training - Example #1
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:05:35,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anz@@', 'a,', 'non', 'è', 'la', 'cosa', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'in@@', 'a.', '</s>']
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte la distanza, non è la cosa speciale di questo problema di questo problema di ghiaccio che non è la distina.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - Example #2
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'è', "l'@@", 'is@@', 'co@@', 'sto', 'che', 'la', 'c@@', 'li@@', 'ma', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la cattiva è l'iscosto che la clima del nostro sistema climatico.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - Example #3
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'b@@', 'agli@@', 'ato', 'nel', 'vent@@', 'o', 'e', 's@@', 'an@@', 'o,', 'e', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Hypothesis: Si è sbagliato nel vento e sano, e in estate.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - Example #4
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:05:35,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'giorn@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'di', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '5', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:05:35,566 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una giornale che è successo negli ultimi 25 anni di successo negli ultimi 25 anni 25 è successo negli ultimi 25 anni.
2025-05-29 20:05:48,544 - INFO - joeynmt.training - Epoch   7, Step:    32100, Batch Loss:     1.750853, Batch Acc: 0.480043, Tokens per Sec:     5581, Lr: 0.000300
2025-05-29 20:06:01,501 - INFO - joeynmt.training - Epoch   7, Step:    32200, Batch Loss:     1.697802, Batch Acc: 0.482050, Tokens per Sec:     5401, Lr: 0.000300
2025-05-29 20:06:14,850 - INFO - joeynmt.training - Epoch   7, Step:    32300, Batch Loss:     1.635395, Batch Acc: 0.480739, Tokens per Sec:     5471, Lr: 0.000300
2025-05-29 20:06:28,179 - INFO - joeynmt.training - Epoch   7, Step:    32400, Batch Loss:     1.821468, Batch Acc: 0.476816, Tokens per Sec:     5297, Lr: 0.000300
2025-05-29 20:06:41,738 - INFO - joeynmt.training - Epoch   7, Step:    32500, Batch Loss:     1.681955, Batch Acc: 0.477121, Tokens per Sec:     5095, Lr: 0.000300
2025-05-29 20:06:41,738 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:07:51,789 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.84, ppl:   6.28, acc:   0.46, generation: 70.0446[sec], evaluation: 0.0000[sec]
2025-05-29 20:07:51,868 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/30500.ckpt
2025-05-29 20:07:51,870 - INFO - joeynmt.training - Example #0
2025-05-29 20:07:51,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:07:51,870 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:07:51,870 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'sc@@', 'ap@@', 'p@@', 'a', 'che', 'la', 'sc@@', 'ap@@', 'p@@', 'a', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'sono', 's@@', 'post@@', 'ati', 'in', 'cui', 'i', 'sono', 'in', 'gra@@', 'do', 'di', 'fare', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'ali', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'ali', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'ac@@', 'r@@', 'i', 'di', 's@@', 'ott@@', 'o@@', '-@@', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'anni@@', '.', '</s>']
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno, ho mostrato queste due dimensioni per ridurre il ghiaccio che la scappa che la scappa che per tre milioni di anni che si sono spostati in cui i sono in grado di fare il 40% dei segnali per 40 per cento dei 40 per cento dei segnali per il 40% dei sacri di sotto-40 per cento di questi due anni.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - Example #1
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 'se', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'se', 'la', 'di@@', 'st@@', 'anza', 'di', 'questa', 'sp@@', 'eci@@', 'e,', 'perché', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'che', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'a.', '</s>']
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Hypothesis: Ma non è forse non è abbastanza forse la distanza di questa specie, perché non è la destinazione che non è la destina.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - Example #2
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'li@@', 'mat@@', 'ica', 'di', 'E@@', 'is@@', 'k@@', 'i@@', 's', 'glob@@', 'ale.', '</s>']
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la climatica di Eiskis globale.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - Example #3
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'ente', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'si', 's@@', 'ente', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - 	Hypothesis: Si sente in inverno, e si sente in estate.
2025-05-29 20:07:51,871 - INFO - joeynmt.training - Example #4
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:07:51,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 's@@', 'li@@', 'de', 'di', 'giorn@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:07:51,872 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:07:51,872 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:07:51,872 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro è una slide di giornale è successo negli ultimi 25 anni.
2025-05-29 20:08:05,381 - INFO - joeynmt.training - Epoch   7, Step:    32600, Batch Loss:     1.887302, Batch Acc: 0.478743, Tokens per Sec:     5104, Lr: 0.000300
2025-05-29 20:08:18,936 - INFO - joeynmt.training - Epoch   7, Step:    32700, Batch Loss:     1.741572, Batch Acc: 0.475303, Tokens per Sec:     5204, Lr: 0.000300
2025-05-29 20:08:32,541 - INFO - joeynmt.training - Epoch   7, Step:    32800, Batch Loss:     1.859365, Batch Acc: 0.477659, Tokens per Sec:     5349, Lr: 0.000300
2025-05-29 20:08:45,932 - INFO - joeynmt.training - Epoch   7, Step:    32900, Batch Loss:     1.824634, Batch Acc: 0.484517, Tokens per Sec:     5217, Lr: 0.000300
2025-05-29 20:08:56,825 - INFO - joeynmt.training - Epoch   7: total training loss 8255.69
2025-05-29 20:08:56,825 - INFO - joeynmt.training - EPOCH 8
2025-05-29 20:08:58,758 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.706087, Batch Acc: 0.512290, Tokens per Sec:     5451, Lr: 0.000300
2025-05-29 20:08:58,758 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:10:04,013 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.25, acc:   0.46, generation: 65.2482[sec], evaluation: 0.0000[sec]
2025-05-29 20:10:04,015 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:10:04,089 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/30000.ckpt
2025-05-29 20:10:04,090 - INFO - joeynmt.training - Example #0
2025-05-29 20:10:04,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'rit@@', 'ti', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'rit@@', 'ti', 'di', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', ',', 'che', 'i', 'po@@', 'tr@@', 'em@@', 'mo', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', ',', 'che', 'i', 'gi@@', 'u@@', 'di@@', 'zi@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 'mo@@', 'ti@@', 'vi', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'pa@@', 'zi@@', 'enti', 'per', 'il', '4@@', '0@@', '%', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due diritti ho mostrato questi due diritti di sottopodi, che i potremmo sottopodi, che i giudizi, per tre milioni di anni per il 40% dei motivi per 40 per cento dei 40 per cento dei 40 per cento dei 40 per cento dei pazienti per il 40% del ghiaccio.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - Example #1
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la distanza di questo speciale è la distanza di questo speciale non è la distanza non è la distanza di ghiaccio.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - Example #2
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'sen@@', 'so', 'è', 'la', 'c@@', 'li@@', 'sta', 'ar@@', 'ia', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il senso è la clista aria del nostro sistema climatico globale.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - Example #3
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:10:04,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'ar@@', 'ono', 'nel', 'vent@@', 'o', 'e', 's@@', 'otto', 'in', 'in@@', 'ver@@', 'n@@', 'o.', '</s>']
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:10:04,091 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:10:04,092 - INFO - joeynmt.training - 	Hypothesis: Si scarono nel vento e sotto in inverno.
2025-05-29 20:10:04,092 - INFO - joeynmt.training - Example #4
2025-05-29 20:10:04,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:10:04,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:10:04,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'una', 'di@@', 'vi@@', 'sione', 'di', 'quello', 'che', 'succ@@', 'ede', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:10:04,092 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:10:04,092 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:10:04,092 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una divisione di una divisione di quello che succede negli ultimi 25 anni.
2025-05-29 20:10:17,472 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.608111, Batch Acc: 0.507565, Tokens per Sec:     5309, Lr: 0.000300
2025-05-29 20:10:30,877 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.521596, Batch Acc: 0.499659, Tokens per Sec:     5473, Lr: 0.000300
2025-05-29 20:10:44,385 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.625597, Batch Acc: 0.504137, Tokens per Sec:     5297, Lr: 0.000300
2025-05-29 20:10:57,908 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.784738, Batch Acc: 0.501933, Tokens per Sec:     5375, Lr: 0.000300
2025-05-29 20:11:12,015 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.543271, Batch Acc: 0.495693, Tokens per Sec:     5078, Lr: 0.000300
2025-05-29 20:11:12,015 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:12:20,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.26, acc:   0.46, generation: 68.1404[sec], evaluation: 0.0000[sec]
2025-05-29 20:12:20,241 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/31000.ckpt
2025-05-29 20:12:20,243 - INFO - joeynmt.training - Example #0
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'rit@@', 'ti', 'di', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'it@@', 'e,', 'per', 'con@@', 'di@@', 'vi@@', 'dere', 'che', 'la', 'c@@', 'at@@', 'tiv@@', 'ità', 'ar@@', 'e@@', 'a', 'che', 'i', 'po@@', 'ver@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'la', 'ra@@', 'gi@@', 'one', 'per', 'cui', 'il', '4@@', '0@@', '%', 'di', 'di@@', 'sc@@', 'us@@', 'sion@@', 'e.', '</s>']
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due diritti di queste due dibattite, per condividere che la cattività area che i poveri di ghiaccio per tre milioni di anni per per la ragione per cui il 40% di discussione.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - Example #1
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:12:20,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questa', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questa', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'in@@', 'zione.', '</s>']
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la distanza di questa particolare problemi di questa particolare problemi del ghiaccio non è la distinzione.
2025-05-29 20:12:20,243 - INFO - joeynmt.training - Example #2
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'c@@', 'at@@', 'tiv@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la cattiva di ghiaccio è il cuore del nostro sistema climatico globale.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - Example #3
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'in', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'po@@', 'sta', 'nel', 'vent@@', 'o.', '</s>']
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Hypothesis: Si tratta in vento e sottoposta nel vento.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - Example #4
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:12:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'di@@', 'vi@@', 'sione', 'di', 'una', 's@@', 'ort@@', 'a', 'di', 'di@@', 'sc@@', 'ut@@', 'ere', 'cosa', 'succ@@', 'e@@', 'de@@', 'va', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:12:20,244 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro è una divisione di una sorta di discutere cosa succedeva negli ultimi 25 anni.
2025-05-29 20:12:33,146 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.670011, Batch Acc: 0.493819, Tokens per Sec:     5478, Lr: 0.000300
2025-05-29 20:12:46,761 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.582373, Batch Acc: 0.495285, Tokens per Sec:     5164, Lr: 0.000300
2025-05-29 20:13:00,051 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.838966, Batch Acc: 0.492962, Tokens per Sec:     5458, Lr: 0.000300
2025-05-29 20:13:13,228 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.762068, Batch Acc: 0.497326, Tokens per Sec:     5449, Lr: 0.000300
2025-05-29 20:13:26,796 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.859245, Batch Acc: 0.495290, Tokens per Sec:     5078, Lr: 0.000300
2025-05-29 20:13:26,796 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:14:35,452 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.25, acc:   0.46, generation: 68.6494[sec], evaluation: 0.0000[sec]
2025-05-29 20:14:35,533 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/31500.ckpt
2025-05-29 20:14:35,534 - INFO - joeynmt.training - Example #0
2025-05-29 20:14:35,534 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:14:35,534 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:14:35,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'scor@@', 'si', 'di', 'questi', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o,', 'che', 'la', 'c@@', 'au@@', 'se', 'ar@@', 'e@@', 'e', 'ar@@', 'e@@', 'e', 'che', 'hanno', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', '4@@', '0@@', '%', 'di', 'b@@', 're@@', 've', 'per', '4@@', '0@@', '%', 'dei', 'c@@', 'entr@@', 'i', 'di', 'c@@', 'ad@@', 'ut@@', 'e', 'di', 'c@@', 'att@@', 'ur@@', 'are', 'il', '4@@', '0@@', '%', 'per', 'c@@', 'ento', 'di', 'questi', 'due', 'di@@', 'sc@@', 'ut@@', 'e', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'gli', 'ha', 'mostr@@', 'ato', 'questi', 'due', 'due', 'milioni', 'di', 'anni', 'di']
2025-05-29 20:14:35,534 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due discorsi di questi due dimensioni di ghiaccio, che la cause aree aree che hanno avuto per tre milioni di anni che hanno avuto per tre milioni di anni di anni di ghiaccio per 40% di breve per 40% dei centri di cadute di catturare il 40% per cento di questi due discute di ghiacciaio di milioni di anni di ghiaccio che gli ha mostrato questi due due milioni di anni di
2025-05-29 20:14:35,535 - INFO - joeynmt.training - Example #1
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 's@@', 'ens@@', 'azione', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'problem@@', 'a', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la sensazione di questo problema di questo problema di problema che non è la distanza di ghiaccio.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - Example #2
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'c@@', 'li@@', 'ico', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'ar@@', 'g@@', 'om@@', 'ent@@', 'o.', '</s>']
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cliico ghiaccio del nostro sistema argomento.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - Example #3
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'ambi@@', 'a', 'e', 's@@', 'otto', 'in', 'vent@@', 'o', 'e', 's@@', 'otto', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - 	Hypothesis: Si scambia e sotto in vento e sotto in estate.
2025-05-29 20:14:35,535 - INFO - joeynmt.training - Example #4
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:14:35,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 's@@', 'ort@@', 'a', 'di', 'di@@', 'mostr@@', 'ar@@', 'vi', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:14:35,536 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:14:35,536 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:14:35,536 - INFO - joeynmt.training - 	Hypothesis: La prossima dilide che vi mostrerò è una sorta di dimostrarvi cosa è successo negli ultimi 25 anni.
2025-05-29 20:14:48,600 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.657884, Batch Acc: 0.497594, Tokens per Sec:     5423, Lr: 0.000300
2025-05-29 20:15:02,767 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.673394, Batch Acc: 0.491972, Tokens per Sec:     5034, Lr: 0.000300
2025-05-29 20:15:16,530 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.658016, Batch Acc: 0.499097, Tokens per Sec:     5153, Lr: 0.000300
2025-05-29 20:15:29,471 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.825513, Batch Acc: 0.490566, Tokens per Sec:     5672, Lr: 0.000300
2025-05-29 20:15:42,740 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.835383, Batch Acc: 0.493556, Tokens per Sec:     5362, Lr: 0.000300
2025-05-29 20:15:42,740 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:16:53,881 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.23, acc:   0.47, generation: 71.1345[sec], evaluation: 0.0000[sec]
2025-05-29 20:16:53,883 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:16:53,959 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/32500.ckpt
2025-05-29 20:16:53,960 - INFO - joeynmt.training - Example #0
2025-05-29 20:16:53,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'questi', 'due', 'di@@', 'a@@', 'str@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'cap@@', 'ac@@', 'ità', 'ar@@', 'ia', 'che', 'la', 'gente', 'ar@@', 'ia', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'la', 'ra@@', 'gi@@', 'one', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'po@@', 'm@@', 'p@@', 'a.', '</s>']
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due dimensioni di questi due diastri di ghiaccio che la capacità aria che la gente aria dei livelli di ghiaccio per tre milioni di anni la ragione di 40 per cento milioni di anni per cento di pompa.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - Example #1
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'ric@@', 'o@@', 'stru@@', 'zione', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'g@@', 'hi@@', 'acci@@', 'o', 'della', 'g@@', 'hi@@', 'acci@@', 'a.', '</s>']
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la ricostruzione di questo specifico non è la distanza di questo ghiaccio della ghiaccia.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - Example #2
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'p@@', 'an@@', 'sione', 'ar@@', 't@@', 'ica', 'è', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ento', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la pansione artica è il cuore argomento di climatica.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - Example #3
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:16:53,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'otto', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sotto in estate.
2025-05-29 20:16:53,961 - INFO - joeynmt.training - Example #4
2025-05-29 20:16:53,962 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:16:53,962 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:16:53,962 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 're@@', 'gi@@', 'one', 'di', 'temp@@', 'o,', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:16:53,962 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:16:53,962 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:16:53,962 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una regione di tempo, è successo negli ultimi 25 anni.
2025-05-29 20:17:06,430 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.699833, Batch Acc: 0.493871, Tokens per Sec:     5865, Lr: 0.000300
2025-05-29 20:17:19,284 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.560198, Batch Acc: 0.496054, Tokens per Sec:     5363, Lr: 0.000300
2025-05-29 20:17:32,523 - INFO - joeynmt.training - Epoch   8, Step:    34800, Batch Loss:     1.638213, Batch Acc: 0.492363, Tokens per Sec:     5579, Lr: 0.000300
2025-05-29 20:17:45,651 - INFO - joeynmt.training - Epoch   8, Step:    34900, Batch Loss:     1.711726, Batch Acc: 0.489407, Tokens per Sec:     5498, Lr: 0.000300
2025-05-29 20:17:59,004 - INFO - joeynmt.training - Epoch   8, Step:    35000, Batch Loss:     1.683256, Batch Acc: 0.492937, Tokens per Sec:     5487, Lr: 0.000300
2025-05-29 20:17:59,004 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:19:02,954 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.19, acc:   0.46, generation: 63.9433[sec], evaluation: 0.0000[sec]
2025-05-29 20:19:02,955 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:19:03,033 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/32000.ckpt
2025-05-29 20:19:03,035 - INFO - joeynmt.training - Example #0
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'sc@@', 'us@@', 'sion@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 's@@', 'cont@@', 'are', 'che', "l'@@", 'es@@', 'peri@@', 'enza', 'ar@@', 'ram@@', 'pic@@', 'ata', 'per', 'tre', 'milioni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', '4@@', '0', 'per@@', 'c@@', 'ento', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'ento', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'c@@', 'att@@', 'ur@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'per', 'c@@', 'ento', 'dei', 'p@@', 'es@@', 'i.', '</s>']
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due discussioni di ghiaccio per scontare che l'esperienza arrampicata per tre milioni di ghiaccio per tre milioni di anni che hanno avuto 40 percento milioni di anni per il 40 percento di cento di 40 percento di catturare il 40 percento per cento dei pesi.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - Example #1
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte la speciale di questo problema di questo problema di questo problema non è la distanza non è la distanza di ghiaccio.
2025-05-29 20:19:03,035 - INFO - joeynmt.training - Example #2
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:19:03,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'ar@@', 'ca', 'la', 'c@@', 'li@@', 'ma', 'del', 'nostro', 'sistema', 'ar@@', 'g@@', 'om@@', 'ent@@', 'are', 'il', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore arca la clima del nostro sistema argomentare il clima.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - Example #3
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'ar@@', 'ono', 'in', 'vent@@', 'o', 'e', 's@@', 'ot@@', 'ti@@', '.', '</s>']
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Hypothesis: Si scarono in vento e sotti.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - Example #4
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:19:03,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 's@@', 'li@@', 'de', 'di', 'temp@@', 'or@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '5', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '5', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '.', '</s>']
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:19:03,036 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una slide di temporale negli ultimi 25 anni 25 è successo negli ultimi 25 anni 25 è successo negli ultimi 25 anni 2.
2025-05-29 20:19:16,086 - INFO - joeynmt.training - Epoch   8, Step:    35100, Batch Loss:     1.539669, Batch Acc: 0.485777, Tokens per Sec:     5218, Lr: 0.000300
2025-05-29 20:19:29,376 - INFO - joeynmt.training - Epoch   8, Step:    35200, Batch Loss:     1.576367, Batch Acc: 0.492695, Tokens per Sec:     5238, Lr: 0.000300
2025-05-29 20:19:42,481 - INFO - joeynmt.training - Epoch   8, Step:    35300, Batch Loss:     1.652205, Batch Acc: 0.492241, Tokens per Sec:     5266, Lr: 0.000300
2025-05-29 20:19:56,245 - INFO - joeynmt.training - Epoch   8, Step:    35400, Batch Loss:     1.685127, Batch Acc: 0.491339, Tokens per Sec:     5155, Lr: 0.000300
2025-05-29 20:20:09,631 - INFO - joeynmt.training - Epoch   8, Step:    35500, Batch Loss:     1.641947, Batch Acc: 0.489366, Tokens per Sec:     5297, Lr: 0.000300
2025-05-29 20:20:09,631 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:21:13,357 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.16, acc:   0.47, generation: 63.7198[sec], evaluation: 0.0000[sec]
2025-05-29 20:21:13,358 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:21:13,437 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/33500.ckpt
2025-05-29 20:21:13,438 - INFO - joeynmt.training - Example #0
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'vol@@', 'te', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'po@@', 'tr@@', 'em@@', 'mo', 's@@', 'ott@@', 'o@@', 'ter@@', 'ra,', 'che', 'i', 'su@@', 'oi', 'li@@', 'ber@@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'ac@@', 'chi', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', '4@@', '0', 'per', 'c@@', 'ento', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'di', '3@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'acci@@', 'ar@@', 'si', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'g@@']
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due volte ho mostrato queste due volte per ridurre il ghiaccio che i potremmo sottoterra, che i suoi liberi di tre milioni di anni per il 40% dei sacchi di ghiaccio per 40 per cento di 40 per cento di 30 per cento di tre milioni di anni per per il 40 per cento di ghiacciarsi per il 40 per cento di ghiaccio per tre milioni di anni per il 40 per cento di g
2025-05-29 20:21:13,439 - INFO - joeynmt.training - Example #1
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'pr@@', 'ev@@', 'en@@', 'zione', 'di', 'questo', 't@@', 'al@@', 'k', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la prevenzione di questo talk non è la distanza non è la distanza non è la distanza del ghiaccio.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - Example #2
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'glob@@', 'ale.', '</s>']
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - 	Hypothesis: In un certo senso è la ghiaccia di ghiaccio di ghiaccio globale.
2025-05-29 20:21:13,439 - INFO - joeynmt.training - Example #3
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:21:13,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'po@@', 'sta', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Hypothesis: Si sposta in inverno, e in estate.
2025-05-29 20:21:13,440 - INFO - joeynmt.training - Example #4
2025-05-29 20:21:13,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:21:13,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:21:13,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'vi@@', 'sione', 'di', 'una', 'vi@@', 'sione', 'di', 'una', 'vi@@', 'sione', 'di', 'questa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:21:13,440 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una visione di una visione di una visione di questa è successo negli ultimi 25 anni.
2025-05-29 20:21:26,343 - INFO - joeynmt.training - Epoch   8, Step:    35600, Batch Loss:     1.756471, Batch Acc: 0.490833, Tokens per Sec:     5415, Lr: 0.000300
2025-05-29 20:21:39,637 - INFO - joeynmt.training - Epoch   8, Step:    35700, Batch Loss:     1.662135, Batch Acc: 0.485481, Tokens per Sec:     5178, Lr: 0.000300
2025-05-29 20:21:52,968 - INFO - joeynmt.training - Epoch   8, Step:    35800, Batch Loss:     1.726772, Batch Acc: 0.489806, Tokens per Sec:     5317, Lr: 0.000300
2025-05-29 20:22:06,353 - INFO - joeynmt.training - Epoch   8, Step:    35900, Batch Loss:     1.617648, Batch Acc: 0.495091, Tokens per Sec:     5326, Lr: 0.000300
2025-05-29 20:22:19,808 - INFO - joeynmt.training - Epoch   8, Step:    36000, Batch Loss:     1.757769, Batch Acc: 0.487231, Tokens per Sec:     5335, Lr: 0.000300
2025-05-29 20:22:19,808 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:23:29,103 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.16, acc:   0.46, generation: 69.2886[sec], evaluation: 0.0000[sec]
2025-05-29 20:23:29,183 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/34000.ckpt
2025-05-29 20:23:29,183 - INFO - joeynmt.training - Example #0
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['N@@', 'el', 'cor@@', 'so', 'di', 'cui', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'iti', 'per', 's@@', 'ott@@', 'o@@', 'ter@@', 'ra', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 's@@', 'b@@', 'agli@@', 'a', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'i', 'di', 's@@', 'egn@@', 'i', 'di', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Hypothesis: Nel corso di cui ho mostrato queste due dibattiti per sottoterra per tre milioni di anni di ghiaccio che la sbaglia che per tre milioni di anni per i tre milioni di anni per il 40 per tre milioni di anni per il 40 per cento dei segni di segni di sottopo.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - Example #1
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 'se', 'la', 'for@@', 't@@', 'una', 'di', 'di@@', 'st@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'cosa', 'che', 'non', 'è', 'la', 'cosa', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Hypothesis: Ma non è forse la fortuna di distanza di questo speciale non è la cosa che non è la cosa che non è la distanza che non è la distanza di ghiaccio.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - Example #2
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 's@@', 'ens@@', 'azione', 'ar@@', 'ia', 'del', 'nostro', 'sistema', 'ar@@', 'g@@', 'om@@', 'ent@@', 'ar@@', 'io', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la sensazione aria del nostro sistema argomentario globale del nostro sistema clima.
2025-05-29 20:23:29,184 - INFO - joeynmt.training - Example #3
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:23:29,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'ino', 'e', 's@@', 'ot@@', 'ti@@', 'le', 'nel', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un ventino e sottile nel estate.
2025-05-29 20:23:29,185 - INFO - joeynmt.training - Example #4
2025-05-29 20:23:29,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:23:29,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:23:29,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'st@@', 'en@@', 'or@@', 'me', 'di', 'una', 'st@@', 'am@@', 'p@@', 'a', 'cosa', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:23:29,185 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro è una stenorme di una stampa cosa negli ultimi 25 anni.
2025-05-29 20:23:42,310 - INFO - joeynmt.training - Epoch   8, Step:    36100, Batch Loss:     1.959298, Batch Acc: 0.488437, Tokens per Sec:     5419, Lr: 0.000300
2025-05-29 20:23:55,648 - INFO - joeynmt.training - Epoch   8, Step:    36200, Batch Loss:     1.697159, Batch Acc: 0.491462, Tokens per Sec:     5159, Lr: 0.000300
2025-05-29 20:24:09,099 - INFO - joeynmt.training - Epoch   8, Step:    36300, Batch Loss:     1.706540, Batch Acc: 0.489390, Tokens per Sec:     5122, Lr: 0.000300
2025-05-29 20:24:22,732 - INFO - joeynmt.training - Epoch   8, Step:    36400, Batch Loss:     1.831185, Batch Acc: 0.490705, Tokens per Sec:     5232, Lr: 0.000300
2025-05-29 20:24:36,231 - INFO - joeynmt.training - Epoch   8, Step:    36500, Batch Loss:     1.586539, Batch Acc: 0.486943, Tokens per Sec:     5311, Lr: 0.000300
2025-05-29 20:24:36,231 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:25:51,692 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.14, acc:   0.47, generation: 75.4539[sec], evaluation: 0.0000[sec]
2025-05-29 20:25:51,693 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:25:51,774 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/33000.ckpt
2025-05-29 20:25:51,776 - INFO - joeynmt.training - Example #0
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', "l'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 're@@', 'zioni', 'che', 'la', 'di@@', 'men@@', 'sione', 'che', 'la', 'gente', 'è', 'che', 'la', 'gente', 'che', 'la', 'gente', 'sono', 'i', 'tre', 'milioni', 'di', 'anni', 'che', 'la', 'ra@@', 'gi@@', 'one', 'di', 'ci@@', 'b@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'mit@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'i', 'di', 'm@@', 'ezz@@', 'o.', '</s>']
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Hypothesis: E l'anno scorso ho mostrato queste due direzioni che la dimensione che la gente è che la gente che la gente sono i tre milioni di anni che la ragione di cibo per tre milioni di anni per il 40 per cento dei limiti di 40 percento dei segni di 40 percento dei segni di mezzo.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - Example #1
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'for@@', 't@@', 'una', 'di', 'di@@', 'st@@', 'anza', 'di', 'questa', 'sp@@', 'eci@@', 'e,', 'perché', 'non', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'il', 'di@@', 'scor@@', 'so', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato fortuna di distanza di questa specie, perché non è il problema di questo speciale non è il discorso del ghiaccio del ghiaccio.
2025-05-29 20:25:51,776 - INFO - joeynmt.training - Example #2
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:25:51,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'della', 'g@@', 'hi@@', 'acci@@', 'a', 'del', 'c@@', 'li@@', 'ma@@', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore della ghiaccia del clima, il cuore globale del nostro sistema climatico.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - Example #3
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'en@@', 'a', 'in', 'v@@', 'in@@', 'a,', 'e', 'r@@', 'ot@@', 'te', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Hypothesis: Si scena in vina, e rotte in estate in estate in estate.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - Example #4
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:25:51,777 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 's@@', 'li@@', 'de', 'di', 'temp@@', 'or@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:25:51,777 - INFO - joeynmt.training - 	Hypothesis: La prossima dilide che vi mostrerò una slide di temporale è successo negli ultimi 25 anni.
2025-05-29 20:26:05,654 - INFO - joeynmt.training - Epoch   8, Step:    36600, Batch Loss:     1.813303, Batch Acc: 0.488125, Tokens per Sec:     4982, Lr: 0.000300
2025-05-29 20:26:18,676 - INFO - joeynmt.training - Epoch   8, Step:    36700, Batch Loss:     1.754164, Batch Acc: 0.490647, Tokens per Sec:     5543, Lr: 0.000300
2025-05-29 20:26:31,847 - INFO - joeynmt.training - Epoch   8, Step:    36800, Batch Loss:     1.707224, Batch Acc: 0.492011, Tokens per Sec:     5574, Lr: 0.000300
2025-05-29 20:26:45,284 - INFO - joeynmt.training - Epoch   8, Step:    36900, Batch Loss:     1.759360, Batch Acc: 0.489544, Tokens per Sec:     5249, Lr: 0.000300
2025-05-29 20:26:59,022 - INFO - joeynmt.training - Epoch   8, Step:    37000, Batch Loss:     1.573062, Batch Acc: 0.490367, Tokens per Sec:     5150, Lr: 0.000300
2025-05-29 20:26:59,022 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:28:06,284 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.15, acc:   0.47, generation: 67.1407[sec], evaluation: 0.0000[sec]
2025-05-29 20:28:06,364 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/34500.ckpt
2025-05-29 20:28:06,364 - INFO - joeynmt.training - Example #0
2025-05-29 20:28:06,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:28:06,364 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:28:06,364 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'iti', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'gente', 'ar@@', 'g@@', 'om@@', 'ento', 'po@@', 'ver@@', 'a', 'che', 'la', 'gente', 'si', 'chiam@@', 'a', 'li@@', 'vello', 'ar@@', 'ia', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'la', 'ra@@', 'gi@@', 'one', 'di', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'mit@@', 'i', 'di', 'po@@', 'ter', 'ri@@', 'dur@@', 're', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'po@@', 'pol@@', 'i', 'ar@@', 'i.', '</s>']
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due dibattiti per ridurre il ghiaccio che la gente argomento povera che la gente si chiama livello aria per tre milioni di anni per la ragione di 40 per cento dei 40 per cento dei 40 per cento dei 40 per cento dei limiti di poter ridurre il 40 per cento dei livelli popoli ari.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - Example #1
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'pr@@', 'em@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Hypothesis: Ma non è stato abbastanza forte la prema di questo specifico di questo specifico non è la distanza che non è la distanza di ghiaccio.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - Example #2
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di ghiaccio di climatico globale.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - Example #3
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:28:06,365 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 's@@', 'ot@@', 'ti@@', 'le', 'in', 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'ol@@', 'i.', '</s>']
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e sottile in estate e rotoli.
2025-05-29 20:28:06,365 - INFO - joeynmt.training - Example #4
2025-05-29 20:28:06,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:28:06,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:28:06,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cosa', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:28:06,366 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:28:06,366 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:28:06,366 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una cosa che è successo negli ultimi 25 anni.
2025-05-29 20:28:19,090 - INFO - joeynmt.training - Epoch   8, Step:    37100, Batch Loss:     1.730680, Batch Acc: 0.491813, Tokens per Sec:     5547, Lr: 0.000300
2025-05-29 20:28:32,455 - INFO - joeynmt.training - Epoch   8, Step:    37200, Batch Loss:     1.779913, Batch Acc: 0.488198, Tokens per Sec:     5266, Lr: 0.000300
2025-05-29 20:28:45,734 - INFO - joeynmt.training - Epoch   8, Step:    37300, Batch Loss:     1.752552, Batch Acc: 0.492019, Tokens per Sec:     5487, Lr: 0.000300
2025-05-29 20:28:59,061 - INFO - joeynmt.training - Epoch   8, Step:    37400, Batch Loss:     1.747742, Batch Acc: 0.483332, Tokens per Sec:     5292, Lr: 0.000300
2025-05-29 20:29:12,074 - INFO - joeynmt.training - Epoch   8, Step:    37500, Batch Loss:     1.716594, Batch Acc: 0.491726, Tokens per Sec:     5447, Lr: 0.000300
2025-05-29 20:29:12,074 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:30:26,321 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.09, acc:   0.47, generation: 74.2397[sec], evaluation: 0.0000[sec]
2025-05-29 20:30:26,323 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:30:26,419 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/35000.ckpt
2025-05-29 20:30:26,419 - INFO - joeynmt.training - Example #0
2025-05-29 20:30:26,419 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:30:26,419 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:30:26,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'it@@', 'e,', 'per', 'ri@@', 'dur@@', 're', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 's@@', 'ott@@', 'ic@@', 'i,', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', '.', '</s>']
2025-05-29 20:30:26,419 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:30:26,419 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:30:26,419 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno, ho mostrato queste due dibattite, per ridurre il ghiaccio di ghiaccio che i sottici, che per tre milioni di anni per tre milioni di anni per i 40 per cento dei livelli di sottopodi.
2025-05-29 20:30:26,419 - INFO - joeynmt.training - Example #1
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questa', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte la distanza di questa particolare problemi di questo particolare problemi del ghiaccio non è la distanza del ghiaccio.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - Example #2
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di ghiaccio il cuore del nostro sistema climatico.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - Example #3
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'en@@', 'a', 'nel', 'vent@@', 'o', 'e', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', 'ano', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'l@@', 'ì@@', '.', '</s>']
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Hypothesis: Si scena nel vento e sottopodiano in estate in estate in estate in estate lì.
2025-05-29 20:30:26,420 - INFO - joeynmt.training - Example #4
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:30:26,420 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'f@@', 'era', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'giorn@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:30:26,420 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:30:26,421 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:30:26,421 - INFO - joeynmt.training - 	Hypothesis: La prossima sfera che vi mostro è una giornale che è successo negli ultimi 25 anni.
2025-05-29 20:30:40,183 - INFO - joeynmt.training - Epoch   8, Step:    37600, Batch Loss:     1.631317, Batch Acc: 0.493011, Tokens per Sec:     5187, Lr: 0.000300
2025-05-29 20:30:53,032 - INFO - joeynmt.training - Epoch   8, Step:    37700, Batch Loss:     1.778027, Batch Acc: 0.487645, Tokens per Sec:     5496, Lr: 0.000300
2025-05-29 20:30:53,032 - INFO - joeynmt.training - Epoch   8: total training loss 8055.41
2025-05-29 20:30:53,032 - INFO - joeynmt.training - EPOCH 9
2025-05-29 20:31:06,585 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.700323, Batch Acc: 0.508167, Tokens per Sec:     5308, Lr: 0.000300
2025-05-29 20:31:20,073 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.676363, Batch Acc: 0.514116, Tokens per Sec:     5441, Lr: 0.000300
2025-05-29 20:31:33,666 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.749890, Batch Acc: 0.506480, Tokens per Sec:     5285, Lr: 0.000300
2025-05-29 20:31:33,666 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:32:55,066 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.14, acc:   0.47, generation: 81.3924[sec], evaluation: 0.0000[sec]
2025-05-29 20:32:55,146 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/36000.ckpt
2025-05-29 20:32:55,146 - INFO - joeynmt.training - Example #0
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'questo', 'due', 'li@@', 'mit@@', 'i', 'di', 'questi', 'due', 'li@@', 'ev@@', 'i', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'ati', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'p@@', 'eg@@', 'gi@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'i', 'per', 'il', '4@@', '0@@', '%', 'dei', '4@@', '0@@', '%', 'dei', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', '</s>']
2025-05-29 20:32:55,146 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:32:55,146 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:32:55,146 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno questo due limiti di questi due lievi che i ghiacciati di ghiaccio che i peggiati per tre milioni di anni per tre milioni di anni per tre milioni di anni per il 40% dei segni per il 40% dei 40% dei 40% del 40%
2025-05-29 20:32:55,146 - INFO - joeynmt.training - Example #1
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:32:55,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', "l'@@", 'es@@', 'peri@@', 'enza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'il', 'di@@', 'mostr@@', 'a', 'il', 'di@@', 'sc@@', 'us@@', 'so', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte l'esperienza di questo speciale è il problema di questo speciale non è il dimostra il discusso del ghiaccio.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - Example #2
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ent@@', 'o,', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il ghiaccio è il cuore argomento, il cuore globale del nostro sistema climatico globale.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - Example #3
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'e', 'si', 's@@', 'po@@', 'sta', 'nel', 'm@@', 'e.', '</s>']
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento e si sposta nel me.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - Example #4
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:32:55,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'di@@', 'vi@@', 'sione', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 's@@', 'li@@', 'de', 'di', 'temp@@', 'or@@', 'ale', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:32:55,147 - INFO - joeynmt.training - 	Hypothesis: La divisione che vi mostro è una slide di temporale che è successo negli ultimi 25 anni.
2025-05-29 20:33:09,002 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.706516, Batch Acc: 0.510367, Tokens per Sec:     5278, Lr: 0.000300
2025-05-29 20:33:23,018 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.571998, Batch Acc: 0.509363, Tokens per Sec:     5007, Lr: 0.000300
2025-05-29 20:33:37,038 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.590738, Batch Acc: 0.505975, Tokens per Sec:     5121, Lr: 0.000300
2025-05-29 20:33:50,545 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.782387, Batch Acc: 0.505733, Tokens per Sec:     5153, Lr: 0.000300
2025-05-29 20:34:04,465 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.441968, Batch Acc: 0.504584, Tokens per Sec:     5132, Lr: 0.000300
2025-05-29 20:34:04,465 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:35:13,550 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.12, acc:   0.47, generation: 69.0787[sec], evaluation: 0.0000[sec]
2025-05-29 20:35:13,627 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/35500.ckpt
2025-05-29 20:35:13,628 - INFO - joeynmt.training - Example #0
2025-05-29 20:35:13,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:35:13,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:35:13,628 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'o', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'li@@', 'mit@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'cap@@', 'ac@@', 'ità', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'po@@', 'ver@@', 'i', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '8@@', '0@@', '%', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'dei', 'mi@@', 'ei', 'li@@', 'mit@@', 'i', 'di', 'anni', 'per', 'f@@', 'a.', '</s>']
2025-05-29 20:35:13,628 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:35:13,628 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:35:13,628 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno, ho mostrato queste due limiti di ghiaccio che la capacità di ghiaccio che i poveri di tre milioni di anni per tre milioni di anni per i 480% di anni per il 40% di anni per il 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% dei miei limiti di anni per fa.
2025-05-29 20:35:13,628 - INFO - joeynmt.training - Example #1
2025-05-29 20:35:13,628 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:35:13,628 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'in@@', 'ta', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'perché', 'non', 'lo', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la distinta di questo speciale non è la distanza di questo speciale non è la distanza perché non lo mostra il ghiaccio.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - Example #2
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ent@@', 'ico', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore argomentico del nostro sistema di climaticale del nostro sistema climatico.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - Example #3
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'nel', 'vent@@', 'o', 'e', 'in', 'vent@@', 'o.', '</s>']
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Hypothesis: Si è nel vento e in vento.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - Example #4
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:35:13,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'con@@', 'di@@', 'vi@@', 'sione', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'cam@@', 'era', 'di', 'temp@@', 'o,', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'di', 'cui', 'vi', 'vi', 'mostr@@', 'er@@', 'ò', 'ciò', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'una', 'cam@@', 'era', 'di', 'temp@@', 'o.', '</s>']
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:35:13,629 - INFO - joeynmt.training - 	Hypothesis: La prossima condivisione che vi mostrerò è una camera di tempo, è successo negli ultimi 25 anni negli ultimi 25 anni negli ultimi 25 anni negli ultimi 25 anni negli ultimi 25 anni di cui vi vi mostrerò ciò che vi mostrerò una camera di tempo.
2025-05-29 20:35:26,967 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.684043, Batch Acc: 0.508233, Tokens per Sec:     5464, Lr: 0.000300
2025-05-29 20:35:40,595 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.683768, Batch Acc: 0.504742, Tokens per Sec:     5324, Lr: 0.000300
2025-05-29 20:35:54,206 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.514798, Batch Acc: 0.503854, Tokens per Sec:     5109, Lr: 0.000300
2025-05-29 20:36:07,669 - INFO - joeynmt.training - Epoch   9, Step:    38900, Batch Loss:     1.673386, Batch Acc: 0.502157, Tokens per Sec:     5373, Lr: 0.000300
2025-05-29 20:36:21,306 - INFO - joeynmt.training - Epoch   9, Step:    39000, Batch Loss:     1.608152, Batch Acc: 0.499493, Tokens per Sec:     5277, Lr: 0.000300
2025-05-29 20:36:21,306 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:37:25,141 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.11, acc:   0.47, generation: 63.8285[sec], evaluation: 0.0000[sec]
2025-05-29 20:37:25,219 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/37000.ckpt
2025-05-29 20:37:25,219 - INFO - joeynmt.training - Example #0
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'b@@', 'att@@', 'it@@', 'e', 'che', 'i', 'di@@', 'sp@@', 'oni@@', 'bi@@', 'li', 'che', 'le', 'di@@', 'st@@', 'anz@@', 'e', 'po@@', 'ver@@', 'i', 'ar@@', 'd@@', 'ini', 'po@@', 'ver@@', 'i', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'è', 'ri@@', 'ma@@', 'sto', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'tre', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'ci@@', 'b@@', 'o', 'che', 'è', 'stato', 'di@@', 'mostr@@', 'ato', 'a', 'con@@', 'temp@@', 'or@@', 'an@@', 'e@@', 'o', 'che', 'è', 'stato', 'di', 'fatto', 'che', 'la', 'ra@@', 'gi@@', 'one', 'di', 'pi@@', 'ù@@', ',', 'per', 'tre', 'milioni', 'di', 'anni']
2025-05-29 20:37:25,219 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:37:25,219 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:37:25,219 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due dibattite che i disponibili che le distanze poveri ardini poveri che per tre milioni di anni che si è rimasto che per tre milioni di anni per il 40 per cento di tre milioni di anni per cento di tre di anni per il 40 per cento di tre milioni di anni di anni di cibo che è stato dimostrato a contemporaneo che è stato di fatto che la ragione di più, per tre milioni di anni
2025-05-29 20:37:25,219 - INFO - joeynmt.training - Example #1
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:37:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'pr@@', 'em@@', 'ess@@', 'a', 'abb@@', 'ast@@', 'anza', 'part@@', 'icol@@', 'ar@@', 'mente', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'che', 'non', 'è', 'la', 'de@@', 'st@@', 'in@@', 'a.', '</s>']
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la premessa abbastanza particolarmente questo specifico non è la destinazione che non è la destina.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - Example #2
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'c@@', 'li@@', 'ma', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il ghiaccio è il clima il cuore globale del nostro sistema climatico.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - Example #3
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'vent@@', 'ur@@', 'o', 'e', 'r@@', 'ot@@', 'ta', 'nel', 'vent@@', 'o.', '</s>']
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Hypothesis: Si tratta di venturo e rotta nel vento.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - Example #4
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:37:25,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'di@@', 'sc@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'giorn@@', 'ale', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:37:25,220 - INFO - joeynmt.training - 	Hypothesis: Il prossimo disco che vi mostrerò è una giornale che vi mostrerò cosa è successo negli ultimi 25 anni.
2025-05-29 20:37:38,460 - INFO - joeynmt.training - Epoch   9, Step:    39100, Batch Loss:     1.708680, Batch Acc: 0.505370, Tokens per Sec:     5195, Lr: 0.000300
2025-05-29 20:37:52,105 - INFO - joeynmt.training - Epoch   9, Step:    39200, Batch Loss:     1.660963, Batch Acc: 0.500352, Tokens per Sec:     5106, Lr: 0.000300
2025-05-29 20:38:05,431 - INFO - joeynmt.training - Epoch   9, Step:    39300, Batch Loss:     1.537470, Batch Acc: 0.503368, Tokens per Sec:     5202, Lr: 0.000300
2025-05-29 20:38:19,218 - INFO - joeynmt.training - Epoch   9, Step:    39400, Batch Loss:     1.623694, Batch Acc: 0.505452, Tokens per Sec:     5195, Lr: 0.000300
2025-05-29 20:38:33,171 - INFO - joeynmt.training - Epoch   9, Step:    39500, Batch Loss:     1.772936, Batch Acc: 0.498493, Tokens per Sec:     5040, Lr: 0.000300
2025-05-29 20:38:33,171 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:39:40,798 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.11, acc:   0.47, generation: 67.6208[sec], evaluation: 0.0000[sec]
2025-05-29 20:39:40,877 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/36500.ckpt
2025-05-29 20:39:40,878 - INFO - joeynmt.training - Example #0
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'vol@@', 'te', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'i', 'che', 'i', 'po@@', 'pol@@', 'i', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i,', 'che', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'la', 'ra@@', 'gi@@', 'one', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'dei', '4@@', '8', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 'g@@', 'hi@@', 'acci@@', 'a@@', 'i.', '</s>']
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due volte ho mostrato questi due diapositivi che i popoli argomenti, che i poveri arghiaccio per tre milioni di anni la ragione per tre milioni di anni per il 40% dei 48 milioni di anni per cento dei 40 per cento dei 40 per cento dei ghiacciai.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - Example #1
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'il', 'p@@', 'es@@', 'o', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'm@@', 'ant@@', 'en@@', 'i@@', 'bil@@', 'ità', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il peso è abbastanza di questo speciale di questo speciale non è la mantenibilità di ghiaccio del ghiaccio del ghiaccio.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - Example #2
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:39:40,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'E@@', 'is@@', 'k@@', 'e', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di Eiske del nostro sistema climatico globale del nostro sistema climatico.
2025-05-29 20:39:40,878 - INFO - joeynmt.training - Example #3
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'post@@', 'ano', 'in', 'in@@', 'ver@@', 'n@@', 'o,', 'e', 'si', 's@@', 'post@@', 'ano', 'in', 'est@@', 'ate', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Hypothesis: Si spostano in inverno, e si spostano in estate sotto.
2025-05-29 20:39:40,879 - INFO - joeynmt.training - Example #4
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:39:40,879 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:39:40,879 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò cosa è successo negli ultimi 25 anni.
2025-05-29 20:39:54,439 - INFO - joeynmt.training - Epoch   9, Step:    39600, Batch Loss:     1.721619, Batch Acc: 0.496737, Tokens per Sec:     5269, Lr: 0.000300
2025-05-29 20:40:08,123 - INFO - joeynmt.training - Epoch   9, Step:    39700, Batch Loss:     1.599823, Batch Acc: 0.499619, Tokens per Sec:     5176, Lr: 0.000300
2025-05-29 20:40:21,370 - INFO - joeynmt.training - Epoch   9, Step:    39800, Batch Loss:     1.743740, Batch Acc: 0.497509, Tokens per Sec:     5304, Lr: 0.000300
2025-05-29 20:40:34,696 - INFO - joeynmt.training - Epoch   9, Step:    39900, Batch Loss:     1.527490, Batch Acc: 0.491825, Tokens per Sec:     5365, Lr: 0.000300
2025-05-29 20:40:47,853 - INFO - joeynmt.training - Epoch   9, Step:    40000, Batch Loss:     1.702576, Batch Acc: 0.500754, Tokens per Sec:     5446, Lr: 0.000300
2025-05-29 20:40:47,853 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:42:06,816 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.09, acc:   0.47, generation: 78.9561[sec], evaluation: 0.0000[sec]
2025-05-29 20:42:06,898 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/38000.ckpt
2025-05-29 20:42:06,898 - INFO - joeynmt.training - Example #0
2025-05-29 20:42:06,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:42:06,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:42:06,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'sc@@', 'en@@', 'der@@', 'si', 'che', 'i', 'con@@', 'ten@@', 'gono', 'che', 'i', 'po@@', 'pol@@', 'i', 'ar@@', 'i,', 'che', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'd@@', 'ini', 'po@@', 'i,', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni', 'di', 'fon@@', 'do', 'per', 'i', '4@@', '8', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0@@', '%', 'di', 'c@@', 'ento', 'per', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0@@', '%', 'del', 'po@@', 'ter@@', 'e.', '</s>']
2025-05-29 20:42:06,898 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato questi due discendersi che i contengono che i popoli ari, che i poveri ardini poi, che per tre milioni di anni di anni di fondo per i 48 milioni di anni per per il 40% di cento per il 40% per il 40% del potere.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - Example #1
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'il', 'problem@@', 'a', 'è', 'abb@@', 'ast@@', 'anza', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'di@@', 'mostr@@', 'a', 'che', 'non', 'è', 'la', 'mostr@@', 'a', 'della', 'chi@@', 'av@@', 'e', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte il problema è abbastanza di questo specifico non è la dimostra che non è la mostra della chiave del ghiaccio.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - Example #2
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', "l'@@", 'is@@', 'co@@', 'di@@', 'ce', 'che', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'ar@@', 'an@@', 'c@@', 'at@@', 'ico.', '</s>']
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, l'iscodice che il cuore del nostro sistema arancatico.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - Example #3
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'b@@', 'agli@@', 'ato', 'nel', 'vent@@', 'o', 'e', 'r@@', 'om@@', 'p@@', 'o.', '</s>']
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - 	Hypothesis: Si è sbagliato nel vento e rompo.
2025-05-29 20:42:06,899 - INFO - joeynmt.training - Example #4
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:42:06,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'con@@', 'di@@', 'vi@@', 'sione', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'succ@@', 'esso', 'in', 'un', 'mom@@', 'ento', 'in', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:42:06,900 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:42:06,900 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:42:06,900 - INFO - joeynmt.training - 	Hypothesis: La prossima condivisione che vi mostrerò è successo in un momento in cui è successo negli ultimi 25 anni.
2025-05-29 20:42:20,260 - INFO - joeynmt.training - Epoch   9, Step:    40100, Batch Loss:     1.695261, Batch Acc: 0.498889, Tokens per Sec:     5388, Lr: 0.000300
2025-05-29 20:42:33,964 - INFO - joeynmt.training - Epoch   9, Step:    40200, Batch Loss:     1.771953, Batch Acc: 0.495614, Tokens per Sec:     5224, Lr: 0.000300
2025-05-29 20:42:47,504 - INFO - joeynmt.training - Epoch   9, Step:    40300, Batch Loss:     1.908925, Batch Acc: 0.496604, Tokens per Sec:     5405, Lr: 0.000300
2025-05-29 20:43:00,907 - INFO - joeynmt.training - Epoch   9, Step:    40400, Batch Loss:     1.685540, Batch Acc: 0.504444, Tokens per Sec:     5390, Lr: 0.000300
2025-05-29 20:43:14,551 - INFO - joeynmt.training - Epoch   9, Step:    40500, Batch Loss:     1.622269, Batch Acc: 0.496601, Tokens per Sec:     5100, Lr: 0.000300
2025-05-29 20:43:14,551 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:44:18,657 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.08, acc:   0.47, generation: 64.0994[sec], evaluation: 0.0000[sec]
2025-05-29 20:44:18,658 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:44:18,734 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/38500.ckpt
2025-05-29 20:44:18,734 - INFO - joeynmt.training - Example #0
2025-05-29 20:44:18,734 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:44:18,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:44:18,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 's@@', 'li@@', 'de', 'per', 'ri@@', 'dur@@', 're', 'questo', 'due', 's@@', 'li@@', 'de', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'cap@@', 'ac@@', 'ità', 'ar@@', 'ia', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'la', 'ra@@', 'gion@@', 'e,', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'delle', 'ra@@', 'gion@@', 'i', 'per', 'cui', '4@@', '0@@', '%', 'delle', 'ra@@', 'gion@@', 'i', 'per', 'cui', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'delle', 's@@', 'li@@', 'de', 'che', 'il', '4@@', '0@@', '%', 'delle', 'ra@@', 'gion@@', 'i', 'po@@', 'pol@@', 'i@@', 'e.', '</s>']
2025-05-29 20:44:18,734 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due slide per ridurre questo due slide di ghiaccio che la capacità aria di ghiaccio per tre milioni di anni per la ragione, per tre milioni di anni per il 40% delle ragioni per cui 40% delle ragioni per cui il 40% del 40% delle slide che il 40% delle ragioni popolie.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - Example #1
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'il', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'di@@', 'mo@@', 'stra@@', 'zione', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte di questo specifico non è il problema di questo specifico non è la dimostrazione del ghiaccio del ghiaccio.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - Example #2
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', "l'@@", 'em@@', 'is@@', 'sion@@', 'e,', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ent@@', 'o,', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico.', '</s>']
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, l'emissione, il cuore argomento, il cuore del nostro sistema climatico.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - Example #3
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 's@@', 'po@@', 'sta', 'nel', 'vent@@', 'o', 'e', 's@@', 'otto', 'in', 'vent@@', 'o', "nell'@@", 'est@@', 'ate', 'di', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - 	Hypothesis: Si sposta nel vento e sotto in vento nell'estate di estate.
2025-05-29 20:44:18,735 - INFO - joeynmt.training - Example #4
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:44:18,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'st@@', 'a@@', 'gi@@', 'one', 'di', 'giorn@@', 'ale', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:44:18,736 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:44:18,736 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:44:18,736 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una stagione di giornale negli ultimi 25 anni.
2025-05-29 20:44:32,558 - INFO - joeynmt.training - Epoch   9, Step:    40600, Batch Loss:     1.764360, Batch Acc: 0.495738, Tokens per Sec:     5114, Lr: 0.000300
2025-05-29 20:44:45,998 - INFO - joeynmt.training - Epoch   9, Step:    40700, Batch Loss:     1.781912, Batch Acc: 0.498058, Tokens per Sec:     5289, Lr: 0.000300
2025-05-29 20:44:59,016 - INFO - joeynmt.training - Epoch   9, Step:    40800, Batch Loss:     1.631699, Batch Acc: 0.500931, Tokens per Sec:     5490, Lr: 0.000300
2025-05-29 20:45:12,600 - INFO - joeynmt.training - Epoch   9, Step:    40900, Batch Loss:     1.615224, Batch Acc: 0.497166, Tokens per Sec:     5391, Lr: 0.000300
2025-05-29 20:45:25,914 - INFO - joeynmt.training - Epoch   9, Step:    41000, Batch Loss:     1.779404, Batch Acc: 0.493767, Tokens per Sec:     5405, Lr: 0.000300
2025-05-29 20:45:25,914 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:46:42,184 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.07, acc:   0.47, generation: 76.2625[sec], evaluation: 0.0000[sec]
2025-05-29 20:46:42,184 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:46:42,260 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/39000.ckpt
2025-05-29 20:46:42,260 - INFO - joeynmt.training - Example #0
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'li@@', 'br@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 'gente', 'si', 'trov@@', 'a', 'che', 'la', 'gente', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', '.', '</s>']
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato questi due libri di ghiaccio che la gente si trova che la gente di ghiaccio per tre milioni di anni per tre milioni di anni per i tre milioni di anni per i 40 per cento dei sottopodi.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - Example #1
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'for@@', 'ma', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'di', 'questo', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'di@@', 'men@@', 'sione', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la forma di questo speciale di questo speciale non è la dimensione del ghiaccio non è la distanza del ghiaccio.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - Example #2
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la ghiaccia di Eiskappe del nostro sistema di climatica.
2025-05-29 20:46:42,261 - INFO - joeynmt.training - Example #3
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:46:42,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'trov@@', 'ano', 'in', 'vent@@', 'o', 'e', 'sc@@', 'ar@@', 'ono', 'nel', 'm@@', 'ett@@', 'ore', 'di', 'un', 'p@@', 'ò', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'ate', 'e', 's@@', 'an@@', 'gu@@', 'e.', '</s>']
2025-05-29 20:46:42,261 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:46:42,262 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:46:42,262 - INFO - joeynmt.training - 	Hypothesis: Si trovano in vento e scarono nel mettore di un pò in estate in estate in estate in estate in estate e rendono in estate e rendono in estate e rendono in estate e rendono in estate in estate e rendono in estate e rendono in estate e rendono in estate e sangue.
2025-05-29 20:46:42,262 - INFO - joeynmt.training - Example #4
2025-05-29 20:46:42,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:46:42,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:46:42,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'succ@@', 'e@@', 'den@@', 'do', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:46:42,262 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:46:42,262 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:46:42,262 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una rivista di una rivista di succedendo negli ultimi 25 anni.
2025-05-29 20:46:55,583 - INFO - joeynmt.training - Epoch   9, Step:    41100, Batch Loss:     1.709512, Batch Acc: 0.497223, Tokens per Sec:     5227, Lr: 0.000300
2025-05-29 20:47:09,039 - INFO - joeynmt.training - Epoch   9, Step:    41200, Batch Loss:     1.628046, Batch Acc: 0.495041, Tokens per Sec:     5074, Lr: 0.000300
2025-05-29 20:47:22,472 - INFO - joeynmt.training - Epoch   9, Step:    41300, Batch Loss:     1.758829, Batch Acc: 0.502170, Tokens per Sec:     5250, Lr: 0.000300
2025-05-29 20:47:36,132 - INFO - joeynmt.training - Epoch   9, Step:    41400, Batch Loss:     1.699955, Batch Acc: 0.497457, Tokens per Sec:     5197, Lr: 0.000300
2025-05-29 20:47:49,851 - INFO - joeynmt.training - Epoch   9, Step:    41500, Batch Loss:     1.658481, Batch Acc: 0.499293, Tokens per Sec:     5102, Lr: 0.000300
2025-05-29 20:47:49,851 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:49:01,396 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.07, acc:   0.47, generation: 71.5372[sec], evaluation: 0.0000[sec]
2025-05-29 20:49:01,398 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:49:01,472 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/39500.ckpt
2025-05-29 20:49:01,473 - INFO - joeynmt.training - Example #0
2025-05-29 20:49:01,473 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:49:01,473 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:49:01,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'cui', 'i', 'di@@', 'vi@@', 'de@@', 'o', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'ati', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'ali', 'per', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'li@@', 'br@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno scorso che ho mostrato questi due diapositive per cui i divideo che i ghiacciati per tre milioni di anni per tre milioni di anni per tre milioni di anni per tre milioni di anni per i 40 per cento dei 40 per cento dei 40 per cento dei segnali per il 40% dei slibri di ghiaccio.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - Example #1
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'for@@', 'za', 'di', 'questa', 'sp@@', 'eci@@', 'e,', 'questo', 'problem@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'non', 'è', 'il', 'di@@', 'mostr@@', 'a', 'il', 'di@@', 'st@@', 'ing@@', 'u@@', 'aggio', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la forza di questa specie, questo problema di questo particolare problema non è il dimostra il distinguaggio del ghiaccio.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - Example #2
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'ar@@', 't@@', 'ico', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', ',', 'il', 'cu@@', 'ore', 'del', 'nostro', 'c@@', 'li@@', 'mat@@', 'o.', '</s>']
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore artico è il cuore del nostro clima, il cuore del nostro climato.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - Example #3
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'un', 'vent@@', 'o', 'in', 'vent@@', 'o', 'e', 'p@@', 'ur@@', 'e,', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 's@@', 'ott@@', 'o@@', 'po@@', '.', '</s>']
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - 	Hypothesis: Si tratta di un vento in vento e pure, in estate in estate in estate in estate in estate in estate e sottopo.
2025-05-29 20:49:01,474 - INFO - joeynmt.training - Example #4
2025-05-29 20:49:01,474 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:49:01,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:49:01,475 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 's@@', 'li@@', 'de', 'di', 'temp@@', 'o,', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'di', 'succ@@', 'ess@@', 'o.', '</s>']
2025-05-29 20:49:01,475 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:49:01,475 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:49:01,475 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una slide di tempo, è successo negli ultimi 25 anni di successo.
2025-05-29 20:49:14,748 - INFO - joeynmt.training - Epoch   9, Step:    41600, Batch Loss:     1.736152, Batch Acc: 0.497877, Tokens per Sec:     5292, Lr: 0.000300
2025-05-29 20:49:28,026 - INFO - joeynmt.training - Epoch   9, Step:    41700, Batch Loss:     1.755654, Batch Acc: 0.500331, Tokens per Sec:     5468, Lr: 0.000300
2025-05-29 20:49:40,892 - INFO - joeynmt.training - Epoch   9, Step:    41800, Batch Loss:     1.695953, Batch Acc: 0.495121, Tokens per Sec:     5464, Lr: 0.000300
2025-05-29 20:49:54,178 - INFO - joeynmt.training - Epoch   9, Step:    41900, Batch Loss:     1.664178, Batch Acc: 0.498752, Tokens per Sec:     5278, Lr: 0.000300
2025-05-29 20:50:07,390 - INFO - joeynmt.training - Epoch   9, Step:    42000, Batch Loss:     1.644370, Batch Acc: 0.497222, Tokens per Sec:     5300, Lr: 0.000300
2025-05-29 20:50:07,390 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:51:24,102 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.05, acc:   0.47, generation: 76.7043[sec], evaluation: 0.0000[sec]
2025-05-29 20:51:24,103 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:51:24,179 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/40000.ckpt
2025-05-29 20:51:24,179 - INFO - joeynmt.training - Example #0
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'di', 'questi', 'due', 'li@@', 'mit@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'la', 's@@', 'li@@', 'de', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', '3@@', '0', 'per', 'c@@', 'ento', 'milioni', 'di', 'anni', 'per', 'i', 's@@', 'otto', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'di', 's@@', 'post@@', 'are', 'il', '4@@', '0@@', '%', 'per', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'per', 'c@@', 'aus@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'ar@@', 'i.', '</s>']
2025-05-29 20:51:24,179 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:51:24,179 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:51:24,179 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato queste due dimensioni di questi due limiti di ghiaccio che la slide poveri che i poveri che per tre milioni di anni per tre milioni di anni per 30 per cento milioni di anni per i sotto milioni di anni per il 40% per il 40% del 40% del 40% di spostare il 40% per cento di ghiacciaio per causa di ghiacciari.
2025-05-29 20:51:24,179 - INFO - joeynmt.training - Example #1
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:51:24,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'ri@@', 'vol@@', 'u@@', 'zione', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'i', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'che', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'che', 'non', 'mostr@@', 'a', 'la', 'd@@', 'og@@', 'a.', '</s>']
2025-05-29 20:51:24,179 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:51:24,179 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte la rivoluzione di questo particolare problemi di questo specifico che non è la distanza che non mostra la doga.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - Example #2
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'c@@', 'li@@', 'mat@@', 'ic@@', 'i.', '</s>']
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di ghiaccio di ghiaccio di climatici.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - Example #3
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'ott@@', 'o@@', 'in@@', 'ter', 'e', 's@@', 'otto', 'in', 'in@@', 'ver@@', 'n@@', 'o.', '</s>']
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Hypothesis: Si è sottointer e sotto in inverno.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - Example #4
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:51:24,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'una', 'ra@@', 'ff@@', 're@@', 'd@@', 'd@@', 'd@@', 'ore', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:51:24,180 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò è una rivista di una raffredddore che è successo negli ultimi 25 anni 25 anni.
2025-05-29 20:51:37,767 - INFO - joeynmt.training - Epoch   9, Step:    42100, Batch Loss:     1.636467, Batch Acc: 0.495709, Tokens per Sec:     5245, Lr: 0.000300
2025-05-29 20:51:51,633 - INFO - joeynmt.training - Epoch   9, Step:    42200, Batch Loss:     1.637400, Batch Acc: 0.499655, Tokens per Sec:     5325, Lr: 0.000300
2025-05-29 20:52:04,760 - INFO - joeynmt.training - Epoch   9, Step:    42300, Batch Loss:     1.610985, Batch Acc: 0.501707, Tokens per Sec:     5467, Lr: 0.000300
2025-05-29 20:52:18,026 - INFO - joeynmt.training - Epoch   9, Step:    42400, Batch Loss:     1.645531, Batch Acc: 0.495987, Tokens per Sec:     5203, Lr: 0.000300
2025-05-29 20:52:19,489 - INFO - joeynmt.training - Epoch   9: total training loss 7898.58
2025-05-29 20:52:19,489 - INFO - joeynmt.training - EPOCH 10
2025-05-29 20:52:31,180 - INFO - joeynmt.training - Epoch  10, Step:    42500, Batch Loss:     1.597279, Batch Acc: 0.519592, Tokens per Sec:     5403, Lr: 0.000300
2025-05-29 20:52:31,180 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:53:37,818 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.03, acc:   0.47, generation: 66.6311[sec], evaluation: 0.0000[sec]
2025-05-29 20:53:37,820 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 20:53:37,905 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/37500.ckpt
2025-05-29 20:53:37,907 - INFO - joeynmt.training - Example #0
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 'ri@@', 'dur@@', 're', 'che', 'la', 's@@', 'li@@', 'de', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'tre', 'la', 'ra@@', 'gi@@', 'one', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'milioni', 'di', 'anni', 'per', 'c@@', 'aus@@', 'a', 'il', '4@@', '0@@', '%', 'del', 'p@@', 'es@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ur@@', 'are', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'pi@@', 'ù@@', ',', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ur@@', 'are', 'il', '4@@', '0@@', '%', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'anni']
2025-05-29 20:53:37,907 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:53:37,907 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:53:37,907 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due dimensioni per ridurre che la slide poveri che i poveri che i poveri che per tre milioni di anni per tre milioni di anni per tre la ragione per tre milioni di anni per il 40% del 40 per cento di milioni di anni per causa il 40% del peso per tre milioni di anni per curare il 40 percento di più, per tre milioni di anni per curare il 40% per tre milioni di anni di anni
2025-05-29 20:53:37,907 - INFO - joeynmt.training - Example #1
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:53:37,907 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', "l'@@", 'in@@', 'credi@@', 'bile', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'fic@@', 'o', 'non', 'è', 'la', 'cosa', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:53:37,907 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:53:37,907 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte l'incredibile problema di questo problema di questo problema specifico non è la cosa del ghiaccio.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - Example #2
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'a', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di Eiskappa il cuore globale del nostro sistema climatico globale.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - Example #3
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'b@@', 'agli@@', 'a', 'in', 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'te', 'nel', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 'p@@', 'ur@@', 'e.', '</s>']
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Hypothesis: Si è sbaglia in estate e rotte nel estate estate in estate estate in estate estate in estate e pure.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - Example #4
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:53:37,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'cosa', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'nel', 'cor@@', 'so', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:53:37,908 - INFO - joeynmt.training - 	Hypothesis: La prossima cosa che vi mostro è una rivista è una rivista nel corso degli ultimi 25 anni.
2025-05-29 20:53:51,980 - INFO - joeynmt.training - Epoch  10, Step:    42600, Batch Loss:     1.808293, Batch Acc: 0.520118, Tokens per Sec:     4943, Lr: 0.000300
2025-05-29 20:54:04,931 - INFO - joeynmt.training - Epoch  10, Step:    42700, Batch Loss:     1.733153, Batch Acc: 0.518246, Tokens per Sec:     5428, Lr: 0.000300
2025-05-29 20:54:18,223 - INFO - joeynmt.training - Epoch  10, Step:    42800, Batch Loss:     1.567915, Batch Acc: 0.516451, Tokens per Sec:     5335, Lr: 0.000300
2025-05-29 20:54:31,831 - INFO - joeynmt.training - Epoch  10, Step:    42900, Batch Loss:     1.562994, Batch Acc: 0.514529, Tokens per Sec:     5276, Lr: 0.000300
2025-05-29 20:54:45,079 - INFO - joeynmt.training - Epoch  10, Step:    43000, Batch Loss:     1.552026, Batch Acc: 0.516980, Tokens per Sec:     5359, Lr: 0.000300
2025-05-29 20:54:45,079 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:55:58,506 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.08, acc:   0.47, generation: 73.4204[sec], evaluation: 0.0000[sec]
2025-05-29 20:55:58,582 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/40500.ckpt
2025-05-29 20:55:58,584 - INFO - joeynmt.training - Example #0
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 's@@', 'post@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'i', 'po@@', 'ver@@', 'i', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'sono', 'i', 'li@@', 'v@@', 'ell@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'aus@@', 'ati', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'di', 's@@', 'egn@@', 'are', 'il', '4@@', '0@@', '%', 'per', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'per', 'per', 'per', 'per', 'per', 'i', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ur@@', 'are', 'il', '4@@', '0@@', '%', 'di', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due dimensioni per sposti che i poveri che i poveri che i poveri che per tre milioni di anni che per tre milioni di anni che sono i livelli di ghiaccio per tre milioni di anni per causati per il 40% del 40% del 40% di segnare il 40% per per tre milioni di anni per per per per per per per i tre milioni di anni per curare il 40% di sotto.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - Example #1
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', "l'@@", 'in@@', 'fer@@', 'i@@', 'ore', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'ale', 'non', 'è', 'la', 'pr@@', 'at@@', 'ica', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'la', 'vi@@', 'sione', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte l'inferiore di questo problema speciale non è la pratica del ghiaccio non è la visione del ghiaccio.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - Example #2
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:55:58,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'a', 'ar@@', 'e@@', 'a', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'o.', '</s>']
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di Eiskappa area del nostro sistema climato.
2025-05-29 20:55:58,584 - INFO - joeynmt.training - Example #3
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'en@@', 'da', 'nel', 'vent@@', 'o', 'e', 'sc@@', 'en@@', 'der@@', 'i@@', 'v@@', 'ano', 'in', 'est@@', 'ate', 'e', 's@@', 'po@@', 'ste', 'nel', 'm@@', 'ett@@', 'or@@', 'e.', '</s>']
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Hypothesis: Si scenda nel vento e scenderivano in estate e sposte nel mettore.
2025-05-29 20:55:58,585 - INFO - joeynmt.training - Example #4
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:55:58,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'f@@', 'ant@@', 'ast@@', 'ica', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'stra@@', 'da', 'di', 'temp@@', 'o,', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:55:58,585 - INFO - joeynmt.training - 	Hypothesis: La prossifantastica che vi mostro è una strada di tempo, è successo negli ultimi 25 anni.
2025-05-29 20:56:12,309 - INFO - joeynmt.training - Epoch  10, Step:    43100, Batch Loss:     1.588531, Batch Acc: 0.510465, Tokens per Sec:     5175, Lr: 0.000300
2025-05-29 20:56:25,807 - INFO - joeynmt.training - Epoch  10, Step:    43200, Batch Loss:     1.525711, Batch Acc: 0.514116, Tokens per Sec:     5327, Lr: 0.000300
2025-05-29 20:56:39,314 - INFO - joeynmt.training - Epoch  10, Step:    43300, Batch Loss:     1.556630, Batch Acc: 0.516723, Tokens per Sec:     5189, Lr: 0.000300
2025-05-29 20:56:52,820 - INFO - joeynmt.training - Epoch  10, Step:    43400, Batch Loss:     1.624047, Batch Acc: 0.513040, Tokens per Sec:     5182, Lr: 0.000300
2025-05-29 20:57:06,406 - INFO - joeynmt.training - Epoch  10, Step:    43500, Batch Loss:     1.635631, Batch Acc: 0.513257, Tokens per Sec:     5125, Lr: 0.000300
2025-05-29 20:57:06,406 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 20:58:15,437 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.05, acc:   0.47, generation: 69.0240[sec], evaluation: 0.0000[sec]
2025-05-29 20:58:15,516 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/43000.ckpt
2025-05-29 20:58:15,517 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/43000.ckpt
2025-05-29 20:58:15,517 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/43000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/43000.ckpt')
2025-05-29 20:58:15,518 - INFO - joeynmt.training - Example #0
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'rit@@', 'ti', 'per', 'mostr@@', 'are', 'che', 'i', 'con@@', 'si@@', 'der@@', 'are', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'tr@@', 'am@@', 'it@@', 'e', 'che', 'è', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'i', 'che', 'è', 'il', '4@@', '0@@', '%', 'dei', 's@@', 'egn@@', 'i', 'a', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'ett@@', 'ori', 's@@', 'fr@@', 'utt@@', 'ati', 'per', 'il', '4@@', '0@@', '%', 'di', 's@@', 'ott@@', 'o.', '</s>']
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due diritti per mostrare che i considerare che i considerano che i considerano che i tramite che è il 40% dei segni che è il 40% dei segni a 40 per cento dei settori sfruttati per il 40% di sotto.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - Example #1
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 20:58:15,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', "l'@@", 'in@@', 'ten@@', 'sit@@', 'à', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'fic@@', 'o', 'che', 'non', 'è', 'la', 'cosa', 'che', 'mostr@@', 'a', 'la', 'de@@', 'st@@', 'in@@', 'azione', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è abbastanza forte l'intensità di questo problema specifico che non è la cosa che mostra la destinazione del ghiaccio.
2025-05-29 20:58:15,518 - INFO - joeynmt.training - Example #2
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di ghiaccio di ghiaccio di climatica.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - Example #3
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'b@@', 'at@@', 'tut@@', 'o', 'e', 's@@', 'otto', 'in', 'v@@', 'in@@', 'o,', 'e', 'r@@', 'end@@', 'ono', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Hypothesis: Si è sbattuto e sotto in vino, e rendono in estate.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - Example #4
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 20:58:15,519 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'b@@', 'att@@', 'agli@@', 'a', 'di', 'temp@@', 'o.', '</s>']
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 20:58:15,519 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una battaglia di tempo.
2025-05-29 20:58:28,771 - INFO - joeynmt.training - Epoch  10, Step:    43600, Batch Loss:     1.556236, Batch Acc: 0.507005, Tokens per Sec:     5327, Lr: 0.000300
2025-05-29 20:58:42,347 - INFO - joeynmt.training - Epoch  10, Step:    43700, Batch Loss:     1.606644, Batch Acc: 0.512614, Tokens per Sec:     5335, Lr: 0.000300
2025-05-29 20:58:55,875 - INFO - joeynmt.training - Epoch  10, Step:    43800, Batch Loss:     1.548290, Batch Acc: 0.506558, Tokens per Sec:     5112, Lr: 0.000300
2025-05-29 20:59:09,331 - INFO - joeynmt.training - Epoch  10, Step:    43900, Batch Loss:     1.727879, Batch Acc: 0.512286, Tokens per Sec:     5369, Lr: 0.000300
2025-05-29 20:59:22,885 - INFO - joeynmt.training - Epoch  10, Step:    44000, Batch Loss:     1.552085, Batch Acc: 0.510594, Tokens per Sec:     5398, Lr: 0.000300
2025-05-29 20:59:22,886 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:00:29,287 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.09, acc:   0.47, generation: 66.3937[sec], evaluation: 0.0000[sec]
2025-05-29 21:00:29,289 - INFO - joeynmt.training - Example #0
2025-05-29 21:00:29,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:00:29,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:00:29,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'str@@', 'i', 'per', 'ri@@', 'dur@@', 're', 'le', 'di@@', 'mostr@@', 'ano', 'che', 'la', 'cap@@', 'ac@@', 'ità', 'ar@@', 'e@@', 'e', 'che', 'la', 'cap@@', 'ac@@', 'ità', 'ar@@', 'e@@', 'a', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'la', 's@@', 'po@@', 'sta', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'per', 'il', '4@@', '0@@', '%', 'delle', 's@@', 'li@@', 'de', 'che', 'è', 'più', 'al@@', 'te', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', 'ris@@', 'ult@@', 'ato', 'per', 'il', '4@@', '0@@', '%', 'del', 'ris@@', 'ult@@', 'ato', 'per', 'il', '4@@', '0@@', '%', 'delle', 's@@', 'li@@', 'de', 'ar@@', 'e@@', 'e', 'che', 'è', 'stato', 'di@@', 'mostr@@', 'ato', 'che', 'la', 'sc@@', 'en@@', 'den@@', 'za', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'fare', 'il', '4@@']
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due diastri per ridurre le dimostrano che la capacità aree che la capacità area che per tre milioni di anni per la sposta per tre milioni di anni per per il 40% delle slide che è più alte per il 40% del 40% del risultato per il 40% del risultato per il 40% delle slide aree che è stato dimostrato che la scendenza di ghiaccio per fare il 4
2025-05-29 21:00:29,290 - INFO - joeynmt.training - Example #1
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'for@@', 't@@', 'una', 'di', 's@@', 'ens@@', 'azione', 'di', 'questo', 'problem@@', 'a', 'è', 'che', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'fic@@', 'o', 'che', 'non', 'è', 'la', 'cosa', 'che', 'mostr@@', 'a', 'il', 't@@', 'es@@', 'chi@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Hypothesis: Ma non è fortuna di sensazione di questo problema è che questo problema specifico che non è la cosa che mostra il teschio del ghiaccio.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - Example #2
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'sen@@', 'so', 'è', 'la', 'g@@', 'hi@@', 'acci@@', 'a', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'o.', '</s>']
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il senso è la ghiaccia di ghiaccio del nostro sistema climato.
2025-05-29 21:00:29,290 - INFO - joeynmt.training - Example #3
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:00:29,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'en@@', 'a', 'in', 'vent@@', 'o', 'e', 'r@@', 'om@@', 'p@@', 'e', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 's@@', 'po@@', 'sta', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Hypothesis: Si scena in vento e rompe in estate in estate in estate in estate in estate e sposta in estate.
2025-05-29 21:00:29,291 - INFO - joeynmt.training - Example #4
2025-05-29 21:00:29,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:00:29,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:00:29,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'una', 'ri@@', 'vi@@', 'sta', 'in', 'ulti@@', 'ma', '2@@', '5', 'anni', 'in', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:00:29,291 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro è una rivista di una rivista in ultima 25 anni in 25 anni.
2025-05-29 21:00:41,925 - INFO - joeynmt.training - Epoch  10, Step:    44100, Batch Loss:     1.671111, Batch Acc: 0.508315, Tokens per Sec:     5567, Lr: 0.000300
2025-05-29 21:00:54,971 - INFO - joeynmt.training - Epoch  10, Step:    44200, Batch Loss:     1.747350, Batch Acc: 0.510577, Tokens per Sec:     5432, Lr: 0.000300
2025-05-29 21:01:08,173 - INFO - joeynmt.training - Epoch  10, Step:    44300, Batch Loss:     1.588451, Batch Acc: 0.509287, Tokens per Sec:     5518, Lr: 0.000300
2025-05-29 21:01:21,866 - INFO - joeynmt.training - Epoch  10, Step:    44400, Batch Loss:     1.717452, Batch Acc: 0.508426, Tokens per Sec:     5127, Lr: 0.000300
2025-05-29 21:01:35,682 - INFO - joeynmt.training - Epoch  10, Step:    44500, Batch Loss:     1.636355, Batch Acc: 0.506579, Tokens per Sec:     5171, Lr: 0.000300
2025-05-29 21:01:35,682 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:02:41,084 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.04, acc:   0.47, generation: 65.3951[sec], evaluation: 0.0000[sec]
2025-05-29 21:02:41,166 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/41000.ckpt
2025-05-29 21:02:41,169 - INFO - joeynmt.training - Example #0
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'str@@', 'att@@', 'ori', 'per', 'ri@@', 'dur@@', 're', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'i', 'che', 'gli', 'sp@@', 'a@@', 'z@@', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'om@@', 'ent@@', 'i,', 'che', 'la', 'gente', 'si', 'trov@@', 'a', 'la', 'di@@', 're@@', 'zione', 'di', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'i', 'di', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'circa', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'del', '4@@', '0', 'per', 'c@@', 'ento', 'di', 'cui', 'è', 'il', '4@@', '0', 'per', 'c@@', 'ento', 'di', 's@@', 'ott@@', 'o@@', 'po@@', 'di@@', '.', '</s>']
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Hypothesis: Ho mostrato questi due diastrattori per ridurre questi due diapositivi che gli spazi poveri argomenti, che la gente si trova la direzione di tre milioni di anni per il 40 per cento dei segni di 40 percento di circa il 40 percento del 40 per cento di cui è il 40 per cento di sottopodi.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - Example #1
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'nostra', 's@@', 'ens@@', 'azione', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'fic@@', 'are', 'problem@@', 'i', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'la', 'di@@', 'st@@', 'in@@', 'ta', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'lo', 'mostr@@', 'a', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la nostra sensazione di questo problema specificare problemi di questo problema non è la distinta di ghiaccio non lo mostra il ghiaccio di ghiaccio.
2025-05-29 21:02:41,169 - INFO - joeynmt.training - Example #2
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:02:41,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'la', 'cap@@', 'ac@@', 'e', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, la capace di ghiaccio di ghiaccio del nostro sistema climatico globale.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - Example #3
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'trov@@', 'a', "nell'@@", 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'ta', 'nel', 'vent@@', 'o.', '</s>']
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Hypothesis: Si trova nell'estate e rotta nel vento.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - Example #4
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:02:41,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'ciò', 'che', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni', 'di', 'anni@@', '.', '</s>']
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:02:41,170 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una rivista di una rivista di ciò che è successo negli ultimi 25 anni di anni.
2025-05-29 21:02:55,238 - INFO - joeynmt.training - Epoch  10, Step:    44600, Batch Loss:     1.721971, Batch Acc: 0.506917, Tokens per Sec:     5015, Lr: 0.000300
2025-05-29 21:03:09,683 - INFO - joeynmt.training - Epoch  10, Step:    44700, Batch Loss:     1.664923, Batch Acc: 0.503632, Tokens per Sec:     5052, Lr: 0.000300
2025-05-29 21:03:24,012 - INFO - joeynmt.training - Epoch  10, Step:    44800, Batch Loss:     1.708461, Batch Acc: 0.499427, Tokens per Sec:     4993, Lr: 0.000300
2025-05-29 21:03:38,053 - INFO - joeynmt.training - Epoch  10, Step:    44900, Batch Loss:     1.560972, Batch Acc: 0.507837, Tokens per Sec:     4989, Lr: 0.000300
2025-05-29 21:03:52,001 - INFO - joeynmt.training - Epoch  10, Step:    45000, Batch Loss:     1.573531, Batch Acc: 0.507259, Tokens per Sec:     5141, Lr: 0.000300
2025-05-29 21:03:52,001 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:04:54,338 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.00, acc:   0.47, generation: 62.3302[sec], evaluation: 0.0000[sec]
2025-05-29 21:04:54,339 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:04:54,416 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/41500.ckpt
2025-05-29 21:04:54,416 - INFO - joeynmt.training - Example #0
2025-05-29 21:04:54,416 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'con@@', 'di@@', 'vi@@', 'dere', 'che', 'i', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'om@@', 'ento', 'po@@', 'ver@@', 'i', 'ar@@', 'g@@', 'om@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'persone', 'che', 'sono', 'st@@', 'ati', 'in', 'gra@@', 'do', 'di', 's@@', 'f@@', 'um@@', 'at@@', 'ure', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', 'f@@', 'ut@@', 'ur@@', 'o.', '</s>']
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato questi due diapositive per condividere che i poveri argomento poveri argomento di tre milioni di anni di ghiaccio per tre milioni di anni di persone che sono stati in grado di sfumature del 40% del 40% del futuro.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - Example #1
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'stato', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'la', 'di@@', 'st@@', 'anza', 'di', 'questo', 'problem@@', 'a', "dell'@@", 'E@@', 'is@@', 'm@@', 'o.', '</s>']
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è stato abbastanza forte la distanza di questo particolare problema di questo problema del ghiaccio non è la distanza di questo problema dell'Eismo.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - Example #2
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'ar@@', 'g@@', 'om@@', 'ent@@', 'ico', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore argomentico è il cuore del nostro sistema climatico globale di climatica.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - Example #3
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:04:54,417 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sc@@', 'al@@', 'a', 'in', 'vent@@', 'o', 'e', 'sc@@', 'en@@', 'a', 'e', 'r@@', 'ot@@', 'ta', 'nel', 's@@', 'ett@@', 'ore', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:04:54,417 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:04:54,418 - INFO - joeynmt.training - 	Hypothesis: Si scala in vento e scena e rotta nel settore estate.
2025-05-29 21:04:54,418 - INFO - joeynmt.training - Example #4
2025-05-29 21:04:54,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:04:54,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:04:54,418 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'o', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 's@@', 'li@@', 'de', 'di', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:04:54,418 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:04:54,418 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:04:54,418 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerò è una slide di cosa è successo negli ultimi 25 anni.
2025-05-29 21:05:08,171 - INFO - joeynmt.training - Epoch  10, Step:    45100, Batch Loss:     1.830943, Batch Acc: 0.502245, Tokens per Sec:     5217, Lr: 0.000300
2025-05-29 21:05:22,247 - INFO - joeynmt.training - Epoch  10, Step:    45200, Batch Loss:     1.804667, Batch Acc: 0.504843, Tokens per Sec:     5098, Lr: 0.000300
2025-05-29 21:05:35,769 - INFO - joeynmt.training - Epoch  10, Step:    45300, Batch Loss:     1.667032, Batch Acc: 0.510133, Tokens per Sec:     5423, Lr: 0.000300
2025-05-29 21:05:49,919 - INFO - joeynmt.training - Epoch  10, Step:    45400, Batch Loss:     1.508391, Batch Acc: 0.508467, Tokens per Sec:     5012, Lr: 0.000300
2025-05-29 21:06:03,590 - INFO - joeynmt.training - Epoch  10, Step:    45500, Batch Loss:     1.719983, Batch Acc: 0.509493, Tokens per Sec:     5197, Lr: 0.000300
2025-05-29 21:06:03,590 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:07:06,161 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.47, generation: 62.5647[sec], evaluation: 0.0000[sec]
2025-05-29 21:07:06,162 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:07:06,238 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/43500.ckpt
2025-05-29 21:07:06,239 - INFO - joeynmt.training - Example #0
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'i', 'per', 'ri@@', 'pro@@', 'dur@@', 're', 'i', 'con@@', 'si@@', 'der@@', 'are', 'che', 'i', 'con@@', 'si@@', 'der@@', 'ano', 'che', 'i', 'tr@@', 'am@@', 'it@@', 'e', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'ha', 'av@@', 'uto', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'i', '4@@', '0', 'per', 'c@@', 'ento', 'dei', 's@@', 'egn@@', 'i', 'di', 's@@', 'ott@@', 'o@@', 'po@@', 'vol@@', 'g@@', 'gi@@', '.', '</s>']
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due diapositivi per riprodurre i considerare che i considerano che i tramite che per tre milioni di anni che ha avuto per tre milioni di anni per i 40 per cento dei segni di sottopovolggi.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - Example #1
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'di', 'questo', 'problem@@', 'a', 'sp@@', 'eci@@', 'ale', 'è', 'il', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'il', 'pr@@', 'em@@', 'io', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte abbastanza forte di questo problema speciale è il problema del ghiaccio non è il premio del ghiaccio.
2025-05-29 21:07:06,239 - INFO - joeynmt.training - Example #2
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:07:06,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'è', 'il', 'cu@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'cu@@', 'ore', 'del', 'nostro', 'sistema', 'di', 'c@@', 'li@@', 'mat@@', 'ica.', '</s>']
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, è il cuore del ghiaccio è il cuore del nostro sistema di climatica.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - Example #3
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'sono', 's@@', 'po@@', 'sta', 'in', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Hypothesis: Si sono sposta in estate.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - Example #4
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:07:06,240 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'temp@@', 'o,', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:07:06,240 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una rivista di tempo, è successo negli ultimi 25 anni.
2025-05-29 21:07:20,275 - INFO - joeynmt.training - Epoch  10, Step:    45600, Batch Loss:     1.655941, Batch Acc: 0.504878, Tokens per Sec:     4968, Lr: 0.000300
2025-05-29 21:07:34,294 - INFO - joeynmt.training - Epoch  10, Step:    45700, Batch Loss:     1.511869, Batch Acc: 0.505913, Tokens per Sec:     5037, Lr: 0.000300
2025-05-29 21:07:48,394 - INFO - joeynmt.training - Epoch  10, Step:    45800, Batch Loss:     1.647579, Batch Acc: 0.505922, Tokens per Sec:     4994, Lr: 0.000300
2025-05-29 21:08:02,462 - INFO - joeynmt.training - Epoch  10, Step:    45900, Batch Loss:     1.760986, Batch Acc: 0.506279, Tokens per Sec:     5066, Lr: 0.000300
2025-05-29 21:08:15,755 - INFO - joeynmt.training - Epoch  10, Step:    46000, Batch Loss:     1.931573, Batch Acc: 0.503132, Tokens per Sec:     5452, Lr: 0.000300
2025-05-29 21:08:15,755 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:09:33,290 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.01, acc:   0.47, generation: 77.5283[sec], evaluation: 0.0000[sec]
2025-05-29 21:09:33,368 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/42000.ckpt
2025-05-29 21:09:33,369 - INFO - joeynmt.training - Example #0
2025-05-29 21:09:33,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:09:33,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:09:33,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'cui', 'ho', 'mostr@@', 'ato', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'che', 'i', 'p@@', 'ap@@', 'à', 'di', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'si', 'sono', 'st@@', 'ati', 'in', 'gra@@', 'do', 'di', 'fare', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'di', 'tre', 'milioni', 'di', 'anni@@', ',', 'per', 'il', '4@@', '0', 'per@@', 'c@@', 'ento', 'dei', 'li@@', 'v@@', 'ell@@', 'i', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:09:33,369 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:09:33,369 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due diapositive per cui ho mostrato che i ghiacciaio che i papà di ghiacciaio di tre milioni di anni che si sono stati in grado di fare il 40 percento di tre milioni di anni, per il 40 percento dei livelli di ghiaccio.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - Example #1
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'il', 'T@@', 'er@@', 'r@@', 'ore', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'di', 'questo', 'problem@@', 'a', 'non', 'è', 'il', 'di@@', 'str@@', 'etto', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte il Terrore di questo problema di questo problema di questo problema non è il distretto del ghiaccio.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - Example #2
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 's@@', 'ens@@', 'ore', 'di', 'E@@', 'is@@', 'ci@@', 'o', 'del', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il sensore di Eiscio del clima.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - Example #3
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'tratt@@', 'a', 'di', 'in@@', 'ver@@', 'no', 'e', 'r@@', 'ot@@', 'ta', 'in', 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'te', 'nel', 'est@@', 'ate', 'di', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'in', 'est@@', 'ate', 'e', 'r@@', 'ot@@', 'ti@@', 'gli@@', 'e.', '</s>']
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - 	Hypothesis: Si tratta di inverno e rotta in estate e rotte nel estate di estate in estate in estate in estate e rottiglie.
2025-05-29 21:09:33,370 - INFO - joeynmt.training - Example #4
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:09:33,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'che', 'vi', 'mostr@@', 'er@@', 'ò', 'è', 'una', 'giorn@@', 'ale', 'di', 'cui', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:09:33,371 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:09:33,371 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:09:33,371 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò è una giornale di cui è successo negli ultimi 25 anni.
2025-05-29 21:09:47,307 - INFO - joeynmt.training - Epoch  10, Step:    46100, Batch Loss:     1.769787, Batch Acc: 0.504975, Tokens per Sec:     5063, Lr: 0.000300
2025-05-29 21:10:00,935 - INFO - joeynmt.training - Epoch  10, Step:    46200, Batch Loss:     1.620694, Batch Acc: 0.504046, Tokens per Sec:     5287, Lr: 0.000300
2025-05-29 21:10:15,316 - INFO - joeynmt.training - Epoch  10, Step:    46300, Batch Loss:     1.623760, Batch Acc: 0.498962, Tokens per Sec:     5057, Lr: 0.000300
2025-05-29 21:10:28,604 - INFO - joeynmt.training - Epoch  10, Step:    46400, Batch Loss:     1.651648, Batch Acc: 0.503855, Tokens per Sec:     5369, Lr: 0.000300
2025-05-29 21:10:43,259 - INFO - joeynmt.training - Epoch  10, Step:    46500, Batch Loss:     1.609852, Batch Acc: 0.501191, Tokens per Sec:     4870, Lr: 0.000300
2025-05-29 21:10:43,260 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:11:58,738 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.97, acc:   0.47, generation: 75.4712[sec], evaluation: 0.0000[sec]
2025-05-29 21:11:58,739 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:11:58,813 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/44500.ckpt
2025-05-29 21:11:58,814 - INFO - joeynmt.training - Example #0
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ann@@', 'o,', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'men@@', 'sion@@', 'i', 'per', 's@@', 'cont@@', 'ato', 'che', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'che', 'per', 'tre', 'milioni', 'di', 'anni', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'c@@', 'ento', 'di', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno, ho mostrato queste due dimensioni per scontato che il ghiaccio che il ghiaccio che per tre milioni di anni che per tre milioni di anni di ghiaccio per tre milioni di anni per cento di ghiaccio.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - Example #1
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'non', 'è', 'il', 'pr@@', 'em@@', 'io', 'sp@@', 'eci@@', 'fic@@', 'o', 'che', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'di', 'questo', 'sp@@', 'eci@@', 'fic@@', 'o', 'che', 'non', 'è', 'il', 'di@@', 'st@@', 'es@@', 'e.', '</s>']
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Hypothesis: Ma questo non è il premio specifico che questo particolare problema di questo specifico che non è il distese.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - Example #2
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'g@@', 'hi@@', 'acci@@', 'o', 'del', 'nostro', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.', '</s>']
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il ghiaccio è il ghiaccio del nostro sistema climatico globale.
2025-05-29 21:11:58,815 - INFO - joeynmt.training - Example #3
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:11:58,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'sc@@', 'el@@', 'ta', 'in', 'in@@', 'ver@@', 'no', 'e', 's@@', 'po@@', 'sta', 'nel', 'v@@', 'in@@', 'ver@@', 'no', 'di', 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Hypothesis: Si è scelta in inverno e sposta nel vinverno di estate.
2025-05-29 21:11:58,816 - INFO - joeynmt.training - Example #4
2025-05-29 21:11:58,816 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:11:58,816 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:11:58,816 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'pr@@', 'ossi@@', 'mo', 'succ@@', 'essi@@', 'vo', 'che', 'vi', 'mostr@@', 'o', 'è', 'una', 'ri@@', 'vi@@', 'sta', 'di', 'un', 'giorn@@', 'ale', 'di', 'giorn@@', 'ale', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:11:58,816 - INFO - joeynmt.training - 	Hypothesis: Il prossimo successivo che vi mostro è una rivista di un giornale di giornale è successo negli ultimi 25 anni.
2025-05-29 21:12:12,465 - INFO - joeynmt.training - Epoch  10, Step:    46600, Batch Loss:     1.810293, Batch Acc: 0.505114, Tokens per Sec:     5207, Lr: 0.000300
2025-05-29 21:12:25,897 - INFO - joeynmt.training - Epoch  10, Step:    46700, Batch Loss:     1.570592, Batch Acc: 0.500892, Tokens per Sec:     5469, Lr: 0.000300
2025-05-29 21:12:40,109 - INFO - joeynmt.training - Epoch  10, Step:    46800, Batch Loss:     1.696053, Batch Acc: 0.509436, Tokens per Sec:     5082, Lr: 0.000300
2025-05-29 21:12:54,073 - INFO - joeynmt.training - Epoch  10, Step:    46900, Batch Loss:     1.649032, Batch Acc: 0.506983, Tokens per Sec:     5179, Lr: 0.000300
2025-05-29 21:13:08,262 - INFO - joeynmt.training - Epoch  10, Step:    47000, Batch Loss:     1.476217, Batch Acc: 0.507568, Tokens per Sec:     4903, Lr: 0.000300
2025-05-29 21:13:08,263 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:14:14,293 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.93, acc:   0.47, generation: 66.0232[sec], evaluation: 0.0000[sec]
2025-05-29 21:14:14,294 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-29 21:14:14,370 - INFO - joeynmt.helpers - delete models_bpelvl_2k_v2/42500.ckpt
2025-05-29 21:14:14,370 - INFO - joeynmt.training - Example #0
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'etz@@', 't@@', 'es', 'Jahr', 'habe', 'ich', 'diese', 'bei@@', 'den', 'F@@', 'ol@@', 'i@@', 'en', 'ge@@', 'zeig@@', 't,', 'um', 'zu', 'ver@@', 'an@@', 'sch@@', 'au@@', 'lich@@', 'en,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e,', 'die', 'für', 'ann@@', 'ä@@', 'her@@', 'n@@', 'd', 'drei', 'Millionen', 'Jahre', 'die', 'Gr@@', 'ös@@', 'se', 'der', 'unter@@', 'en', '4@@', '8', 'St@@', 'a@@', 'aten', 'hatt@@', 'e,', 'um', '4@@', '0', 'Proz@@', 'ent', 'gesch@@', 'r@@', 'um@@', 'p@@', 'ft', 'ist.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'e', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'av@@', 'uto', 'le', 'di@@', 'men@@', 'sion@@', 'i', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'cont@@', 'in@@', 'ent@@', 'al@@', 'i,', 'si', 'è', 'ri@@', 'str@@', 'ett@@', 'a', 'del', '4@@', '0@@', '%@@', '.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["L'@@", 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'li@@', 'ev@@', 'ole', 'per', 's@@', 'cont@@', 'ato', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'di', 'tre', 'milioni', 'di', 'anni', 'che', 'hanno', 'av@@', 'uto', 'il', '4@@', '0@@', '%', 'di', 'questi', 'g@@', 'hi@@', 'acci@@', 'a@@', 'io', 'per', 'tre', 'milioni', 'di', 'anni', 'per', 'il', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'del', '4@@', '0@@', '%', 'delle', 's@@', 'li@@', 'de', 'che', 'gli', 'st@@', 'ati', 's@@', 'ott@@', 'o@@', '-@@', 'g@@', 'hi@@', 'acci@@', 'o', 'che', 'i', 'su@@', 'oi', 'di@@', 'a@@', 'str@@', 'ut@@', 'ti', 'po@@']
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due lievole per scontato che i ghiaccio che i ghiaccio che i ghiacciaio di tre milioni di anni che hanno avuto il 40% di questi ghiacciaio per tre milioni di anni per il 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% del 40% delle slide che gli stati sotto-ghiaccio che i suoi diastrutti po
2025-05-29 21:14:14,371 - INFO - joeynmt.training - Example #1
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'dr@@', 'ück@@', 't', 'nicht', 'st@@', 'ar@@', 'k', 'gen@@', 'u@@', 'g', 'die', 'Er@@', 'n@@', 'st@@', 'h@@', 'af@@', 'tig@@', 'keit', 'dieses', 'sp@@', 'e@@', 'zi@@', 'ellen', 'Problem@@', 's', 'aus@@', ',', 'da', 'es', 'nicht', 'die', 'D@@', 'ick@@', 'e', 'des', 'E@@', 'is@@', 'es', 'zeig@@', 't.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['T@@', 'utt@@', 'avi@@', 'a', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'ut@@', 'a', 'la', 'gra@@', 'v@@', 'ità', 'del', 'problem@@', 'a', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'g@@', 'hi@@', 'acci@@', 'o.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'abb@@', 'ast@@', 'anza', 'for@@', 'te', 'il', 'problem@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'di', 'questo', 'part@@', 'icol@@', 'are', 'problem@@', 'a', 'del', 'g@@', 'hi@@', 'acci@@', 'o', 'non', 'è', 'il', 'di@@', 'st@@', 'es@@', 'o', 'del', 'g@@', 'hi@@', 'acci@@', 'o.', '</s>']
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Hypothesis: Ma non è abbastanza forte il problema di questo particolare problema di questo particolare problema del ghiaccio non è il disteso del ghiaccio.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - Example #2
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'ge@@', 'wis@@', 's@@', 'em', 'S@@', 'in@@', 'ne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'E@@', 'is@@', 'k@@', 'ap@@', 'p@@', 'e', 'das', 'schl@@', 'ag@@', 'ende', 'Her@@', 'z', 'unser@@', 'es', 'glob@@', 'alen', 'K@@', 'li@@', 'ma@@', 'sy@@', 'stem@@', 's.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'a@@', 'ci@@', 'ale', 'art@@', 'ica', 'è@@', ',', 'in', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'c@@', 'li@@', 'mat@@', 'ico', 'glob@@', 'ale.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cer@@', 'to', 's@@', 'ens@@', 'o,', 'il', 'cu@@', 'ore', 'di', 'g@@', 'hi@@', 'acci@@', 'o', 'è', 'il', 'cu@@', 'ore', 'di', 'c@@', 'li@@', 'ma', 'glob@@', 'ale', 'del', 'nostro', 'c@@', 'li@@', 'ma@@', '.', '</s>']
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Hypothesis: In un certo senso, il cuore di ghiaccio è il cuore di clima globale del nostro clima.
2025-05-29 21:14:14,371 - INFO - joeynmt.training - Example #3
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wä@@', 'ch@@', 'st', 'im', 'W@@', 'in@@', 'ter', 'und', 'sch@@', 'r@@', 'um@@', 'p@@', 'ft', 'im', 'S@@', 'omm@@', 'er.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'ande', "d'@@", 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'ir@@', 'a', "d'@@", 'est@@', 'at@@', 'e.']
2025-05-29 21:14:14,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 's@@', 'ott@@', 'o@@', 'ter@@', 'ra', 'e', "l'@@", 'est@@', 'at@@', 'e.', '</s>']
2025-05-29 21:14:14,371 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-29 21:14:14,372 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-29 21:14:14,372 - INFO - joeynmt.training - 	Hypothesis: Si è sottoterra e l'estate.
2025-05-29 21:14:14,372 - INFO - joeynmt.training - Example #4
2025-05-29 21:14:14,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'näch@@', 'ste', 'F@@', 'ol@@', 'i@@', 'e,', 'die', 'ich', 'Ihnen', 'zeig@@', 'e,', 'ist', 'eine', 'Z@@', 'eit@@', 'ra@@', 'ff@@', 'er@@', 'auf@@', 'nah@@', 'me', 'was', 'in', 'den', 'letz@@', 'ten', '2@@', '5', 'Jahren', 'passier@@', 't', 'ist.']
2025-05-29 21:14:14,372 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'pr@@', 'ossi@@', 'ma', 'di@@', 'a@@', 'posi@@', 'tiv@@', 'a', 'sar@@', 'à', 'una', 'ra@@', 'pi@@', 'da', 'car@@', 'r@@', 'ell@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.']
2025-05-29 21:14:14,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 'de', 'pr@@', 'ossi@@', 'ma', 's@@', 'li@@', 're', 'è', 'una', 'di', 'cam@@', 'pag@@', 'n@@', 'a', 'cosa', 'è', 'succ@@', 'esso', 'negli', 'ulti@@', 'mi', '2@@', '5', 'anni@@', '.', '</s>']
2025-05-29 21:14:14,372 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-29 21:14:14,372 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-29 21:14:14,372 - INFO - joeynmt.training - 	Hypothesis: La prossima slide prossima slire è una di campagna cosa è successo negli ultimi 25 anni.
2025-05-29 21:14:28,524 - INFO - joeynmt.training - Epoch  10, Step:    47100, Batch Loss:     1.761084, Batch Acc: 0.499936, Tokens per Sec:     4945, Lr: 0.000300
2025-05-29 21:14:30,714 - INFO - joeynmt.training - Epoch  10: total training loss 7761.54
2025-05-29 21:14:30,714 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-29 21:14:30,714 - INFO - joeynmt.training - Best validation result (greedy) at step    47000:   5.93 ppl.
2025-05-29 21:14:30,725 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-29 21:14:30,754 - INFO - joeynmt.model - Enc-dec model built.
2025-05-29 21:14:30,767 - INFO - joeynmt.helpers - Load model from /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/47000.ckpt.
2025-05-29 21:14:30,769 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2002),
	loss_function=None)
2025-05-29 21:14:30,773 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-29 21:14:30,773 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:17:05,692 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 154.9142[sec], evaluation: 0.0000[sec]
2025-05-29 21:17:05,695 - INFO - joeynmt.prediction - Translations saved to: /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/00047000.hyps.dev.
2025-05-29 21:17:05,695 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-29 21:17:05,695 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-29 21:20:29,733 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 204.0306[sec], evaluation: 0.0000[sec]
2025-05-29 21:20:29,736 - INFO - joeynmt.prediction - Translations saved to: /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl_2k_v2/00047000.hyps.test.
