2025-05-18 23:43:03,118 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-18 23:43:03,118 - INFO - joeynmt.helpers -                           cfg.name : transformer_sample_config
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                     cfg.data.train : sampled_data/train.de-it
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                       cfg.data.dev : sampled_data/dev.de-it
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                      cfg.data.test : sampled_data/test.de-it
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                  cfg.data.src.lang : de
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : joint_vocab.txt
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : bpe_codes
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : joint_vocab.txt
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : bpe_codes
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.training.model_dir : models_bpelvl
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-18 23:43:03,119 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-18 23:43:03,120 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-18 23:43:03,121 - INFO - joeynmt.data - Building tokenizer...
2025-05-18 23:43:03,152 - INFO - joeynmt.tokenizers - de tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-18 23:43:03,152 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2025-05-18 23:43:03,152 - INFO - joeynmt.data - Loading train set...
2025-05-18 23:43:03,232 - INFO - joeynmt.data - Building vocabulary...
2025-05-18 23:43:08,370 - INFO - joeynmt.data - Loading dev set...
2025-05-18 23:43:08,372 - INFO - joeynmt.data - Loading test set...
2025-05-18 23:43:08,373 - INFO - joeynmt.data - Data loaded.
2025-05-18 23:43:08,374 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-18 23:43:08,374 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=923, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-18 23:43:08,374 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1567, src_lang=de, trg_lang=it, has_trg=True, random_subset=-1)
2025-05-18 23:43:08,374 - INFO - joeynmt.data - First training example:
	[SRC] Al Gor@@ e: Die Ab@@ wend@@ ung der Klima@@ katastrop@@ he
	[TRG] Al Gor@@ e: arrest@@ iamo il riscaldamento globale
2025-05-18 23:43:08,374 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)   (5) £ (6) ¥ (7) © (8) « (9) ®
2025-05-18 23:43:08,374 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4)   (5) £ (6) ¥ (7) © (8) « (9) ®
2025-05-18 23:43:08,374 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 31870
2025-05-18 23:43:08,374 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 31870
2025-05-18 23:43:08,379 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-18 23:43:08,512 - INFO - joeynmt.model - Enc-dec model built.
2025-05-18 23:43:08,514 - INFO - joeynmt.model - Total params: 11057920
2025-05-18 23:43:08,514 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2025-05-18 23:43:08,514 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=31870),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=31870),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-18 23:43:08,514 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-18 23:43:08,514 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-18 23:43:08,514 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-18 23:43:08,514 - INFO - joeynmt.training - EPOCH 1
2025-05-18 23:43:54,188 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     5.170078, Batch Acc: 0.050963, Tokens per Sec:     1398, Lr: 0.000300
2025-05-18 23:44:35,085 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.773207, Batch Acc: 0.064882, Tokens per Sec:     1519, Lr: 0.000300
2025-05-18 23:45:18,245 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     4.816957, Batch Acc: 0.076303, Tokens per Sec:     1477, Lr: 0.000300
2025-05-18 23:46:00,839 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     4.863256, Batch Acc: 0.081906, Tokens per Sec:     1563, Lr: 0.000300
2025-05-18 23:46:39,746 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     4.885501, Batch Acc: 0.083905, Tokens per Sec:     1640, Lr: 0.000300
2025-05-18 23:46:39,746 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-18 23:46:39,746 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-18 23:49:19,339 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.81, ppl: 122.31, acc:   0.08, generation: 159.5801[sec], evaluation: 0.0000[sec]
2025-05-18 23:49:19,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-18 23:49:19,565 - INFO - joeynmt.training - Example #0
2025-05-18 23:49:19,565 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-18 23:49:19,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-18 23:49:19,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Hypothesis: E un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:49:19,566 - INFO - joeynmt.training - Example #1
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Hypothesis: E un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:49:19,566 - INFO - joeynmt.training - Example #2
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Hypothesis: E un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:49:19,566 - INFO - joeynmt.training - Example #3
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è']
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-18 23:49:19,566 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è
2025-05-18 23:49:19,566 - INFO - joeynmt.training - Example #4
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-18 23:49:19,566 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:49:19,567 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-18 23:49:19,567 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-18 23:49:19,567 - INFO - joeynmt.training - 	Hypothesis: E un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:50:02,496 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     4.629152, Batch Acc: 0.084330, Tokens per Sec:     1519, Lr: 0.000300
2025-05-18 23:50:44,664 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     4.757985, Batch Acc: 0.085040, Tokens per Sec:     1512, Lr: 0.000300
2025-05-18 23:51:26,857 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     4.605819, Batch Acc: 0.087587, Tokens per Sec:     1577, Lr: 0.000300
2025-05-18 23:52:09,085 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     4.723162, Batch Acc: 0.088531, Tokens per Sec:     1543, Lr: 0.000300
2025-05-18 23:52:52,430 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     4.737421, Batch Acc: 0.087727, Tokens per Sec:     1525, Lr: 0.000300
2025-05-18 23:52:52,430 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-18 23:52:52,430 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-18 23:55:31,214 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.64, ppl: 104.02, acc:   0.08, generation: 158.7724[sec], evaluation: 0.0000[sec]
2025-05-18 23:55:31,217 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-18 23:55:31,421 - INFO - joeynmt.training - Example #0
2025-05-18 23:55:31,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-18 23:55:31,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-18 23:55:31,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:55:31,421 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-18 23:55:31,421 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-18 23:55:31,421 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:55:31,422 - INFO - joeynmt.training - Example #1
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:55:31,422 - INFO - joeynmt.training - Example #2
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:55:31,422 - INFO - joeynmt.training - Example #3
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:55:31,422 - INFO - joeynmt.training - Example #4
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-18 23:55:31,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-18 23:55:31,422 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-18 23:56:13,339 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     4.434519, Batch Acc: 0.089278, Tokens per Sec:     1473, Lr: 0.000300
2025-05-18 23:56:55,694 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     4.640815, Batch Acc: 0.090620, Tokens per Sec:     1543, Lr: 0.000300
2025-05-18 23:57:38,027 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     4.560756, Batch Acc: 0.090019, Tokens per Sec:     1569, Lr: 0.000300
2025-05-18 23:58:20,283 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     4.546051, Batch Acc: 0.089581, Tokens per Sec:     1487, Lr: 0.000300
2025-05-18 23:59:02,168 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     4.615382, Batch Acc: 0.091765, Tokens per Sec:     1518, Lr: 0.000300
2025-05-18 23:59:02,169 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-18 23:59:02,169 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:01:42,868 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.57, ppl:  96.62, acc:   0.09, generation: 160.6877[sec], evaluation: 0.0000[sec]
2025-05-19 00:01:42,871 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:01:43,081 - INFO - joeynmt.training - Example #0
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Hypothesis: E il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:01:43,082 - INFO - joeynmt.training - Example #1
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Hypothesis: E il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:01:43,082 - INFO - joeynmt.training - Example #2
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Hypothesis: E il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:01:43,082 - INFO - joeynmt.training - Example #3
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:01:43,082 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è', 'è']
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:01:43,082 - INFO - joeynmt.training - 	Hypothesis: E è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è è
2025-05-19 00:01:43,083 - INFO - joeynmt.training - Example #4
2025-05-19 00:01:43,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:01:43,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:01:43,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:01:43,083 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:01:43,083 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:01:43,083 - INFO - joeynmt.training - 	Hypothesis: E il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:02:25,120 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     4.530464, Batch Acc: 0.096551, Tokens per Sec:     1551, Lr: 0.000300
2025-05-19 00:03:07,690 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     4.500464, Batch Acc: 0.092314, Tokens per Sec:     1492, Lr: 0.000300
2025-05-19 00:03:50,281 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     4.671737, Batch Acc: 0.093549, Tokens per Sec:     1531, Lr: 0.000300
2025-05-19 00:04:32,371 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     4.518629, Batch Acc: 0.093370, Tokens per Sec:     1540, Lr: 0.000300
2025-05-19 00:05:15,514 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     4.532166, Batch Acc: 0.094258, Tokens per Sec:     1528, Lr: 0.000300
2025-05-19 00:05:15,515 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:05:15,515 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:07:56,634 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.55, ppl:  94.63, acc:   0.09, generation: 161.1071[sec], evaluation: 0.0000[sec]
2025-05-19 00:07:56,636 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:07:56,862 - INFO - joeynmt.training - Example #0
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'modo', 'che', 'la', 'modo', 'che', 'la', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-19 00:07:56,862 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:07:56,862 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:07:56,862 - INFO - joeynmt.training - 	Hypothesis: E la modo che la modo che la modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di
2025-05-19 00:07:56,862 - INFO - joeynmt.training - Example #1
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:07:56,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa']
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Hypothesis: E la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa che la cosa la cosa la cosa la cosa che la cosa la cosa la cosa
2025-05-19 00:07:56,863 - INFO - joeynmt.training - Example #2
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'modo', 'che', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Hypothesis: E la modo che un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di
2025-05-19 00:07:56,863 - INFO - joeynmt.training - Example #3
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'la', 'cosa', 'la', 'cosa', 'di', 'un', 'cosa', 'la', 'cosa', 'la', 'cosa']
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Hypothesis: E la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa la cosa che la cosa la cosa la cosa la cosa la cosa la cosa di un cosa di un cosa la cosa la cosa di un cosa la cosa la cosa
2025-05-19 00:07:56,863 - INFO - joeynmt.training - Example #4
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:07:56,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa', 'che', 'la', 'cosa']
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:07:56,863 - INFO - joeynmt.training - 	Hypothesis: E la cosa la cosa la cosa la cosa che la cosa che la cosa che la cosa che la cosa la cosa che la cosa la cosa la cosa che la cosa la cosa che la cosa che la cosa la cosa la cosa la cosa che la cosa che la cosa che la cosa la cosa che la cosa che la cosa che la cosa
2025-05-19 00:08:38,608 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     4.567563, Batch Acc: 0.092665, Tokens per Sec:     1540, Lr: 0.000300
2025-05-19 00:09:21,393 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     4.408219, Batch Acc: 0.094839, Tokens per Sec:     1532, Lr: 0.000300
2025-05-19 00:10:02,195 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     4.637225, Batch Acc: 0.093912, Tokens per Sec:     1559, Lr: 0.000300
2025-05-19 00:10:44,389 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     4.584852, Batch Acc: 0.093856, Tokens per Sec:     1517, Lr: 0.000300
2025-05-19 00:11:26,458 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     4.670863, Batch Acc: 0.093671, Tokens per Sec:     1560, Lr: 0.000300
2025-05-19 00:11:26,459 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:11:26,459 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:14:08,651 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.54, ppl:  93.61, acc:   0.09, generation: 162.1801[sec], evaluation: 0.0000[sec]
2025-05-19 00:14:08,653 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:14:08,874 - INFO - joeynmt.training - Example #0
2025-05-19 00:14:08,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:14:08,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Hypothesis: Il un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 00:14:08,875 - INFO - joeynmt.training - Example #1
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Hypothesis: E la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 00:14:08,875 - INFO - joeynmt.training - Example #2
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Hypothesis: Il un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 00:14:08,875 - INFO - joeynmt.training - Example #3
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'la', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:14:08,875 - INFO - joeynmt.training - 	Hypothesis: Ma la un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 00:14:08,875 - INFO - joeynmt.training - Example #4
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:14:08,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 00:14:08,876 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:14:08,876 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:14:08,876 - INFO - joeynmt.training - 	Hypothesis: Il un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 00:14:50,156 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     4.459292, Batch Acc: 0.094273, Tokens per Sec:     1539, Lr: 0.000300
2025-05-19 00:15:32,325 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     4.405437, Batch Acc: 0.096568, Tokens per Sec:     1579, Lr: 0.000300
2025-05-19 00:16:14,120 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     4.392112, Batch Acc: 0.095765, Tokens per Sec:     1534, Lr: 0.000300
2025-05-19 00:16:56,383 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     4.476308, Batch Acc: 0.097188, Tokens per Sec:     1559, Lr: 0.000300
2025-05-19 00:17:35,764 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     4.486340, Batch Acc: 0.097708, Tokens per Sec:     1597, Lr: 0.000300
2025-05-19 00:17:35,764 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:17:35,765 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:20:19,418 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.50, ppl:  90.43, acc:   0.09, generation: 163.6414[sec], evaluation: 0.0000[sec]
2025-05-19 00:20:19,420 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:20:19,628 - INFO - joeynmt.helpers - delete models_bpelvl/500.ckpt
2025-05-19 00:20:19,629 - INFO - joeynmt.training - Example #0
2025-05-19 00:20:19,629 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:20:19,629 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:20:19,629 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'e', 'la', 'loro', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'loro', 'mondo', 'di', 'un']
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Hypothesis: E la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo e la loro mondo di un mondo di un loro mondo di un
2025-05-19 00:20:19,630 - INFO - joeynmt.training - Example #1
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', 'mondo', 'che', 'la', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Hypothesis: E la mio mondo che la mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:20:19,630 - INFO - joeynmt.training - Example #2
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'loro', 'loro', 'loro', 'loro', 'loro']
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Hypothesis: E la mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un loro loro loro loro loro
2025-05-19 00:20:19,630 - INFO - joeynmt.training - Example #3
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'la', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:20:19,630 - INFO - joeynmt.training - 	Hypothesis: Non la mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 00:20:19,630 - INFO - joeynmt.training - Example #4
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:20:19,630 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un']
2025-05-19 00:20:19,631 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:20:19,631 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:20:19,631 - INFO - joeynmt.training - 	Hypothesis: La mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un
2025-05-19 00:21:01,922 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     4.558885, Batch Acc: 0.097965, Tokens per Sec:     1511, Lr: 0.000300
2025-05-19 00:21:41,205 - INFO - joeynmt.training - Epoch   1: total training loss 14808.96
2025-05-19 00:21:41,206 - INFO - joeynmt.training - EPOCH 2
2025-05-19 00:21:43,628 - INFO - joeynmt.training - Epoch   2, Step:     3200, Batch Loss:     4.489048, Batch Acc: 0.098806, Tokens per Sec:     1521, Lr: 0.000300
2025-05-19 00:22:25,610 - INFO - joeynmt.training - Epoch   2, Step:     3300, Batch Loss:     4.464875, Batch Acc: 0.098153, Tokens per Sec:     1567, Lr: 0.000300
2025-05-19 00:23:07,730 - INFO - joeynmt.training - Epoch   2, Step:     3400, Batch Loss:     4.485538, Batch Acc: 0.099975, Tokens per Sec:     1502, Lr: 0.000300
2025-05-19 00:23:50,311 - INFO - joeynmt.training - Epoch   2, Step:     3500, Batch Loss:     4.528540, Batch Acc: 0.095867, Tokens per Sec:     1513, Lr: 0.000300
2025-05-19 00:23:50,312 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:23:50,312 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:26:31,134 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.53, ppl:  92.40, acc:   0.09, generation: 160.8103[sec], evaluation: 0.0000[sec]
2025-05-19 00:26:31,343 - INFO - joeynmt.helpers - delete models_bpelvl/1000.ckpt
2025-05-19 00:26:31,344 - INFO - joeynmt.training - Example #0
2025-05-19 00:26:31,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:26:31,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:26:31,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'la', 'mondo', 'di', 'un', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è']
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Hypothesis: Il mondo che è il mondo che è il mondo che è il mondo che è il mondo che è la mondo di un mondo che è la mondo che è il mondo che è la mondo che è il mondo che è il mondo che è il mondo che è il mondo che è il mondo che è la mondo che è la mondo che è
2025-05-19 00:26:31,345 - INFO - joeynmt.training - Example #1
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mondo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'che', 'è', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo', 'che', 'è', 'il', 'mondo']
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Hypothesis: E il mondo che è che è che è che è che è che è che è che è il mondo che è il mondo che è il mondo che è che è il mondo che è il mondo che è che è che è il mondo che è il mondo che è il mondo che è il mondo che è il mondo che è il mondo
2025-05-19 00:26:31,345 - INFO - joeynmt.training - Example #2
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che', 'è', 'la', 'mondo', 'che']
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Hypothesis: Il mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che è la mondo che
2025-05-19 00:26:31,345 - INFO - joeynmt.training - Example #3
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un']
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:26:31,345 - INFO - joeynmt.training - 	Hypothesis: Il mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un
2025-05-19 00:26:31,345 - INFO - joeynmt.training - Example #4
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:26:31,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 00:26:31,346 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:26:31,346 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:26:31,346 - INFO - joeynmt.training - 	Hypothesis: Il mondo che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 00:27:13,490 - INFO - joeynmt.training - Epoch   2, Step:     3600, Batch Loss:     4.275284, Batch Acc: 0.099232, Tokens per Sec:     1528, Lr: 0.000300
2025-05-19 00:27:57,138 - INFO - joeynmt.training - Epoch   2, Step:     3700, Batch Loss:     4.333814, Batch Acc: 0.100248, Tokens per Sec:     1471, Lr: 0.000300
2025-05-19 00:28:39,463 - INFO - joeynmt.training - Epoch   2, Step:     3800, Batch Loss:     4.467629, Batch Acc: 0.097816, Tokens per Sec:     1522, Lr: 0.000300
2025-05-19 00:29:23,152 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     4.445246, Batch Acc: 0.099593, Tokens per Sec:     1478, Lr: 0.000300
2025-05-19 00:30:04,765 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     4.415269, Batch Acc: 0.100343, Tokens per Sec:     1561, Lr: 0.000300
2025-05-19 00:30:04,765 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:30:04,765 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:32:45,602 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.45, ppl:  85.69, acc:   0.10, generation: 160.8249[sec], evaluation: 0.0000[sec]
2025-05-19 00:32:45,605 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:32:45,806 - INFO - joeynmt.helpers - delete models_bpelvl/1500.ckpt
2025-05-19 00:32:45,808 - INFO - joeynmt.training - Example #0
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'e', 'un', 'mondo', 'e', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un']
2025-05-19 00:32:45,808 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:32:45,808 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:32:45,808 - INFO - joeynmt.training - 	Hypothesis: La mondo e il mondo e il mondo e il mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo e un mondo e un mondo di un mondo di un mondo di un
2025-05-19 00:32:45,808 - INFO - joeynmt.training - Example #1
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:32:45,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'cosa', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'mondo', 'di', 'un', 'modo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'che', 'non', 'è', 'un', 'mondo', 'che', 'non', 'è', 'un', 'mondo', 'di', 'un', 'mio', 'mondo', 'di', 'un', 'mio']
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Hypothesis: Ma non è un cosa un modo di un modo di un mondo di un modo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo che è un mondo di un mondo di un mondo che non è un mondo che non è un mondo di un mio mondo di un mio
2025-05-19 00:32:45,809 - INFO - joeynmt.training - Example #2
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'di', 'un', 'parte', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'mondo', 'di', 'un', 'modo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'mondo', 'di', 'un']
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Hypothesis: La mio di un parte di un modo di un modo di un mondo di un modo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mio parte di un mondo di un mondo di un mondo di un mio parte di un mio mondo di un
2025-05-19 00:32:45,809 - INFO - joeynmt.training - Example #3
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'cosa', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'mio', 'di', 'un', 'mio', 'di', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'il', 'mio', 'cosa', 'un', 'mio', 'cosa', 'il', 'mio', 'cosa', 'un', 'di', 'un', 'di', 'un', 'mio', 'cosa', 'il', 'mio', 'cosa', 'il', 'mio', 'cosa', 'il', 'mio', 'cosa', 'il', 'mio', 'cosa', 'il', 'mio', 'cosa', 'il', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Hypothesis: La mio cosa un di un di un di un di un di un di un di un di un mio di un mio di un mio cosa un mio cosa il mio cosa un mio cosa il mio cosa un di un di un mio cosa il mio cosa il mio cosa il mio cosa il mio cosa il mio cosa il mio mio mio mio
2025-05-19 00:32:45,809 - INFO - joeynmt.training - Example #4
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:32:45,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'di', 'un', 'parte', 'di', 'un', 'modo', 'di', 'un', 'parte', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un']
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:32:45,809 - INFO - joeynmt.training - 	Hypothesis: La mondo di un parte di un modo di un parte di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un
2025-05-19 00:33:28,650 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     4.440731, Batch Acc: 0.101518, Tokens per Sec:     1506, Lr: 0.000300
2025-05-19 00:34:10,500 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     4.529902, Batch Acc: 0.098757, Tokens per Sec:     1551, Lr: 0.000300
2025-05-19 00:34:49,396 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     4.503210, Batch Acc: 0.101876, Tokens per Sec:     1672, Lr: 0.000300
2025-05-19 00:35:29,376 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     4.386436, Batch Acc: 0.100166, Tokens per Sec:     1569, Lr: 0.000300
2025-05-19 00:36:09,062 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     4.477298, Batch Acc: 0.097410, Tokens per Sec:     1651, Lr: 0.000300
2025-05-19 00:36:09,063 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:36:09,063 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:38:52,738 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.46, ppl:  86.29, acc:   0.10, generation: 163.6676[sec], evaluation: 0.0000[sec]
2025-05-19 00:38:52,945 - INFO - joeynmt.helpers - delete models_bpelvl/2000.ckpt
2025-05-19 00:38:52,946 - INFO - joeynmt.training - Example #0
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'e', 'il', 'nostro', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un']
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Hypothesis: E la mondo di un mondo anni di un mondo di un mondo anni di un mondo e il nostro mondo anni di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo anni di un
2025-05-19 00:38:52,947 - INFO - joeynmt.training - Example #1
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'il', 'mio', 'cosa', 'la', 'mio', 'cosa', '</s>']
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Hypothesis: Ma il mio cosa la mio cosa
2025-05-19 00:38:52,947 - INFO - joeynmt.training - Example #2
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'a,', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'anni', 'di', 'un', 'mondo', 'anni']
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Hypothesis: E la mondo di un mondo anni di un mondo di un mondo anni di un mondo a, di un mondo anni di un mondo di un mondo di un mondo di un mondo di un mondo anni di un mondo di un mondo di un mondo anni di un mondo anni di un mondo di un mondo anni di un mondo anni di un mondo anni
2025-05-19 00:38:52,947 - INFO - joeynmt.training - Example #3
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:38:52,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'di', 'un', 'cosa', '</s>']
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:38:52,947 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:38:52,948 - INFO - joeynmt.training - 	Hypothesis: E è di un cosa
2025-05-19 00:38:52,948 - INFO - joeynmt.training - Example #4
2025-05-19 00:38:52,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:38:52,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:38:52,948 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'mio', 'cosa', '</s>']
2025-05-19 00:38:52,948 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:38:52,948 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:38:52,948 - INFO - joeynmt.training - 	Hypothesis: E il mio cosa
2025-05-19 00:39:36,093 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     4.263903, Batch Acc: 0.099649, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 00:40:18,350 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     4.590182, Batch Acc: 0.101802, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 00:41:01,365 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     4.361783, Batch Acc: 0.098515, Tokens per Sec:     1557, Lr: 0.000300
2025-05-19 00:41:44,129 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     4.344297, Batch Acc: 0.102035, Tokens per Sec:     1521, Lr: 0.000300
2025-05-19 00:42:26,759 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     4.435497, Batch Acc: 0.103635, Tokens per Sec:     1509, Lr: 0.000300
2025-05-19 00:42:26,759 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:42:26,759 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:45:08,006 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.42, ppl:  82.69, acc:   0.10, generation: 161.2348[sec], evaluation: 0.0000[sec]
2025-05-19 00:45:08,008 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:45:08,224 - INFO - joeynmt.helpers - delete models_bpelvl/2500.ckpt
2025-05-19 00:45:08,226 - INFO - joeynmt.training - Example #0
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', "po'", 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'che', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo']
2025-05-19 00:45:08,226 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:45:08,226 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:45:08,226 - INFO - joeynmt.training - 	Hypothesis: E la mio po' di un mondo di un mondo che è che non è che è che non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è un mondo di un mondo
2025-05-19 00:45:08,226 - INFO - joeynmt.training - Example #1
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:45:08,226 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'un', 'mio', 'cosa', 'un', 'mio', "po'", 'di', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'mio', 'mio']
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Hypothesis: Ma è un mio cosa un mio po' di un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio cosa un mio mio mio
2025-05-19 00:45:08,227 - INFO - joeynmt.training - Example #2
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'parte', 'di', 'un', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Hypothesis: E la mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio parte di un mio mio mio mio mio
2025-05-19 00:45:08,227 - INFO - joeynmt.training - Example #3
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Hypothesis: E non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 00:45:08,227 - INFO - joeynmt.training - Example #4
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:45:08,227 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'di', 'un', 'mio', 'modo', 'di', 'un']
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:45:08,227 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non è che non è che non è che non è che non è che è che è che non è che non è che non è che è che è che è che è che è che è che è che è che non è che non è che è che non è di un mio modo di un
2025-05-19 00:45:51,456 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     4.474353, Batch Acc: 0.106207, Tokens per Sec:     1541, Lr: 0.000300
2025-05-19 00:46:34,172 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     4.428946, Batch Acc: 0.103485, Tokens per Sec:     1521, Lr: 0.000300
2025-05-19 00:47:15,979 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     4.382552, Batch Acc: 0.104572, Tokens per Sec:     1568, Lr: 0.000300
2025-05-19 00:47:58,521 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     4.388891, Batch Acc: 0.103280, Tokens per Sec:     1511, Lr: 0.000300
2025-05-19 00:48:39,830 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     4.351880, Batch Acc: 0.105721, Tokens per Sec:     1571, Lr: 0.000300
2025-05-19 00:48:39,830 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:48:39,831 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:51:23,191 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  80.14, acc:   0.10, generation: 163.3487[sec], evaluation: 0.0000[sec]
2025-05-19 00:51:23,193 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 00:51:23,411 - INFO - joeynmt.helpers - delete models_bpelvl/3500.ckpt
2025-05-19 00:51:23,412 - INFO - joeynmt.training - Example #0
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'un', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'mondo', 'di', 'un', 'mondo']
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Hypothesis: E la mondo di un cosa un cosa un cosa un cosa un cosa un cosa un cosa un mondo di un cosa la mondo di un cosa un cosa un cosa un mondo di un mondo di un mondo di un cosa un cosa un mondo di un cosa un cosa un cosa un cosa un cosa un cosa un cosa un mondo di un mondo
2025-05-19 00:51:23,412 - INFO - joeynmt.training - Example #1
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 00:51:23,412 - INFO - joeynmt.training - Example #2
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:51:23,412 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia']
2025-05-19 00:51:23,412 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Hypothesis: E la mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia
2025-05-19 00:51:23,413 - INFO - joeynmt.training - Example #3
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia', 'mia']
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Hypothesis: La mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia mia
2025-05-19 00:51:23,413 - INFO - joeynmt.training - Example #4
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:51:23,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'che', 'è', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un']
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:51:23,413 - INFO - joeynmt.training - 	Hypothesis: La mondo di un cosa la mondo che è un cosa un cosa un cosa un cosa un cosa un cosa la mondo di un cosa la mondo di un cosa la mondo di un cosa un cosa la mondo di un cosa la mondo di un cosa la mondo di un cosa un cosa la mondo di un cosa un cosa un cosa un cosa un
2025-05-19 00:52:03,692 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     4.506636, Batch Acc: 0.105267, Tokens per Sec:     1636, Lr: 0.000300
2025-05-19 00:52:42,933 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     4.439064, Batch Acc: 0.103695, Tokens per Sec:     1664, Lr: 0.000300
2025-05-19 00:53:22,731 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     4.415338, Batch Acc: 0.105151, Tokens per Sec:     1615, Lr: 0.000300
2025-05-19 00:54:05,403 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     4.393209, Batch Acc: 0.103989, Tokens per Sec:     1560, Lr: 0.000300
2025-05-19 00:54:47,630 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     4.256522, Batch Acc: 0.103745, Tokens per Sec:     1539, Lr: 0.000300
2025-05-19 00:54:47,630 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 00:54:47,630 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 00:57:29,615 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.39, ppl:  80.33, acc:   0.10, generation: 161.9735[sec], evaluation: 0.0000[sec]
2025-05-19 00:57:29,819 - INFO - joeynmt.helpers - delete models_bpelvl/3000.ckpt
2025-05-19 00:57:29,821 - INFO - joeynmt.training - Example #0
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'è', 'un', 'volta', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'volta', 'che', 'è', 'un', 'mondo', 'di', 'un', 'volta', 'che', 'la', 'mondo', 'di', 'un', 'mondo', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Hypothesis: E la mondo che la mondo che è un volta che la mondo che la mondo che la mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un volta che è un mondo di un volta che la mondo di un mondo che è un mondo di un mondo di un mondo di
2025-05-19 00:57:29,821 - INFO - joeynmt.training - Example #1
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'un', 'cosa', 'la', 'mondo', 'che', 'è', 'un', 'cosa', 'la', 'mondo', 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', "po'", 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', "po'", 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Hypothesis: Ma è un cosa la mondo che è un cosa la mondo che è un po' di un po' di un po' di un po' di un po' di un cosa la mondo di un po' di un po' di un cosa la mondo di un po' di un cosa la mondo di un po' di un cosa la mondo di un po' di un po' di
2025-05-19 00:57:29,821 - INFO - joeynmt.training - Example #2
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 00:57:29,821 - INFO - joeynmt.training - 	Hypothesis: E è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 00:57:29,821 - INFO - joeynmt.training - Example #3
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 00:57:29,821 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'mio', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'un', 'cosa', 'è', 'un', 'cosa', 'è', 'un', 'cosa', 'un', 'mio', 'cosa', 'un', 'mio', 'mio', 'mio']
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Hypothesis: La mio cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un cosa è un mio cosa è un cosa è un cosa è un cosa è un cosa un cosa è un cosa è un cosa un mio cosa un mio mio mio
2025-05-19 00:57:29,822 - INFO - joeynmt.training - Example #4
2025-05-19 00:57:29,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 00:57:29,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 00:57:29,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un']
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 00:57:29,822 - INFO - joeynmt.training - 	Hypothesis: La mondo e la mondo e la mondo di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un
2025-05-19 00:58:12,269 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     4.255771, Batch Acc: 0.105087, Tokens per Sec:     1559, Lr: 0.000300
2025-05-19 00:58:54,021 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     4.359732, Batch Acc: 0.103400, Tokens per Sec:     1562, Lr: 0.000300
2025-05-19 00:59:36,102 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     4.401905, Batch Acc: 0.104526, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 01:00:06,028 - INFO - joeynmt.training - Epoch   2: total training loss 14032.44
2025-05-19 01:00:06,029 - INFO - joeynmt.training - EPOCH 3
2025-05-19 01:00:18,353 - INFO - joeynmt.training - Epoch   3, Step:     6400, Batch Loss:     4.318939, Batch Acc: 0.106051, Tokens per Sec:     1507, Lr: 0.000300
2025-05-19 01:01:00,860 - INFO - joeynmt.training - Epoch   3, Step:     6500, Batch Loss:     4.198534, Batch Acc: 0.106209, Tokens per Sec:     1528, Lr: 0.000300
2025-05-19 01:01:00,860 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:01:00,860 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:03:41,952 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.79, acc:   0.10, generation: 161.0796[sec], evaluation: 0.0000[sec]
2025-05-19 01:03:41,955 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 01:03:42,162 - INFO - joeynmt.helpers - delete models_bpelvl/4500.ckpt
2025-05-19 01:03:42,163 - INFO - joeynmt.training - Example #0
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'non', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un']
2025-05-19 01:03:42,163 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:03:42,163 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:03:42,163 - INFO - joeynmt.training - 	Hypothesis: E non è che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è che non è un po' che non non non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un
2025-05-19 01:03:42,163 - INFO - joeynmt.training - Example #1
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:03:42,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che']
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che non è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che
2025-05-19 01:03:42,164 - INFO - joeynmt.training - Example #2
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Hypothesis: E non è un po' che è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 01:03:42,164 - INFO - joeynmt.training - Example #3
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Hypothesis: E la mondo di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 01:03:42,164 - INFO - joeynmt.training - Example #4
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:03:42,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:03:42,164 - INFO - joeynmt.training - 	Hypothesis: E non è un po' che è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' di un po' di un po' di un po' di un po' di un po' che non è un po' di un po' di un po' di un
2025-05-19 01:04:24,470 - INFO - joeynmt.training - Epoch   3, Step:     6600, Batch Loss:     4.321323, Batch Acc: 0.104665, Tokens per Sec:     1553, Lr: 0.000300
2025-05-19 01:05:06,427 - INFO - joeynmt.training - Epoch   3, Step:     6700, Batch Loss:     4.315644, Batch Acc: 0.103137, Tokens per Sec:     1545, Lr: 0.000300
2025-05-19 01:05:48,815 - INFO - joeynmt.training - Epoch   3, Step:     6800, Batch Loss:     4.216326, Batch Acc: 0.103952, Tokens per Sec:     1528, Lr: 0.000300
2025-05-19 01:06:31,306 - INFO - joeynmt.training - Epoch   3, Step:     6900, Batch Loss:     4.344339, Batch Acc: 0.105072, Tokens per Sec:     1505, Lr: 0.000300
2025-05-19 01:07:11,602 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     4.306800, Batch Acc: 0.105322, Tokens per Sec:     1661, Lr: 0.000300
2025-05-19 01:07:11,602 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:07:11,602 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:09:51,390 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.87, acc:   0.10, generation: 159.7746[sec], evaluation: 0.0000[sec]
2025-05-19 01:09:51,602 - INFO - joeynmt.helpers - delete models_bpelvl/4000.ckpt
2025-05-19 01:09:51,604 - INFO - joeynmt.training - Example #0
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'la', 'parte', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'parte', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di']
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Hypothesis: E non la parte di un cosa la mondo di un parte di un cosa la mondo di un cosa la mondo di un cosa la mondo di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di
2025-05-19 01:09:51,604 - INFO - joeynmt.training - Example #1
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'la', 'mondo', 'di', 'un', 'cosa', 'la', 'mondo', 'di']
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:09:51,604 - INFO - joeynmt.training - 	Hypothesis: Ma non è che è un cosa non è un cosa la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo di un cosa la mondo di un cosa la mondo di un cosa la mondo di un cosa non è un cosa la mondo di un cosa la mondo di
2025-05-19 01:09:51,604 - INFO - joeynmt.training - Example #2
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:09:51,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Hypothesis: E è un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 01:09:51,605 - INFO - joeynmt.training - Example #3
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Hypothesis: E sono sono sono sono sono sono di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 01:09:51,605 - INFO - joeynmt.training - Example #4
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:09:51,605 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'modo', 'che', 'sono']
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:09:51,605 - INFO - joeynmt.training - 	Hypothesis: Il mondo di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un modo che sono
2025-05-19 01:10:34,412 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     4.493306, Batch Acc: 0.103077, Tokens per Sec:     1501, Lr: 0.000300
2025-05-19 01:11:17,248 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     4.235729, Batch Acc: 0.106297, Tokens per Sec:     1496, Lr: 0.000300
2025-05-19 01:11:59,423 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     4.400034, Batch Acc: 0.105335, Tokens per Sec:     1520, Lr: 0.000300
2025-05-19 01:12:42,227 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     4.449998, Batch Acc: 0.103641, Tokens per Sec:     1538, Lr: 0.000300
2025-05-19 01:13:25,796 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     4.482608, Batch Acc: 0.106372, Tokens per Sec:     1498, Lr: 0.000300
2025-05-19 01:13:25,796 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:13:25,796 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:16:07,762 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.45, ppl:  85.76, acc:   0.10, generation: 161.9541[sec], evaluation: 0.0000[sec]
2025-05-19 01:16:07,766 - INFO - joeynmt.training - Example #0
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo']
2025-05-19 01:16:07,766 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:16:07,766 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:16:07,766 - INFO - joeynmt.training - 	Hypothesis: La mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo
2025-05-19 01:16:07,766 - INFO - joeynmt.training - Example #1
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:16:07,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'è', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'di', 'un', 'cosa', 'di', 'un', 'cosa']
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Hypothesis: E è di un cosa è di un cosa è di un cosa è di un cosa è di un cosa è di un cosa è di un cosa è di un cosa è di un cosa di un cosa di un cosa è di un cosa è di un cosa di un cosa è di un cosa di un cosa di un cosa di un cosa
2025-05-19 01:16:07,767 - INFO - joeynmt.training - Example #2
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di']
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Hypothesis: La mondo di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di
2025-05-19 01:16:07,767 - INFO - joeynmt.training - Example #3
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['di', 'un', 'cosa', 'è', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'sono', 'la', 'loro', 'di']
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Hypothesis: di un cosa è la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro sono la loro di
2025-05-19 01:16:07,767 - INFO - joeynmt.training - Example #4
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:16:07,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il']
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:16:07,767 - INFO - joeynmt.training - 	Hypothesis: La mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il
2025-05-19 01:16:50,507 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     4.327687, Batch Acc: 0.103177, Tokens per Sec:     1494, Lr: 0.000300
2025-05-19 01:17:32,909 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     4.518534, Batch Acc: 0.102204, Tokens per Sec:     1497, Lr: 0.000300
2025-05-19 01:18:15,538 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     4.281459, Batch Acc: 0.099739, Tokens per Sec:     1530, Lr: 0.000300
2025-05-19 01:18:58,591 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     4.269277, Batch Acc: 0.105220, Tokens per Sec:     1485, Lr: 0.000300
2025-05-19 01:19:41,983 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     4.396253, Batch Acc: 0.098341, Tokens per Sec:     1537, Lr: 0.000300
2025-05-19 01:19:41,984 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:19:41,984 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:22:23,436 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.41, ppl:  81.91, acc:   0.10, generation: 161.4399[sec], evaluation: 0.0000[sec]
2025-05-19 01:22:23,639 - INFO - joeynmt.helpers - delete models_bpelvl/5000.ckpt
2025-05-19 01:22:23,640 - INFO - joeynmt.training - Example #0
2025-05-19 01:22:23,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:22:23,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:22:23,640 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'che', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'che', 'la', 'mondo', 'e', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la']
2025-05-19 01:22:23,640 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:22:23,640 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Hypothesis: La mondo che la mondo e la mondo e la mondo e la mondo e la mondo e la mondo e la mondo che la mondo e la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la
2025-05-19 01:22:23,641 - INFO - joeynmt.training - Example #1
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Hypothesis: Ma è che non non non non non è che non è che è che è che è che è che è che non è che non è che non è che non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 01:22:23,641 - INFO - joeynmt.training - Example #2
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un']
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Hypothesis: E è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un
2025-05-19 01:22:23,641 - INFO - joeynmt.training - Example #3
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'di', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'di', 'un', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'che', 'è', 'un']
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Hypothesis: E è un modo che è un modo di è un modo di un modo di un modo di un modo di un modo di un modo di un di un di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo che è un
2025-05-19 01:22:23,641 - INFO - joeynmt.training - Example #4
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:22:23,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'un', "po'", 'che', 'è', 'che']
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:22:23,641 - INFO - joeynmt.training - 	Hypothesis: Il mondo che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è un po' che è che
2025-05-19 01:23:06,091 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     4.370014, Batch Acc: 0.104289, Tokens per Sec:     1500, Lr: 0.000300
2025-05-19 01:23:48,709 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     4.344761, Batch Acc: 0.104040, Tokens per Sec:     1537, Lr: 0.000300
2025-05-19 01:24:31,540 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     4.268102, Batch Acc: 0.104807, Tokens per Sec:     1498, Lr: 0.000300
2025-05-19 01:25:14,737 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     4.323601, Batch Acc: 0.106573, Tokens per Sec:     1492, Lr: 0.000300
2025-05-19 01:25:57,133 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     4.428808, Batch Acc: 0.108557, Tokens per Sec:     1506, Lr: 0.000300
2025-05-19 01:25:57,133 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:25:57,133 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:28:39,191 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.35, ppl:  77.70, acc:   0.10, generation: 162.0452[sec], evaluation: 0.0000[sec]
2025-05-19 01:28:39,192 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 01:28:39,403 - INFO - joeynmt.helpers - delete models_bpelvl/8000.ckpt
2025-05-19 01:28:39,404 - INFO - joeynmt.training - Example #0
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'che', 'è', 'un', 'cosa', 'il', 'mondo']
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Hypothesis: In un cosa non è un cosa il mondo di un cosa non è un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa non è un cosa il mondo di un cosa non è un cosa il mondo di un cosa il mondo che è un cosa il mondo
2025-05-19 01:28:39,405 - INFO - joeynmt.training - Example #1
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Hypothesis: Ma non è non è non è non è non è non è non è non è non è non è che non è che non è non è che non è che non è che è che è che è che è che è che è che è che è che non è non è che è che è che è che è che è che
2025-05-19 01:28:39,405 - INFO - joeynmt.training - Example #2
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Se', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'e', 'il', 'mondo', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un']
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:28:39,405 - INFO - joeynmt.training - 	Hypothesis: Se il mondo e il mondo e il mondo e il mondo e il mondo e il mondo e il mondo di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un
2025-05-19 01:28:39,405 - INFO - joeynmt.training - Example #3
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:28:39,405 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'nostro', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'parte', 'di', 'un', 'di']
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Hypothesis: E il nostro di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un parte di un di
2025-05-19 01:28:39,406 - INFO - joeynmt.training - Example #4
2025-05-19 01:28:39,406 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:28:39,406 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:28:39,406 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'che', 'è', 'un', 'cosa', 'il', 'mondo', 'che', 'è', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', 'cosa', 'il', 'mondo', 'di', 'un', "po'"]
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:28:39,406 - INFO - joeynmt.training - 	Hypothesis: La mondo che è un cosa il mondo che è un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un cosa il mondo di un po'
2025-05-19 01:29:21,354 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     4.032905, Batch Acc: 0.107482, Tokens per Sec:     1547, Lr: 0.000300
2025-05-19 01:30:03,269 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     4.271102, Batch Acc: 0.108130, Tokens per Sec:     1585, Lr: 0.000300
2025-05-19 01:30:46,432 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     4.290458, Batch Acc: 0.109870, Tokens per Sec:     1559, Lr: 0.000300
2025-05-19 01:31:29,449 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     4.401994, Batch Acc: 0.106327, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 01:32:13,260 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     4.187506, Batch Acc: 0.108821, Tokens per Sec:     1499, Lr: 0.000300
2025-05-19 01:32:13,261 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:32:13,262 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:34:55,814 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.34, ppl:  76.53, acc:   0.10, generation: 162.5407[sec], evaluation: 0.0000[sec]
2025-05-19 01:34:55,817 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 01:34:56,016 - INFO - joeynmt.helpers - delete models_bpelvl/6000.ckpt
2025-05-19 01:34:56,018 - INFO - joeynmt.training - Example #0
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'e', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Hypothesis: La mondo e non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 01:34:56,018 - INFO - joeynmt.training - Example #1
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:34:56,018 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 01:34:56,018 - INFO - joeynmt.training - Example #2
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:34:56,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['TED', 'Talk', 'Subtitles', 'Subtitles', 'Subtitles', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri']
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Hypothesis: TED Talk Subtitles Subtitles Subtitles nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri
2025-05-19 01:34:56,019 - INFO - joeynmt.training - Example #3
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Questo', 'è', 'il', 'nostro', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di']
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Hypothesis: Questo è il nostro di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di
2025-05-19 01:34:56,019 - INFO - joeynmt.training - Example #4
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:34:56,019 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:34:56,019 - INFO - joeynmt.training - 	Hypothesis: La mia po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 01:35:39,238 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     4.214198, Batch Acc: 0.107709, Tokens per Sec:     1449, Lr: 0.000300
2025-05-19 01:36:22,189 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     4.289064, Batch Acc: 0.108749, Tokens per Sec:     1539, Lr: 0.000300
2025-05-19 01:37:04,764 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     4.277824, Batch Acc: 0.108507, Tokens per Sec:     1539, Lr: 0.000300
2025-05-19 01:37:47,637 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     4.235126, Batch Acc: 0.109990, Tokens per Sec:     1479, Lr: 0.000300
2025-05-19 01:38:30,955 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     4.314948, Batch Acc: 0.109896, Tokens per Sec:     1484, Lr: 0.000300
2025-05-19 01:38:30,955 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:38:30,955 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:41:13,243 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.36, ppl:  77.92, acc:   0.10, generation: 162.2765[sec], evaluation: 0.0000[sec]
2025-05-19 01:41:13,445 - INFO - joeynmt.helpers - delete models_bpelvl/5500.ckpt
2025-05-19 01:41:13,446 - INFO - joeynmt.training - Example #0
2025-05-19 01:41:13,446 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:41:13,446 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:41:13,446 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Hypothesis: E la mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 01:41:13,447 - INFO - joeynmt.training - Example #1
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Hypothesis: Ma non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 01:41:13,447 - INFO - joeynmt.training - Example #2
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'", 'che', 'è', 'di', 'un', "po'"]
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Hypothesis: E la mondo che è di un po' che è di un po' che è di un po' che è di un po' che è un po' che è di un po' che è di un po' che è di un po' che è di un po' che è di un po' che è di un po' che è di un po' che è di un po'
2025-05-19 01:41:13,447 - INFO - joeynmt.training - Example #3
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mia', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:41:13,447 - INFO - joeynmt.training - 	Hypothesis: E la mia po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 01:41:13,447 - INFO - joeynmt.training - Example #4
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:41:13,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 01:41:13,448 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:41:13,448 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:41:13,448 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 01:41:36,687 - INFO - joeynmt.training - Epoch   3: total training loss 13836.57
2025-05-19 01:41:36,689 - INFO - joeynmt.training - EPOCH 4
2025-05-19 01:41:56,788 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     4.252906, Batch Acc: 0.106179, Tokens per Sec:     1486, Lr: 0.000300
2025-05-19 01:42:38,511 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     4.328102, Batch Acc: 0.110163, Tokens per Sec:     1545, Lr: 0.000300
2025-05-19 01:43:20,539 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     4.236679, Batch Acc: 0.104958, Tokens per Sec:     1530, Lr: 0.000300
2025-05-19 01:44:02,008 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     4.374724, Batch Acc: 0.107541, Tokens per Sec:     1554, Lr: 0.000300
2025-05-19 01:44:44,382 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     4.462141, Batch Acc: 0.102573, Tokens per Sec:     1574, Lr: 0.000300
2025-05-19 01:44:44,383 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:44:44,383 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:47:25,836 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.40, ppl:  81.84, acc:   0.10, generation: 161.4409[sec], evaluation: 0.0000[sec]
2025-05-19 01:47:25,839 - INFO - joeynmt.training - Example #0
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Hypothesis: E non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 01:47:25,839 - INFO - joeynmt.training - Example #1
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:47:25,839 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 01:47:25,839 - INFO - joeynmt.training - Example #2
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:47:25,839 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Hypothesis: E non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 01:47:25,840 - INFO - joeynmt.training - Example #3
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'il', 'nostro', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'modo', 'di', 'un', 'parte']
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Hypothesis: E il nostro parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un modo di un parte
2025-05-19 01:47:25,840 - INFO - joeynmt.training - Example #4
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:47:25,840 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non']
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:47:25,840 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non è che non è che non è che non è che è che non è che non è che non è che non è che non è che non è che non è che è che è che è che non è che non è che non è che è che è che non è che è che non
2025-05-19 01:48:07,658 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     4.380311, Batch Acc: 0.108227, Tokens per Sec:     1524, Lr: 0.000300
2025-05-19 01:48:50,241 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     4.275103, Batch Acc: 0.105182, Tokens per Sec:     1533, Lr: 0.000300
2025-05-19 01:49:31,891 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     4.516412, Batch Acc: 0.099227, Tokens per Sec:     1554, Lr: 0.000300
2025-05-19 01:50:12,863 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     4.438118, Batch Acc: 0.101529, Tokens per Sec:     1582, Lr: 0.000300
2025-05-19 01:50:54,897 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     4.228885, Batch Acc: 0.104075, Tokens per Sec:     1564, Lr: 0.000300
2025-05-19 01:50:54,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:50:54,898 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:53:36,001 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.39, ppl:  80.44, acc:   0.10, generation: 161.0902[sec], evaluation: 0.0000[sec]
2025-05-19 01:53:36,003 - INFO - joeynmt.training - Example #0
2025-05-19 01:53:36,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'di', 'un', 'cosa', 'che', 'è', 'di', 'un', 'cosa', 'che', 'è', 'di', 'un', 'mio', 'cosa', 'che', 'è', 'di', 'un', 'cosa', 'che', 'è', 'di', 'un', 'cosa', 'la', 'mio', 'cosa', 'la', 'mio', 'cosa', 'la', 'mio', 'cosa', 'che', 'è', 'di', 'un', 'modo', 'che', 'è', 'di', 'un', 'mio', 'cosa', 'la', 'mio', 'cosa', 'non', 'è', 'di', 'un', 'mio', 'cosa', 'la', 'mio', 'cosa', 'la', 'mio', 'cosa', 'la', 'mio', 'cosa', 'la', 'mio']
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Hypothesis: E non è di un cosa che è di un cosa che è di un mio cosa che è di un cosa che è di un cosa la mio cosa la mio cosa la mio cosa che è di un modo che è di un mio cosa la mio cosa non è di un mio cosa la mio cosa la mio cosa la mio cosa la mio
2025-05-19 01:53:36,004 - INFO - joeynmt.training - Example #1
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Hypothesis: Ma non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 01:53:36,004 - INFO - joeynmt.training - Example #2
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'nostra']
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:53:36,004 - INFO - joeynmt.training - 	Hypothesis: In un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra parte di un nostra
2025-05-19 01:53:36,004 - INFO - joeynmt.training - Example #3
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:53:36,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Questo', 'è', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'mia', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'nostra', 'parte', 'di', 'un', 'mia', 'parte', 'di', 'un', 'parte', 'di', 'un', 'mia', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'mia', 'parte', 'di', 'un', 'parte', 'di', 'un', 'mia', 'parte', 'di', 'un']
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Hypothesis: Questo è di un parte di un parte di un parte di un parte di un mia parte di un parte di un parte di un parte di un parte di un parte di un nostra parte di un mia parte di un parte di un mia parte di un parte di un parte di un mia parte di un parte di un mia parte di un
2025-05-19 01:53:36,005 - INFO - joeynmt.training - Example #4
2025-05-19 01:53:36,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:53:36,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:53:36,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mia', "po'", 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:53:36,005 - INFO - joeynmt.training - 	Hypothesis: Il mia po' che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 01:54:18,907 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     4.293567, Batch Acc: 0.106571, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 01:55:01,730 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     4.446459, Batch Acc: 0.107654, Tokens per Sec:     1515, Lr: 0.000300
2025-05-19 01:55:43,915 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     4.301002, Batch Acc: 0.104621, Tokens per Sec:     1520, Lr: 0.000300
2025-05-19 01:56:27,902 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     4.168983, Batch Acc: 0.110160, Tokens per Sec:     1503, Lr: 0.000300
2025-05-19 01:57:10,757 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     4.304166, Batch Acc: 0.106431, Tokens per Sec:     1520, Lr: 0.000300
2025-05-19 01:57:10,757 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 01:57:10,757 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 01:59:53,761 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.52, acc:   0.10, generation: 162.9929[sec], evaluation: 0.0000[sec]
2025-05-19 01:59:53,968 - INFO - joeynmt.helpers - delete models_bpelvl/7000.ckpt
2025-05-19 01:59:53,970 - INFO - joeynmt.training - Example #0
2025-05-19 01:59:53,970 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 01:59:53,970 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 01:59:53,970 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 01:59:53,971 - INFO - joeynmt.training - Example #1
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 01:59:53,971 - INFO - joeynmt.training - Example #2
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mondo', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che', 'si', 'è', 'che']
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Hypothesis: E la mondo che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che si è che
2025-05-19 01:59:53,971 - INFO - joeynmt.training - Example #3
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 01:59:53,971 - INFO - joeynmt.training - 	Hypothesis: E la nostro parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 01:59:53,971 - INFO - joeynmt.training - Example #4
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 01:59:53,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è']
2025-05-19 01:59:53,972 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 01:59:53,972 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 01:59:53,972 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è
2025-05-19 02:00:37,672 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     4.312573, Batch Acc: 0.104549, Tokens per Sec:     1532, Lr: 0.000300
2025-05-19 02:01:21,949 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     4.200456, Batch Acc: 0.105990, Tokens per Sec:     1449, Lr: 0.000300
2025-05-19 02:02:04,743 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     4.255720, Batch Acc: 0.105462, Tokens per Sec:     1500, Lr: 0.000300
2025-05-19 02:02:47,268 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     4.310414, Batch Acc: 0.106822, Tokens per Sec:     1507, Lr: 0.000300
2025-05-19 02:03:29,828 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     4.270550, Batch Acc: 0.107821, Tokens per Sec:     1555, Lr: 0.000300
2025-05-19 02:03:29,829 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:03:29,829 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:06:10,363 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.33, ppl:  76.06, acc:   0.11, generation: 160.5224[sec], evaluation: 0.0000[sec]
2025-05-19 02:06:10,366 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 02:06:10,571 - INFO - joeynmt.helpers - delete models_bpelvl/6500.ckpt
2025-05-19 02:06:10,573 - INFO - joeynmt.training - Example #0
2025-05-19 02:06:10,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:06:10,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:06:10,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 02:06:10,573 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:06:10,573 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non è che non non non non non non non non non non non non non non non non non non non non non è che non non non non non non non non non non è che non non non non è che non non non non non non non non non non non non non non non non non
2025-05-19 02:06:10,574 - INFO - joeynmt.training - Example #1
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è']
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Hypothesis: Ma è che non è che non è che non è che è che è che è che non è che non è che non è che non è che non è che non è che non è che non è che è che non è che non è che non è che non è che non è che non è che non è che non è
2025-05-19 02:06:10,574 - INFO - joeynmt.training - Example #2
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'fatto', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Hypothesis: Abbiamo fatto che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 02:06:10,574 - INFO - joeynmt.training - Example #3
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è', 'il', 'nostro', "po'", 'che', 'è']
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Hypothesis: E è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è il nostro po' che è
2025-05-19 02:06:10,574 - INFO - joeynmt.training - Example #4
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:06:10,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:06:10,574 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:06:10,575 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:06:10,575 - INFO - joeynmt.training - 	Hypothesis: E non è che è un po' che è un po' che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:06:52,575 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     4.195373, Batch Acc: 0.107202, Tokens per Sec:     1491, Lr: 0.000300
2025-05-19 02:07:35,268 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     4.276713, Batch Acc: 0.106364, Tokens per Sec:     1505, Lr: 0.000300
2025-05-19 02:08:18,061 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     4.381406, Batch Acc: 0.104668, Tokens per Sec:     1526, Lr: 0.000300
2025-05-19 02:09:00,839 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     4.325833, Batch Acc: 0.109153, Tokens per Sec:     1550, Lr: 0.000300
2025-05-19 02:09:43,327 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     4.310406, Batch Acc: 0.104729, Tokens per Sec:     1542, Lr: 0.000300
2025-05-19 02:09:43,327 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:09:43,327 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:12:24,760 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.77, acc:   0.10, generation: 161.4212[sec], evaluation: 0.0000[sec]
2025-05-19 02:12:24,763 - INFO - joeynmt.training - Example #0
2025-05-19 02:12:24,763 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:12:24,763 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:12:24,763 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è', 'non', 'è']
2025-05-19 02:12:24,763 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:12:24,763 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:12:24,763 - INFO - joeynmt.training - 	Hypothesis: E non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è non è
2025-05-19 02:12:24,763 - INFO - joeynmt.training - Example #1
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Hypothesis: Ma che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:12:24,764 - INFO - joeynmt.training - Example #2
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:12:24,764 - INFO - joeynmt.training - 	Hypothesis: E è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 02:12:24,764 - INFO - joeynmt.training - Example #3
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:12:24,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Hypothesis: E è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 02:12:24,765 - INFO - joeynmt.training - Example #4
2025-05-19 02:12:24,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:12:24,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:12:24,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un']
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:12:24,765 - INFO - joeynmt.training - 	Hypothesis: E è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un
2025-05-19 02:13:07,003 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     4.467211, Batch Acc: 0.098145, Tokens per Sec:     1494, Lr: 0.000300
2025-05-19 02:13:50,296 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     4.410471, Batch Acc: 0.098910, Tokens per Sec:     1511, Lr: 0.000300
2025-05-19 02:14:32,280 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     4.415154, Batch Acc: 0.093861, Tokens per Sec:     1533, Lr: 0.000300
2025-05-19 02:15:14,032 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     4.498055, Batch Acc: 0.098813, Tokens per Sec:     1546, Lr: 0.000300
2025-05-19 02:15:57,023 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     4.423555, Batch Acc: 0.096771, Tokens per Sec:     1557, Lr: 0.000300
2025-05-19 02:15:57,024 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:15:57,024 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:18:40,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.54, ppl:  93.28, acc:   0.09, generation: 163.3012[sec], evaluation: 0.0000[sec]
2025-05-19 02:18:40,339 - INFO - joeynmt.training - Example #0
2025-05-19 02:18:40,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:18:40,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:18:40,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Hypothesis: E che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:18:40,340 - INFO - joeynmt.training - Example #1
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo']
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:18:40,340 - INFO - joeynmt.training - 	Hypothesis: E la mio modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo
2025-05-19 02:18:40,340 - INFO - joeynmt.training - Example #2
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:18:40,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo']
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Hypothesis: E che è che è un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo
2025-05-19 02:18:40,341 - INFO - joeynmt.training - Example #3
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo']
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Hypothesis: E che è che è un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo
2025-05-19 02:18:40,341 - INFO - joeynmt.training - Example #4
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:18:40,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:18:40,341 - INFO - joeynmt.training - 	Hypothesis: E che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:19:23,995 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     4.556853, Batch Acc: 0.094325, Tokens per Sec:     1491, Lr: 0.000300
2025-05-19 02:20:05,269 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     4.460587, Batch Acc: 0.097890, Tokens per Sec:     1572, Lr: 0.000300
2025-05-19 02:20:19,395 - INFO - joeynmt.training - Epoch   4: total training loss 13883.85
2025-05-19 02:20:19,395 - INFO - joeynmt.training - EPOCH 5
2025-05-19 02:20:46,312 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:     4.387887, Batch Acc: 0.099490, Tokens per Sec:     1522, Lr: 0.000300
2025-05-19 02:21:29,769 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:     4.373543, Batch Acc: 0.097830, Tokens per Sec:     1488, Lr: 0.000300
2025-05-19 02:22:12,079 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:     4.546641, Batch Acc: 0.096091, Tokens per Sec:     1564, Lr: 0.000300
2025-05-19 02:22:12,080 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:22:12,080 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:24:53,410 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.52, ppl:  91.86, acc:   0.09, generation: 161.3189[sec], evaluation: 0.0000[sec]
2025-05-19 02:24:53,413 - INFO - joeynmt.training - Example #0
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', "po'", 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra', 'E', 'che', 'la', 'nostra']
2025-05-19 02:24:53,413 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:24:53,413 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:24:53,413 - INFO - joeynmt.training - 	Hypothesis: E che la nostra E che la nostra E che la po' che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra E che la nostra
2025-05-19 02:24:53,413 - INFO - joeynmt.training - Example #1
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:24:53,413 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', "po'", 'che', 'la', 'mio', 'che', 'la', "po'", 'che', 'la', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', "po'", 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', 'mio', 'che', 'la', "po'", 'che', 'la', 'mio', 'che', 'la', "po'", 'che', 'la', 'mio', 'che', 'la', 'mio']
2025-05-19 02:24:53,413 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:24:53,413 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Hypothesis: E non è che la mio che la mio che la po' che la mio che la po' che la po' che la mio po' che la mio che la mio che la mio che la mio che la po' che la mio che la mio che la mio che la mio che la po' che la mio che la po' che la mio che la mio
2025-05-19 02:24:53,414 - INFO - joeynmt.training - Example #2
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa', 'un', 'cosa']
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Hypothesis: E non è un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa un cosa
2025-05-19 02:24:53,414 - INFO - joeynmt.training - Example #3
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'cosa', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:24:53,414 - INFO - joeynmt.training - 	Hypothesis: E la nostra cosa un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 02:24:53,414 - INFO - joeynmt.training - Example #4
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:24:53,414 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', "po'", 'che', 'la', 'nostra', 'E', 'la', 'nostro', "po'", 'che', 'la', 'nostro', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostro', 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostra', "po'", 'che', 'la', 'nostro', "po'", 'che', 'la', 'nostra', "po'", 'che']
2025-05-19 02:24:53,415 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:24:53,415 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:24:53,415 - INFO - joeynmt.training - 	Hypothesis: E la nostro po' che la nostra E la nostro po' che la nostro po' che la nostra po' che la nostra po' che la nostra po' che la nostra po' che la nostra po' che la nostro che la nostra po' che la nostra po' che la nostra po' che la nostra po' che la nostra po' che la nostro po' che la nostra po' che
2025-05-19 02:25:36,068 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:     4.491904, Batch Acc: 0.095550, Tokens per Sec:     1469, Lr: 0.000300
2025-05-19 02:26:18,561 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:     4.344420, Batch Acc: 0.098661, Tokens per Sec:     1513, Lr: 0.000300
2025-05-19 02:27:01,550 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:     4.246141, Batch Acc: 0.098676, Tokens per Sec:     1526, Lr: 0.000300
2025-05-19 02:27:43,667 - INFO - joeynmt.training - Epoch   5, Step:    13400, Batch Loss:     4.270203, Batch Acc: 0.101104, Tokens per Sec:     1510, Lr: 0.000300
2025-05-19 02:28:27,223 - INFO - joeynmt.training - Epoch   5, Step:    13500, Batch Loss:     4.327030, Batch Acc: 0.100491, Tokens per Sec:     1491, Lr: 0.000300
2025-05-19 02:28:27,224 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:28:27,224 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:31:08,131 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.41, ppl:  82.43, acc:   0.10, generation: 160.8953[sec], evaluation: 0.0000[sec]
2025-05-19 02:31:08,134 - INFO - joeynmt.training - Example #0
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', "po'", 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', "po'", 'di', 'un', 'mondo', 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo']
2025-05-19 02:31:08,134 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:31:08,134 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:31:08,134 - INFO - joeynmt.training - 	Hypothesis: E è un mondo di un mondo di un mondo di un po' di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un po' di un mondo di un po' di un po' di un mondo di un mondo di un mondo di un mondo di un mondo
2025-05-19 02:31:08,134 - INFO - joeynmt.training - Example #1
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:31:08,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'un', "po'", 'e', 'la', 'mio', "po'", 'di', 'un', "po'", 'che', 'non', 'non', 'non', 'non', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un']
2025-05-19 02:31:08,134 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:31:08,134 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' che non non non non non non è un po' e la mio po' di un po' che non non non non non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un
2025-05-19 02:31:08,135 - INFO - joeynmt.training - Example #2
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un']
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Hypothesis: E la nostro di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un
2025-05-19 02:31:08,135 - INFO - joeynmt.training - Example #3
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Hypothesis: E è un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 02:31:08,135 - INFO - joeynmt.training - Example #4
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:31:08,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un']
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:31:08,135 - INFO - joeynmt.training - 	Hypothesis: E la nostro po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che è un
2025-05-19 02:31:51,117 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     4.532908, Batch Acc: 0.100651, Tokens per Sec:     1518, Lr: 0.000300
2025-05-19 02:32:33,403 - INFO - joeynmt.training - Epoch   5, Step:    13700, Batch Loss:     4.318073, Batch Acc: 0.099685, Tokens per Sec:     1504, Lr: 0.000300
2025-05-19 02:33:15,209 - INFO - joeynmt.training - Epoch   5, Step:    13800, Batch Loss:     4.243414, Batch Acc: 0.099370, Tokens per Sec:     1531, Lr: 0.000300
2025-05-19 02:33:57,794 - INFO - joeynmt.training - Epoch   5, Step:    13900, Batch Loss:     4.524028, Batch Acc: 0.097863, Tokens per Sec:     1520, Lr: 0.000300
2025-05-19 02:34:40,507 - INFO - joeynmt.training - Epoch   5, Step:    14000, Batch Loss:     4.436104, Batch Acc: 0.100794, Tokens per Sec:     1537, Lr: 0.000300
2025-05-19 02:34:40,508 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:34:40,508 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:37:22,872 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.43, ppl:  84.18, acc:   0.10, generation: 162.3530[sec], evaluation: 0.0000[sec]
2025-05-19 02:37:22,874 - INFO - joeynmt.training - Example #0
2025-05-19 02:37:22,874 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:37:22,874 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo', 'la', 'mondo']
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Hypothesis: In un po' la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo la mondo
2025-05-19 02:37:22,875 - INFO - joeynmt.training - Example #1
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Hypothesis: Ma è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 02:37:22,875 - INFO - joeynmt.training - Example #2
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:37:22,875 - INFO - joeynmt.training - 	Hypothesis: E non è un mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 02:37:22,875 - INFO - joeynmt.training - Example #3
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:37:22,875 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:37:22,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostra', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di']
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Hypothesis: La nostra parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di
2025-05-19 02:37:22,876 - INFO - joeynmt.training - Example #4
2025-05-19 02:37:22,876 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:37:22,876 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:37:22,876 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'mio', 'mio', "po'", 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:37:22,876 - INFO - joeynmt.training - 	Hypothesis: E la mio mio po' che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:38:05,123 - INFO - joeynmt.training - Epoch   5, Step:    14100, Batch Loss:     4.290778, Batch Acc: 0.100459, Tokens per Sec:     1551, Lr: 0.000300
2025-05-19 02:38:47,161 - INFO - joeynmt.training - Epoch   5, Step:    14200, Batch Loss:     4.614380, Batch Acc: 0.094765, Tokens per Sec:     1503, Lr: 0.000300
2025-05-19 02:39:29,829 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     4.511004, Batch Acc: 0.101461, Tokens per Sec:     1474, Lr: 0.000300
2025-05-19 02:40:11,587 - INFO - joeynmt.training - Epoch   5, Step:    14400, Batch Loss:     4.399525, Batch Acc: 0.103570, Tokens per Sec:     1555, Lr: 0.000300
2025-05-19 02:40:54,538 - INFO - joeynmt.training - Epoch   5, Step:    14500, Batch Loss:     4.318388, Batch Acc: 0.104487, Tokens per Sec:     1562, Lr: 0.000300
2025-05-19 02:40:54,539 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:40:54,539 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:43:36,522 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.40, ppl:  81.59, acc:   0.10, generation: 161.9715[sec], evaluation: 0.0000[sec]
2025-05-19 02:43:36,526 - INFO - joeynmt.training - Example #0
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'mondo', 'che', 'non', 'è', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Hypothesis: E non è un mondo che non è un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 02:43:36,526 - INFO - joeynmt.training - Example #1
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:43:36,526 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:43:36,526 - INFO - joeynmt.training - 	Hypothesis: Ma non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 02:43:36,526 - INFO - joeynmt.training - Example #2
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'E', 'la', 'nostro', 'mondo', 'che', 'la', 'nostro', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un']
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Hypothesis: E la nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro E la nostro mondo che la nostro mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un
2025-05-19 02:43:36,527 - INFO - joeynmt.training - Example #3
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'un', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'E', '</s>']
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Hypothesis: E un nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro E
2025-05-19 02:43:36,527 - INFO - joeynmt.training - Example #4
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:43:36,527 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'modo', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:43:36,527 - INFO - joeynmt.training - 	Hypothesis: E non è un modo che è che non è che non è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che non è che è che è che è che è che è che è che
2025-05-19 02:44:19,835 - INFO - joeynmt.training - Epoch   5, Step:    14600, Batch Loss:     4.341390, Batch Acc: 0.103288, Tokens per Sec:     1512, Lr: 0.000300
2025-05-19 02:45:02,864 - INFO - joeynmt.training - Epoch   5, Step:    14700, Batch Loss:     4.404140, Batch Acc: 0.101819, Tokens per Sec:     1538, Lr: 0.000300
2025-05-19 02:45:44,540 - INFO - joeynmt.training - Epoch   5, Step:    14800, Batch Loss:     4.389092, Batch Acc: 0.106870, Tokens per Sec:     1582, Lr: 0.000300
2025-05-19 02:46:27,735 - INFO - joeynmt.training - Epoch   5, Step:    14900, Batch Loss:     4.384059, Batch Acc: 0.103401, Tokens per Sec:     1485, Lr: 0.000300
2025-05-19 02:47:12,207 - INFO - joeynmt.training - Epoch   5, Step:    15000, Batch Loss:     4.426567, Batch Acc: 0.102187, Tokens per Sec:     1484, Lr: 0.000300
2025-05-19 02:47:12,209 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:47:12,209 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:49:54,736 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.42, ppl:  82.93, acc:   0.10, generation: 162.5155[sec], evaluation: 0.0000[sec]
2025-05-19 02:49:54,740 - INFO - joeynmt.training - Example #0
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un']
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Hypothesis: In un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un
2025-05-19 02:49:54,741 - INFO - joeynmt.training - Example #1
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non']
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non
2025-05-19 02:49:54,741 - INFO - joeynmt.training - Example #2
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:49:54,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ato', 'il', 'mondo', 'di', 'un', "po'", 'che', 'la', 'mondo', 'di', 'un', "po'", 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo']
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:49:54,741 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Hypothesis: E ato il mondo di un po' che la mondo di un po' che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo
2025-05-19 02:49:54,742 - INFO - joeynmt.training - Example #3
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'ato', 'e', 'la', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Hypothesis: E ato e la nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 02:49:54,742 - INFO - joeynmt.training - Example #4
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:49:54,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Questo', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un']
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:49:54,742 - INFO - joeynmt.training - 	Hypothesis: Questo è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un
2025-05-19 02:50:37,790 - INFO - joeynmt.training - Epoch   5, Step:    15100, Batch Loss:     4.308669, Batch Acc: 0.103211, Tokens per Sec:     1480, Lr: 0.000300
2025-05-19 02:51:20,941 - INFO - joeynmt.training - Epoch   5, Step:    15200, Batch Loss:     4.323400, Batch Acc: 0.104886, Tokens per Sec:     1458, Lr: 0.000300
2025-05-19 02:52:03,979 - INFO - joeynmt.training - Epoch   5, Step:    15300, Batch Loss:     4.348154, Batch Acc: 0.102811, Tokens per Sec:     1475, Lr: 0.000300
2025-05-19 02:52:46,399 - INFO - joeynmt.training - Epoch   5, Step:    15400, Batch Loss:     4.365419, Batch Acc: 0.102803, Tokens per Sec:     1539, Lr: 0.000300
2025-05-19 02:53:28,857 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     4.356395, Batch Acc: 0.107195, Tokens per Sec:     1510, Lr: 0.000300
2025-05-19 02:53:28,858 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:53:28,858 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 02:56:11,183 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.37, ppl:  79.27, acc:   0.10, generation: 162.3129[sec], evaluation: 0.0000[sec]
2025-05-19 02:56:11,393 - INFO - joeynmt.helpers - delete models_bpelvl/11000.ckpt
2025-05-19 02:56:11,396 - INFO - joeynmt.training - Example #0
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Hypothesis: In un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di
2025-05-19 02:56:11,397 - INFO - joeynmt.training - Example #1
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui', 'è', 'un', 'modo', 'di', 'cui']
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Hypothesis: Ma non è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui è un modo di cui
2025-05-19 02:56:11,397 - INFO - joeynmt.training - Example #2
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un']
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Hypothesis: E non è un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un
2025-05-19 02:56:11,397 - INFO - joeynmt.training - Example #3
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 02:56:11,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 02:56:11,397 - INFO - joeynmt.training - 	Hypothesis: La nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 02:56:11,398 - INFO - joeynmt.training - Example #4
2025-05-19 02:56:11,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 02:56:11,398 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 02:56:11,398 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 02:56:11,398 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 02:56:11,398 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 02:56:11,398 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 02:56:53,813 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     4.354977, Batch Acc: 0.105349, Tokens per Sec:     1523, Lr: 0.000300
2025-05-19 02:57:36,379 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     4.269418, Batch Acc: 0.106553, Tokens per Sec:     1566, Lr: 0.000300
2025-05-19 02:58:18,527 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     4.245596, Batch Acc: 0.103180, Tokens per Sec:     1520, Lr: 0.000300
2025-05-19 02:59:03,791 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     4.406028, Batch Acc: 0.104743, Tokens per Sec:     1487, Lr: 0.000300
2025-05-19 02:59:14,119 - INFO - joeynmt.training - Epoch   5: total training loss 14030.73
2025-05-19 02:59:14,121 - INFO - joeynmt.training - EPOCH 6
2025-05-19 02:59:45,260 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:     4.356292, Batch Acc: 0.106329, Tokens per Sec:     1543, Lr: 0.000300
2025-05-19 02:59:45,261 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 02:59:45,261 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:02:25,728 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.36, ppl:  78.45, acc:   0.10, generation: 160.4606[sec], evaluation: 0.0000[sec]
2025-05-19 03:02:25,930 - INFO - joeynmt.helpers - delete models_bpelvl/15500.ckpt
2025-05-19 03:02:25,932 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/15500.ckpt
2025-05-19 03:02:25,932 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/15500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/15500.ckpt')
2025-05-19 03:02:25,933 - INFO - joeynmt.training - Example #0
2025-05-19 03:02:25,933 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:02:25,933 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:02:25,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che']
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Hypothesis: La mio modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che è un modo che si è un modo che si è un modo che è un modo che si è un modo che
2025-05-19 03:02:25,934 - INFO - joeynmt.training - Example #1
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'"]
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che è un po' che non è un po' che non è un po' che non è un po' che non è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che non è un po' che non è un po' che è un po' che è un po'
2025-05-19 03:02:25,934 - INFO - joeynmt.training - Example #2
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '</s>']
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Hypothesis: E
2025-05-19 03:02:25,934 - INFO - joeynmt.training - Example #3
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di']
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:02:25,934 - INFO - joeynmt.training - 	Hypothesis: La nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di
2025-05-19 03:02:25,934 - INFO - joeynmt.training - Example #4
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:02:25,934 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '</s>']
2025-05-19 03:02:25,935 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:02:25,935 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:02:25,935 - INFO - joeynmt.training - 	Hypothesis: E
2025-05-19 03:03:08,717 - INFO - joeynmt.training - Epoch   6, Step:    16100, Batch Loss:     4.265932, Batch Acc: 0.107019, Tokens per Sec:     1553, Lr: 0.000210
2025-05-19 03:03:51,982 - INFO - joeynmt.training - Epoch   6, Step:    16200, Batch Loss:     4.438708, Batch Acc: 0.101638, Tokens per Sec:     1495, Lr: 0.000210
2025-05-19 03:04:34,954 - INFO - joeynmt.training - Epoch   6, Step:    16300, Batch Loss:     4.289211, Batch Acc: 0.108809, Tokens per Sec:     1525, Lr: 0.000210
2025-05-19 03:05:17,715 - INFO - joeynmt.training - Epoch   6, Step:    16400, Batch Loss:     4.388418, Batch Acc: 0.107287, Tokens per Sec:     1472, Lr: 0.000210
2025-05-19 03:06:01,275 - INFO - joeynmt.training - Epoch   6, Step:    16500, Batch Loss:     4.321300, Batch Acc: 0.106130, Tokens per Sec:     1417, Lr: 0.000210
2025-05-19 03:06:01,276 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:06:01,276 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:08:42,598 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.36, ppl:  78.16, acc:   0.10, generation: 161.3097[sec], evaluation: 0.0000[sec]
2025-05-19 03:08:42,808 - INFO - joeynmt.helpers - delete models_bpelvl/16000.ckpt
2025-05-19 03:08:42,810 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16000.ckpt
2025-05-19 03:08:42,810 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16000.ckpt')
2025-05-19 03:08:42,811 - INFO - joeynmt.training - Example #0
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mondo', 'che', 'è', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 03:08:42,811 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:08:42,811 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:08:42,811 - INFO - joeynmt.training - 	Hypothesis: Il mondo che è un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 03:08:42,811 - INFO - joeynmt.training - Example #1
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:08:42,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 03:08:42,812 - INFO - joeynmt.training - Example #2
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostra', 'delle', 'persone', 'che', 'la', 'nostra', 'delle', 'persone', 'che', 'la', 'nostra', 'delle', 'di', 'nostra', 'delle', 'persone', 'che', 'la', 'nostra', 'delle', 'persone', 'che', 'la', 'nostra', 'delle', 'di', 'nostra', 'delle', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'delle', 'di', 'nostra', 'delle', 'di', 'nostra', 'parte', 'di', 'nostra', 'delle', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra']
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Hypothesis: La nostra delle persone che la nostra delle persone che la nostra delle di nostra delle persone che la nostra delle persone che la nostra delle di nostra delle di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra delle di nostra delle di nostra parte di nostra delle di nostra parte di nostra parte di nostra
2025-05-19 03:08:42,812 - INFO - joeynmt.training - Example #3
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il', 'nostra', 'di', 'un', "po'", 'che', 'il']
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Hypothesis: Il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il nostra di un po' che il
2025-05-19 03:08:42,812 - INFO - joeynmt.training - Example #4
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:08:42,812 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '</s>']
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:08:42,812 - INFO - joeynmt.training - 	Hypothesis: E
2025-05-19 03:09:25,179 - INFO - joeynmt.training - Epoch   6, Step:    16600, Batch Loss:     4.237683, Batch Acc: 0.107089, Tokens per Sec:     1514, Lr: 0.000210
2025-05-19 03:10:07,427 - INFO - joeynmt.training - Epoch   6, Step:    16700, Batch Loss:     4.261680, Batch Acc: 0.106387, Tokens per Sec:     1508, Lr: 0.000210
2025-05-19 03:10:48,705 - INFO - joeynmt.training - Epoch   6, Step:    16800, Batch Loss:     4.271928, Batch Acc: 0.107447, Tokens per Sec:     1608, Lr: 0.000210
2025-05-19 03:11:31,535 - INFO - joeynmt.training - Epoch   6, Step:    16900, Batch Loss:     4.529484, Batch Acc: 0.103175, Tokens per Sec:     1522, Lr: 0.000210
2025-05-19 03:12:14,982 - INFO - joeynmt.training - Epoch   6, Step:    17000, Batch Loss:     4.351947, Batch Acc: 0.104896, Tokens per Sec:     1493, Lr: 0.000210
2025-05-19 03:12:14,984 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:12:14,984 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:14:57,186 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.87, acc:   0.10, generation: 162.1911[sec], evaluation: 0.0000[sec]
2025-05-19 03:14:57,191 - INFO - joeynmt.training - Example #0
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che']
2025-05-19 03:14:57,191 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:14:57,191 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:14:57,191 - INFO - joeynmt.training - 	Hypothesis: La mondo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che
2025-05-19 03:14:57,191 - INFO - joeynmt.training - Example #1
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:14:57,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'la', 'mondo', 'che', 'non', 'è', 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Hypothesis: Ma la mondo che non è che non è un po' che non è un po' che non è un po' di un po' di un po' che non è un po' di un po' di un po' che non è un po' di un po' di un po' che non è un po' che non è un po' di un po' di un po' di un
2025-05-19 03:14:57,192 - INFO - joeynmt.training - Example #2
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'che', 'la', 'loro', 'delle', 'persone', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo']
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Hypothesis: La mondo che la loro delle persone di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo
2025-05-19 03:14:57,192 - INFO - joeynmt.training - Example #3
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Hypothesis: La nostro sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 03:14:57,192 - INFO - joeynmt.training - Example #4
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:14:57,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che']
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:14:57,192 - INFO - joeynmt.training - 	Hypothesis: La mondo che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che
2025-05-19 03:15:39,919 - INFO - joeynmt.training - Epoch   6, Step:    17100, Batch Loss:     4.282486, Batch Acc: 0.104471, Tokens per Sec:     1494, Lr: 0.000210
2025-05-19 03:16:23,622 - INFO - joeynmt.training - Epoch   6, Step:    17200, Batch Loss:     4.334316, Batch Acc: 0.105513, Tokens per Sec:     1496, Lr: 0.000210
2025-05-19 03:17:04,438 - INFO - joeynmt.training - Epoch   6, Step:    17300, Batch Loss:     4.306960, Batch Acc: 0.107987, Tokens per Sec:     1649, Lr: 0.000210
2025-05-19 03:17:45,391 - INFO - joeynmt.training - Epoch   6, Step:    17400, Batch Loss:     4.302631, Batch Acc: 0.108447, Tokens per Sec:     1593, Lr: 0.000210
2025-05-19 03:18:29,166 - INFO - joeynmt.training - Epoch   6, Step:    17500, Batch Loss:     4.434618, Batch Acc: 0.106866, Tokens per Sec:     1510, Lr: 0.000210
2025-05-19 03:18:29,167 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:18:29,167 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:21:12,732 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.38, ppl:  79.60, acc:   0.10, generation: 163.5528[sec], evaluation: 0.0000[sec]
2025-05-19 03:21:12,735 - INFO - joeynmt.training - Example #0
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'e', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un']
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Hypothesis: La mondo e la mondo e la mondo e la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un modo che la mondo di un
2025-05-19 03:21:12,735 - INFO - joeynmt.training - Example #1
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'mondo', 'di', 'un', 'modo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'un', 'modo', 'che', 'è', 'che', 'è', 'che', 'è', 'un', 'modo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che']
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Hypothesis: Ma la mia cosa la mia cosa la mia cosa non è che è che è che è che è che è che è mondo di un modo che è che è che è che è che è che è un modo che è che è che è un modo che è che è che è che è che è un modo che è un modo che
2025-05-19 03:21:12,735 - INFO - joeynmt.training - Example #2
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:21:12,735 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'che', 'la', 'mondo', 'di', 'un', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che']
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:21:12,735 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo che la mondo di un mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo che
2025-05-19 03:21:12,735 - INFO - joeynmt.training - Example #3
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Hypothesis: La nostro modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di
2025-05-19 03:21:12,736 - INFO - joeynmt.training - Example #4
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:21:12,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un']
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:21:12,736 - INFO - joeynmt.training - 	Hypothesis: La modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un
2025-05-19 03:21:55,111 - INFO - joeynmt.training - Epoch   6, Step:    17600, Batch Loss:     4.282258, Batch Acc: 0.101437, Tokens per Sec:     1529, Lr: 0.000210
2025-05-19 03:22:37,403 - INFO - joeynmt.training - Epoch   6, Step:    17700, Batch Loss:     4.232384, Batch Acc: 0.104844, Tokens per Sec:     1510, Lr: 0.000210
2025-05-19 03:23:20,011 - INFO - joeynmt.training - Epoch   6, Step:    17800, Batch Loss:     4.443672, Batch Acc: 0.107551, Tokens per Sec:     1511, Lr: 0.000210
2025-05-19 03:24:02,843 - INFO - joeynmt.training - Epoch   6, Step:    17900, Batch Loss:     4.430078, Batch Acc: 0.105389, Tokens per Sec:     1569, Lr: 0.000210
2025-05-19 03:24:45,617 - INFO - joeynmt.training - Epoch   6, Step:    18000, Batch Loss:     4.291418, Batch Acc: 0.105411, Tokens per Sec:     1520, Lr: 0.000210
2025-05-19 03:24:45,617 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:24:45,617 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:27:28,695 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.41, ppl:  81.88, acc:   0.10, generation: 163.0660[sec], evaluation: 0.0000[sec]
2025-05-19 03:27:28,697 - INFO - joeynmt.training - Example #0
2025-05-19 03:27:28,697 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:27:28,697 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:27:28,697 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'di', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che']
2025-05-19 03:27:28,697 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:27:28,697 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:27:28,697 - INFO - joeynmt.training - 	Hypothesis: E la nostra di un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che
2025-05-19 03:27:28,698 - INFO - joeynmt.training - Example #1
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'ho', 'un', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia']
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Hypothesis: Ma non ho un cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia
2025-05-19 03:27:28,698 - INFO - joeynmt.training - Example #2
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'di', 'un', "po'", '</s>']
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:27:28,698 - INFO - joeynmt.training - 	Hypothesis: E la nostra di un po'
2025-05-19 03:27:28,698 - INFO - joeynmt.training - Example #3
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:27:28,698 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra', 'delle', 'persone', 'di', 'un', "po'", 'che', 'la', 'nostra']
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Hypothesis: E la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra delle persone di un po' che la nostra
2025-05-19 03:27:28,699 - INFO - joeynmt.training - Example #4
2025-05-19 03:27:28,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:27:28,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:27:28,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostra', 'di', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'non', 'si', 'è', 'un', 'modo', 'che', 'non', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'non', 'si', 'è', 'un']
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:27:28,699 - INFO - joeynmt.training - 	Hypothesis: La nostra di un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che si è un modo che non si è un modo che non si è un modo che si è un modo che non si è un
2025-05-19 03:28:11,791 - INFO - joeynmt.training - Epoch   6, Step:    18100, Batch Loss:     4.491739, Batch Acc: 0.099348, Tokens per Sec:     1543, Lr: 0.000210
2025-05-19 03:28:54,852 - INFO - joeynmt.training - Epoch   6, Step:    18200, Batch Loss:     4.406371, Batch Acc: 0.106212, Tokens per Sec:     1501, Lr: 0.000210
2025-05-19 03:29:37,578 - INFO - joeynmt.training - Epoch   6, Step:    18300, Batch Loss:     4.331780, Batch Acc: 0.105450, Tokens per Sec:     1531, Lr: 0.000210
2025-05-19 03:30:19,936 - INFO - joeynmt.training - Epoch   6, Step:    18400, Batch Loss:     4.539145, Batch Acc: 0.105730, Tokens per Sec:     1495, Lr: 0.000210
2025-05-19 03:31:02,682 - INFO - joeynmt.training - Epoch   6, Step:    18500, Batch Loss:     4.266447, Batch Acc: 0.101454, Tokens per Sec:     1536, Lr: 0.000210
2025-05-19 03:31:02,682 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:31:02,682 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:33:44,914 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.36, ppl:  78.03, acc:   0.10, generation: 162.2200[sec], evaluation: 0.0000[sec]
2025-05-19 03:33:45,122 - INFO - joeynmt.helpers - delete models_bpelvl/16500.ckpt
2025-05-19 03:33:45,123 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16500.ckpt
2025-05-19 03:33:45,124 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/16500.ckpt')
2025-05-19 03:33:45,124 - INFO - joeynmt.training - Example #0
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più']
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Hypothesis: In più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più più
2025-05-19 03:33:45,124 - INFO - joeynmt.training - Example #1
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:33:45,124 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è', 'un', 'che', 'non', 'è']
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:33:45,124 - INFO - joeynmt.training - 	Hypothesis: Ma non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è un che non è
2025-05-19 03:33:45,124 - INFO - joeynmt.training - Example #2
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di']
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Hypothesis: In nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di
2025-05-19 03:33:45,125 - INFO - joeynmt.training - Example #3
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di']
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Hypothesis: La nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di
2025-05-19 03:33:45,125 - INFO - joeynmt.training - Example #4
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:33:45,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'loro', 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo']
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:33:45,125 - INFO - joeynmt.training - 	Hypothesis: La loro di un po' che non è un po' che non è un po' che non è un modo che non è che non è che non è che non è un modo che non è un modo che non è che non è un po' che non è un po' che non è un po' che non è un modo che non è un modo
2025-05-19 03:34:27,658 - INFO - joeynmt.training - Epoch   6, Step:    18600, Batch Loss:     4.245173, Batch Acc: 0.111565, Tokens per Sec:     1517, Lr: 0.000210
2025-05-19 03:35:09,479 - INFO - joeynmt.training - Epoch   6, Step:    18700, Batch Loss:     4.307469, Batch Acc: 0.107615, Tokens per Sec:     1531, Lr: 0.000210
2025-05-19 03:35:53,252 - INFO - joeynmt.training - Epoch   6, Step:    18800, Batch Loss:     4.250603, Batch Acc: 0.105696, Tokens per Sec:     1531, Lr: 0.000210
2025-05-19 03:36:36,063 - INFO - joeynmt.training - Epoch   6, Step:    18900, Batch Loss:     4.150453, Batch Acc: 0.110228, Tokens per Sec:     1501, Lr: 0.000210
2025-05-19 03:37:18,706 - INFO - joeynmt.training - Epoch   6, Step:    19000, Batch Loss:     4.328661, Batch Acc: 0.109211, Tokens per Sec:     1500, Lr: 0.000210
2025-05-19 03:37:18,706 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:37:18,707 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:40:03,520 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.35, ppl:  77.81, acc:   0.11, generation: 164.8014[sec], evaluation: 0.0000[sec]
2025-05-19 03:40:03,724 - INFO - joeynmt.helpers - delete models_bpelvl/18500.ckpt
2025-05-19 03:40:03,724 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/18500.ckpt
2025-05-19 03:40:03,724 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/18500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/18500.ckpt')
2025-05-19 03:40:03,725 - INFO - joeynmt.training - Example #0
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 03:40:03,725 - INFO - joeynmt.training - Example #1
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:40:03,725 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che è che è che è che è che è che è che è che è che è che non è che non è che non è che è che non è che non è che non
2025-05-19 03:40:03,725 - INFO - joeynmt.training - Example #2
2025-05-19 03:40:03,725 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Hypothesis: In un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 03:40:03,726 - INFO - joeynmt.training - Example #3
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo']
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Hypothesis: La suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo
2025-05-19 03:40:03,726 - INFO - joeynmt.training - Example #4
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:40:03,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:40:03,726 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 03:40:46,754 - INFO - joeynmt.training - Epoch   6, Step:    19100, Batch Loss:     4.453214, Batch Acc: 0.110261, Tokens per Sec:     1485, Lr: 0.000210
2025-05-19 03:40:49,825 - INFO - joeynmt.training - Epoch   6: total training loss 13744.47
2025-05-19 03:40:49,825 - INFO - joeynmt.training - EPOCH 7
2025-05-19 03:41:29,202 - INFO - joeynmt.training - Epoch   7, Step:    19200, Batch Loss:     4.229585, Batch Acc: 0.108650, Tokens per Sec:     1519, Lr: 0.000210
2025-05-19 03:42:11,799 - INFO - joeynmt.training - Epoch   7, Step:    19300, Batch Loss:     4.413107, Batch Acc: 0.110865, Tokens per Sec:     1517, Lr: 0.000210
2025-05-19 03:42:53,437 - INFO - joeynmt.training - Epoch   7, Step:    19400, Batch Loss:     4.274277, Batch Acc: 0.110264, Tokens per Sec:     1547, Lr: 0.000210
2025-05-19 03:43:35,344 - INFO - joeynmt.training - Epoch   7, Step:    19500, Batch Loss:     4.247589, Batch Acc: 0.113194, Tokens per Sec:     1542, Lr: 0.000210
2025-05-19 03:43:35,345 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:43:35,345 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:46:17,826 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.31, ppl:  74.62, acc:   0.11, generation: 162.4689[sec], evaluation: 0.0000[sec]
2025-05-19 03:46:17,828 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 03:46:18,033 - INFO - joeynmt.helpers - delete models_bpelvl/9500.ckpt
2025-05-19 03:46:18,035 - INFO - joeynmt.training - Example #0
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Se', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Hypothesis: Se non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 03:46:18,035 - INFO - joeynmt.training - Example #1
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:46:18,035 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 03:46:18,035 - INFO - joeynmt.training - Example #2
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:46:18,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'che', 'è', 'un', 'mondo', 'che', 'è', 'un', 'mondo', 'che', 'è', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è', 'di', 'un', 'mondo', 'che', 'è']
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Hypothesis: In un mondo che è un mondo che è un mondo che è un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è di un mondo che è
2025-05-19 03:46:18,036 - INFO - joeynmt.training - Example #3
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Hypothesis: La nostro sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 03:46:18,036 - INFO - joeynmt.training - Example #4
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:46:18,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che']
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:46:18,036 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che
2025-05-19 03:47:02,071 - INFO - joeynmt.training - Epoch   7, Step:    19600, Batch Loss:     4.363656, Batch Acc: 0.107671, Tokens per Sec:     1456, Lr: 0.000210
2025-05-19 03:47:45,118 - INFO - joeynmt.training - Epoch   7, Step:    19700, Batch Loss:     4.326323, Batch Acc: 0.110033, Tokens per Sec:     1525, Lr: 0.000210
2025-05-19 03:48:27,987 - INFO - joeynmt.training - Epoch   7, Step:    19800, Batch Loss:     4.246703, Batch Acc: 0.106917, Tokens per Sec:     1489, Lr: 0.000210
2025-05-19 03:49:10,106 - INFO - joeynmt.training - Epoch   7, Step:    19900, Batch Loss:     4.261443, Batch Acc: 0.110410, Tokens per Sec:     1497, Lr: 0.000210
2025-05-19 03:49:52,761 - INFO - joeynmt.training - Epoch   7, Step:    20000, Batch Loss:     4.279381, Batch Acc: 0.109969, Tokens per Sec:     1541, Lr: 0.000210
2025-05-19 03:49:52,762 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:49:52,762 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:52:35,221 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.32, ppl:  75.39, acc:   0.11, generation: 162.4468[sec], evaluation: 0.0000[sec]
2025-05-19 03:52:35,421 - INFO - joeynmt.helpers - delete models_bpelvl/19000.ckpt
2025-05-19 03:52:35,422 - INFO - joeynmt.training - Example #0
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non']
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Hypothesis: E non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non
2025-05-19 03:52:35,422 - INFO - joeynmt.training - Example #1
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:52:35,422 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non non non è che non è che non non è che non è che non non non è che non è che non è che non è che non è che non è che non è che non è che non non non non non è che non è che non è che non è che
2025-05-19 03:52:35,422 - INFO - joeynmt.training - Example #2
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:52:35,422 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'la', 'nostro', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Hypothesis: In la nostro po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 03:52:35,423 - INFO - joeynmt.training - Example #3
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Hypothesis: La nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 03:52:35,423 - INFO - joeynmt.training - Example #4
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:52:35,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:52:35,423 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 03:53:19,033 - INFO - joeynmt.training - Epoch   7, Step:    20100, Batch Loss:     4.355500, Batch Acc: 0.111374, Tokens per Sec:     1514, Lr: 0.000210
2025-05-19 03:54:02,149 - INFO - joeynmt.training - Epoch   7, Step:    20200, Batch Loss:     4.131076, Batch Acc: 0.109278, Tokens per Sec:     1521, Lr: 0.000210
2025-05-19 03:54:45,650 - INFO - joeynmt.training - Epoch   7, Step:    20300, Batch Loss:     4.312397, Batch Acc: 0.109025, Tokens per Sec:     1533, Lr: 0.000210
2025-05-19 03:55:28,052 - INFO - joeynmt.training - Epoch   7, Step:    20400, Batch Loss:     4.236091, Batch Acc: 0.108163, Tokens per Sec:     1477, Lr: 0.000210
2025-05-19 03:56:11,260 - INFO - joeynmt.training - Epoch   7, Step:    20500, Batch Loss:     4.152097, Batch Acc: 0.106994, Tokens per Sec:     1480, Lr: 0.000210
2025-05-19 03:56:11,261 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 03:56:11,261 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 03:58:53,459 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.37, ppl:  79.27, acc:   0.11, generation: 162.1866[sec], evaluation: 0.0000[sec]
2025-05-19 03:58:53,461 - INFO - joeynmt.training - Example #0
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non']
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Hypothesis: E non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non
2025-05-19 03:58:53,461 - INFO - joeynmt.training - Example #1
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'cose', 'di', 'cose', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'cose', 'che', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'cose', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un']
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Hypothesis: Ma non è un modo di un modo di cose di cose di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di cose che è un modo di un modo di un modo di un modo di cose di un modo di un modo di un modo di un modo di un
2025-05-19 03:58:53,461 - INFO - joeynmt.training - Example #2
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 03:58:53,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'sua', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', 'è', 'che', 'si', 'è', 'un', 'modo', 'che', 'si', '</s>']
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 03:58:53,461 - INFO - joeynmt.training - 	Hypothesis: E la sua un modo che si è un modo che si è un modo che si è un modo che si è che si è un modo che si
2025-05-19 03:58:53,461 - INFO - joeynmt.training - Example #3
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'di', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Hypothesis: E' di un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 03:58:53,462 - INFO - joeynmt.training - Example #4
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 03:58:53,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 03:58:53,462 - INFO - joeynmt.training - 	Hypothesis: E che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 03:59:36,566 - INFO - joeynmt.training - Epoch   7, Step:    20600, Batch Loss:     4.355387, Batch Acc: 0.108609, Tokens per Sec:     1534, Lr: 0.000210
2025-05-19 04:00:18,934 - INFO - joeynmt.training - Epoch   7, Step:    20700, Batch Loss:     4.235376, Batch Acc: 0.110575, Tokens per Sec:     1474, Lr: 0.000210
2025-05-19 04:01:01,592 - INFO - joeynmt.training - Epoch   7, Step:    20800, Batch Loss:     4.241175, Batch Acc: 0.108861, Tokens per Sec:     1499, Lr: 0.000210
2025-05-19 04:01:43,110 - INFO - joeynmt.training - Epoch   7, Step:    20900, Batch Loss:     4.348462, Batch Acc: 0.108904, Tokens per Sec:     1571, Lr: 0.000210
2025-05-19 04:02:25,394 - INFO - joeynmt.training - Epoch   7, Step:    21000, Batch Loss:     4.254016, Batch Acc: 0.109631, Tokens per Sec:     1540, Lr: 0.000210
2025-05-19 04:02:25,395 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:02:25,395 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:05:05,963 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.31, ppl:  74.62, acc:   0.11, generation: 160.5553[sec], evaluation: 0.0000[sec]
2025-05-19 04:05:05,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 04:05:06,176 - INFO - joeynmt.helpers - delete models_bpelvl/8500.ckpt
2025-05-19 04:05:06,179 - INFO - joeynmt.training - Example #0
2025-05-19 04:05:06,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:05:06,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:05:06,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un']
2025-05-19 04:05:06,179 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:05:06,179 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:05:06,179 - INFO - joeynmt.training - 	Hypothesis: E non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che è un modo che è un modo che non è un modo che non è un modo che non è un modo che non è un
2025-05-19 04:05:06,179 - INFO - joeynmt.training - Example #1
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non']
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Hypothesis: Ma non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non
2025-05-19 04:05:06,180 - INFO - joeynmt.training - Example #2
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'fatto', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'la', 'mondo', 'di', 'un', 'modo', 'che', 'la']
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Hypothesis: Abbiamo fatto che la mondo che la mondo che la mondo che la mondo che la mondo che la mondo di un modo che la mondo di un modo che è un modo che è un modo che è un modo che è un modo che è un modo che la mondo di un modo che è un modo che la mondo di un modo che la
2025-05-19 04:05:06,180 - INFO - joeynmt.training - Example #3
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Hypothesis: E la nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 04:05:06,180 - INFO - joeynmt.training - Example #4
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:05:06,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'non', 'non', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che']
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:05:06,180 - INFO - joeynmt.training - 	Hypothesis: Il mio po' che non è un po' che non non non non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che
2025-05-19 04:05:48,890 - INFO - joeynmt.training - Epoch   7, Step:    21100, Batch Loss:     4.376118, Batch Acc: 0.107564, Tokens per Sec:     1524, Lr: 0.000210
2025-05-19 04:06:31,675 - INFO - joeynmt.training - Epoch   7, Step:    21200, Batch Loss:     4.364079, Batch Acc: 0.107646, Tokens per Sec:     1539, Lr: 0.000210
2025-05-19 04:07:15,145 - INFO - joeynmt.training - Epoch   7, Step:    21300, Batch Loss:     4.283272, Batch Acc: 0.108117, Tokens per Sec:     1501, Lr: 0.000210
2025-05-19 04:07:55,899 - INFO - joeynmt.training - Epoch   7, Step:    21400, Batch Loss:     4.359231, Batch Acc: 0.109392, Tokens per Sec:     1623, Lr: 0.000210
2025-05-19 04:08:36,000 - INFO - joeynmt.training - Epoch   7, Step:    21500, Batch Loss:     4.273973, Batch Acc: 0.109443, Tokens per Sec:     1604, Lr: 0.000210
2025-05-19 04:08:36,001 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:08:36,001 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:11:17,538 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.31, ppl:  74.62, acc:   0.11, generation: 161.5248[sec], evaluation: 0.0000[sec]
2025-05-19 04:11:17,749 - INFO - joeynmt.helpers - delete models_bpelvl/9000.ckpt
2025-05-19 04:11:17,751 - INFO - joeynmt.training - Example #0
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo']
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Hypothesis: Il modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo
2025-05-19 04:11:17,752 - INFO - joeynmt.training - Example #1
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 04:11:17,752 - INFO - joeynmt.training - Example #2
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'il', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Hypothesis: In il mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 04:11:17,752 - INFO - joeynmt.training - Example #3
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:11:17,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra', 'nostra']
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:11:17,752 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:11:17,753 - INFO - joeynmt.training - 	Hypothesis: E la nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra nostra
2025-05-19 04:11:17,753 - INFO - joeynmt.training - Example #4
2025-05-19 04:11:17,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:11:17,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:11:17,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'parte', 'di', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'è']
2025-05-19 04:11:17,753 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:11:17,753 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:11:17,753 - INFO - joeynmt.training - 	Hypothesis: La mia parte di un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che non è un po' che è un po' che non è un po' che è
2025-05-19 04:12:00,754 - INFO - joeynmt.training - Epoch   7, Step:    21600, Batch Loss:     4.223413, Batch Acc: 0.109813, Tokens per Sec:     1517, Lr: 0.000210
2025-05-19 04:12:43,282 - INFO - joeynmt.training - Epoch   7, Step:    21700, Batch Loss:     4.047983, Batch Acc: 0.111755, Tokens per Sec:     1558, Lr: 0.000210
2025-05-19 04:13:26,200 - INFO - joeynmt.training - Epoch   7, Step:    21800, Batch Loss:     4.282997, Batch Acc: 0.107656, Tokens per Sec:     1530, Lr: 0.000210
2025-05-19 04:14:09,224 - INFO - joeynmt.training - Epoch   7, Step:    21900, Batch Loss:     4.361636, Batch Acc: 0.110039, Tokens per Sec:     1497, Lr: 0.000210
2025-05-19 04:14:51,692 - INFO - joeynmt.training - Epoch   7, Step:    22000, Batch Loss:     4.287367, Batch Acc: 0.107359, Tokens per Sec:     1505, Lr: 0.000210
2025-05-19 04:14:51,692 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:14:51,692 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:17:37,254 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.30, ppl:  73.70, acc:   0.11, generation: 165.5499[sec], evaluation: 0.0000[sec]
2025-05-19 04:17:37,255 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 04:17:37,457 - INFO - joeynmt.helpers - delete models_bpelvl/11500.ckpt
2025-05-19 04:17:37,460 - INFO - joeynmt.training - Example #0
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'un', 'modo', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non è un modo che non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:17:37,460 - INFO - joeynmt.training - Example #1
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 04:17:37,460 - INFO - joeynmt.training - Example #2
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di']
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:17:37,460 - INFO - joeynmt.training - 	Hypothesis: In un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di
2025-05-19 04:17:37,460 - INFO - joeynmt.training - Example #3
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:17:37,460 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'un', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Hypothesis: E' un nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 04:17:37,461 - INFO - joeynmt.training - Example #4
2025-05-19 04:17:37,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:17:37,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:17:37,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'modo']
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:17:37,461 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un modo
2025-05-19 04:18:20,079 - INFO - joeynmt.training - Epoch   7, Step:    22100, Batch Loss:     4.221600, Batch Acc: 0.108383, Tokens per Sec:     1467, Lr: 0.000210
2025-05-19 04:19:02,388 - INFO - joeynmt.training - Epoch   7, Step:    22200, Batch Loss:     4.190119, Batch Acc: 0.113130, Tokens per Sec:     1540, Lr: 0.000210
2025-05-19 04:19:41,573 - INFO - joeynmt.training - Epoch   7: total training loss 13602.49
2025-05-19 04:19:41,573 - INFO - joeynmt.training - EPOCH 8
2025-05-19 04:19:43,615 - INFO - joeynmt.training - Epoch   8, Step:    22300, Batch Loss:     4.097716, Batch Acc: 0.114376, Tokens per Sec:     1550, Lr: 0.000210
2025-05-19 04:20:26,144 - INFO - joeynmt.training - Epoch   8, Step:    22400, Batch Loss:     4.106812, Batch Acc: 0.116099, Tokens per Sec:     1556, Lr: 0.000210
2025-05-19 04:21:06,323 - INFO - joeynmt.training - Epoch   8, Step:    22500, Batch Loss:     4.259467, Batch Acc: 0.114216, Tokens per Sec:     1676, Lr: 0.000210
2025-05-19 04:21:06,323 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:21:06,323 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:23:47,944 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.28, ppl:  72.42, acc:   0.11, generation: 161.6082[sec], evaluation: 0.0000[sec]
2025-05-19 04:23:47,946 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 04:23:48,158 - INFO - joeynmt.helpers - delete models_bpelvl/20000.ckpt
2025-05-19 04:23:48,161 - INFO - joeynmt.training - Example #0
2025-05-19 04:23:48,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:23:48,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:23:48,161 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:23:48,162 - INFO - joeynmt.training - Example #1
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è']
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è
2025-05-19 04:23:48,162 - INFO - joeynmt.training - Example #2
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 04:23:48,162 - INFO - joeynmt.training - Example #3
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'un', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:23:48,162 - INFO - joeynmt.training - 	Hypothesis: E' un nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 04:23:48,162 - INFO - joeynmt.training - Example #4
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:23:48,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', "po'", 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 04:23:48,163 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:23:48,163 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:23:48,163 - INFO - joeynmt.training - 	Hypothesis: La mia po' che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 04:24:31,352 - INFO - joeynmt.training - Epoch   8, Step:    22600, Batch Loss:     4.311670, Batch Acc: 0.111867, Tokens per Sec:     1510, Lr: 0.000210
2025-05-19 04:25:14,426 - INFO - joeynmt.training - Epoch   8, Step:    22700, Batch Loss:     4.289949, Batch Acc: 0.110811, Tokens per Sec:     1523, Lr: 0.000210
2025-05-19 04:25:56,593 - INFO - joeynmt.training - Epoch   8, Step:    22800, Batch Loss:     4.178534, Batch Acc: 0.111536, Tokens per Sec:     1525, Lr: 0.000210
2025-05-19 04:26:38,932 - INFO - joeynmt.training - Epoch   8, Step:    22900, Batch Loss:     4.238228, Batch Acc: 0.108224, Tokens per Sec:     1506, Lr: 0.000210
2025-05-19 04:27:22,056 - INFO - joeynmt.training - Epoch   8, Step:    23000, Batch Loss:     4.119817, Batch Acc: 0.113569, Tokens per Sec:     1470, Lr: 0.000210
2025-05-19 04:27:22,056 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:27:22,056 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:30:03,518 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  72.86, acc:   0.11, generation: 161.4501[sec], evaluation: 0.0000[sec]
2025-05-19 04:30:03,728 - INFO - joeynmt.helpers - delete models_bpelvl/21500.ckpt
2025-05-19 04:30:03,731 - INFO - joeynmt.training - Example #0
2025-05-19 04:30:03,731 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:30:03,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:30:03,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Hypothesis: E non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:30:03,732 - INFO - joeynmt.training - Example #1
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'un', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non è un cosa non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:30:03,732 - INFO - joeynmt.training - Example #2
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Hypothesis: In un po' di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 04:30:03,732 - INFO - joeynmt.training - Example #3
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'una', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte']
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Hypothesis: Si è una parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte
2025-05-19 04:30:03,732 - INFO - joeynmt.training - Example #4
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:30:03,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:30:03,732 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:30:03,733 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:30:03,733 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:30:45,718 - INFO - joeynmt.training - Epoch   8, Step:    23100, Batch Loss:     4.243133, Batch Acc: 0.115511, Tokens per Sec:     1509, Lr: 0.000210
2025-05-19 04:31:29,309 - INFO - joeynmt.training - Epoch   8, Step:    23200, Batch Loss:     4.248206, Batch Acc: 0.111608, Tokens per Sec:     1504, Lr: 0.000210
2025-05-19 04:32:11,466 - INFO - joeynmt.training - Epoch   8, Step:    23300, Batch Loss:     4.366533, Batch Acc: 0.110190, Tokens per Sec:     1543, Lr: 0.000210
2025-05-19 04:32:54,054 - INFO - joeynmt.training - Epoch   8, Step:    23400, Batch Loss:     4.213058, Batch Acc: 0.113548, Tokens per Sec:     1535, Lr: 0.000210
2025-05-19 04:33:36,094 - INFO - joeynmt.training - Epoch   8, Step:    23500, Batch Loss:     4.069017, Batch Acc: 0.110876, Tokens per Sec:     1532, Lr: 0.000210
2025-05-19 04:33:36,095 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:33:36,095 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:36:18,440 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.30, ppl:  74.06, acc:   0.10, generation: 162.3330[sec], evaluation: 0.0000[sec]
2025-05-19 04:36:18,647 - INFO - joeynmt.helpers - delete models_bpelvl/19500.ckpt
2025-05-19 04:36:18,649 - INFO - joeynmt.training - Example #0
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:36:18,649 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:36:18,649 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:36:18,649 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:36:18,649 - INFO - joeynmt.training - Example #1
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:36:18,649 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa', 'la', 'mia', 'cosa']
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Hypothesis: Ma la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa la mia cosa
2025-05-19 04:36:18,650 - INFO - joeynmt.training - Example #2
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 04:36:18,650 - INFO - joeynmt.training - Example #3
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di']
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Hypothesis: E' un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di
2025-05-19 04:36:18,650 - INFO - joeynmt.training - Example #4
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:36:18,650 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:36:18,650 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 04:37:01,280 - INFO - joeynmt.training - Epoch   8, Step:    23600, Batch Loss:     4.120339, Batch Acc: 0.107766, Tokens per Sec:     1504, Lr: 0.000210
2025-05-19 04:37:43,127 - INFO - joeynmt.training - Epoch   8, Step:    23700, Batch Loss:     4.321183, Batch Acc: 0.110052, Tokens per Sec:     1562, Lr: 0.000210
2025-05-19 04:38:24,953 - INFO - joeynmt.training - Epoch   8, Step:    23800, Batch Loss:     4.122159, Batch Acc: 0.109403, Tokens per Sec:     1479, Lr: 0.000210
2025-05-19 04:39:07,162 - INFO - joeynmt.training - Epoch   8, Step:    23900, Batch Loss:     4.251233, Batch Acc: 0.111682, Tokens per Sec:     1517, Lr: 0.000210
2025-05-19 04:39:48,400 - INFO - joeynmt.training - Epoch   8, Step:    24000, Batch Loss:     4.121984, Batch Acc: 0.110552, Tokens per Sec:     1524, Lr: 0.000210
2025-05-19 04:39:48,400 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:39:48,400 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:42:31,686 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.28, ppl:  72.02, acc:   0.11, generation: 163.2746[sec], evaluation: 0.0000[sec]
2025-05-19 04:42:31,689 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 04:42:31,903 - INFO - joeynmt.helpers - delete models_bpelvl/21000.ckpt
2025-05-19 04:42:31,905 - INFO - joeynmt.training - Example #0
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'loro', 'anni', 'e', 'la', 'loro', 'anni', 'e', 'la', 'loro', 'anni', 'e', 'la', 'loro', 'anni', 'di', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'", 'che', 'si', 'è', 'un', "po'"]
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Hypothesis: La loro anni e la loro anni e la loro anni e la loro anni di un po' che si è un po' che si è un po' che si è un po' che si è un po' che si è un po' che è un po' che si è un po' che si è un po' che si è un po' che si è un po'
2025-05-19 04:42:31,905 - INFO - joeynmt.training - Example #1
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è']
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:42:31,905 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che è un po' che è un po' di un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' di un po' di un po' che è un po' di un po' che è un po' che è
2025-05-19 04:42:31,905 - INFO - joeynmt.training - Example #2
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:42:31,905 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro', 'parte', 'di', 'un', 'altro']
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Hypothesis: In un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro parte di un altro
2025-05-19 04:42:31,906 - INFO - joeynmt.training - Example #3
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'un', 'parte', 'di', 'mondo.', '</s>']
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Hypothesis: Si è un parte di mondo.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - Example #4
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:42:31,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:42:31,906 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po'
2025-05-19 04:43:14,431 - INFO - joeynmt.training - Epoch   8, Step:    24100, Batch Loss:     4.181726, Batch Acc: 0.110586, Tokens per Sec:     1480, Lr: 0.000210
2025-05-19 04:43:58,176 - INFO - joeynmt.training - Epoch   8, Step:    24200, Batch Loss:     4.186358, Batch Acc: 0.113386, Tokens per Sec:     1489, Lr: 0.000210
2025-05-19 04:44:41,999 - INFO - joeynmt.training - Epoch   8, Step:    24300, Batch Loss:     4.174077, Batch Acc: 0.111417, Tokens per Sec:     1499, Lr: 0.000210
2025-05-19 04:45:25,460 - INFO - joeynmt.training - Epoch   8, Step:    24400, Batch Loss:     4.323856, Batch Acc: 0.109993, Tokens per Sec:     1506, Lr: 0.000210
2025-05-19 04:46:08,123 - INFO - joeynmt.training - Epoch   8, Step:    24500, Batch Loss:     4.169230, Batch Acc: 0.111857, Tokens per Sec:     1484, Lr: 0.000210
2025-05-19 04:46:08,123 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:46:08,123 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:48:49,850 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.27, ppl:  71.68, acc:   0.11, generation: 161.7143[sec], evaluation: 0.0000[sec]
2025-05-19 04:48:49,852 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 04:48:50,051 - INFO - joeynmt.helpers - delete models_bpelvl/23500.ckpt
2025-05-19 04:48:50,053 - INFO - joeynmt.training - Example #0
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono', 'un', "po'", 'che', 'non', 'sono']
2025-05-19 04:48:50,053 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:48:50,053 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:48:50,053 - INFO - joeynmt.training - 	Hypothesis: In un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non sono un po' che non non sono un po' che non sono un po' che non sono
2025-05-19 04:48:50,053 - INFO - joeynmt.training - Example #1
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:48:50,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'di', 'un', "po'", 'che', 'è', 'un', "po'", 'che', 'è']
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' che è un po' che è un po' di un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' che è un po' di un po' di un po' che è un po' di un po' che è un po' che è
2025-05-19 04:48:50,054 - INFO - joeynmt.training - Example #2
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro']
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Hypothesis: In un altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro
2025-05-19 04:48:50,054 - INFO - joeynmt.training - Example #3
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un']
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Hypothesis: Si è di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un
2025-05-19 04:48:50,054 - INFO - joeynmt.training - Example #4
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:48:50,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'", 'che', 'non', 'è', 'un', "po'"]
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:48:50,054 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po' che non è un po'
2025-05-19 04:49:32,830 - INFO - joeynmt.training - Epoch   8, Step:    24600, Batch Loss:     4.258528, Batch Acc: 0.114954, Tokens per Sec:     1484, Lr: 0.000210
2025-05-19 04:50:15,452 - INFO - joeynmt.training - Epoch   8, Step:    24700, Batch Loss:     4.161408, Batch Acc: 0.110541, Tokens per Sec:     1508, Lr: 0.000210
2025-05-19 04:50:58,058 - INFO - joeynmt.training - Epoch   8, Step:    24800, Batch Loss:     4.265097, Batch Acc: 0.111414, Tokens per Sec:     1507, Lr: 0.000210
2025-05-19 04:51:40,878 - INFO - joeynmt.training - Epoch   8, Step:    24900, Batch Loss:     4.307643, Batch Acc: 0.113360, Tokens per Sec:     1514, Lr: 0.000210
2025-05-19 04:52:23,383 - INFO - joeynmt.training - Epoch   8, Step:    25000, Batch Loss:     4.321273, Batch Acc: 0.110749, Tokens per Sec:     1531, Lr: 0.000210
2025-05-19 04:52:23,383 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:52:23,383 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 04:55:05,366 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  73.03, acc:   0.11, generation: 161.9711[sec], evaluation: 0.0000[sec]
2025-05-19 04:55:05,574 - INFO - joeynmt.helpers - delete models_bpelvl/22000.ckpt
2025-05-19 04:55:05,577 - INFO - joeynmt.training - Example #0
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Hypothesis: In un modo che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 04:55:05,577 - INFO - joeynmt.training - Example #1
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 04:55:05,577 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 04:55:05,577 - INFO - joeynmt.training - Example #2
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 04:55:05,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo', 'suo']
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Hypothesis: In un suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo suo
2025-05-19 04:55:05,578 - INFO - joeynmt.training - Example #3
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo']
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Hypothesis: Si è un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo
2025-05-19 04:55:05,578 - INFO - joeynmt.training - Example #4
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 04:55:05,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 04:55:05,578 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non
2025-05-19 04:55:48,218 - INFO - joeynmt.training - Epoch   8, Step:    25100, Batch Loss:     4.193164, Batch Acc: 0.112089, Tokens per Sec:     1544, Lr: 0.000210
2025-05-19 04:56:30,060 - INFO - joeynmt.training - Epoch   8, Step:    25200, Batch Loss:     4.374903, Batch Acc: 0.108829, Tokens per Sec:     1541, Lr: 0.000210
2025-05-19 04:57:13,013 - INFO - joeynmt.training - Epoch   8, Step:    25300, Batch Loss:     4.212932, Batch Acc: 0.108283, Tokens per Sec:     1490, Lr: 0.000210
2025-05-19 04:57:55,899 - INFO - joeynmt.training - Epoch   8, Step:    25400, Batch Loss:     4.249007, Batch Acc: 0.109687, Tokens per Sec:     1538, Lr: 0.000210
2025-05-19 04:58:33,454 - INFO - joeynmt.training - Epoch   8: total training loss 13533.50
2025-05-19 04:58:33,454 - INFO - joeynmt.training - EPOCH 9
2025-05-19 04:58:38,351 - INFO - joeynmt.training - Epoch   9, Step:    25500, Batch Loss:     4.282640, Batch Acc: 0.101826, Tokens per Sec:     1610, Lr: 0.000210
2025-05-19 04:58:38,351 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 04:58:38,351 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:01:20,421 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.30, ppl:  73.59, acc:   0.11, generation: 162.0577[sec], evaluation: 0.0000[sec]
2025-05-19 05:01:20,425 - INFO - joeynmt.training - Example #0
2025-05-19 05:01:20,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:01:20,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:01:20,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'In', 'un', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'In', 'un', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la', 'mio', "po'", 'che', 'la']
2025-05-19 05:01:20,425 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Hypothesis: In un po' che la mio po' che la mio po' che la In un po' che la mio po' che la mio po' che la mio po' che la mio po' che la mio po' che la In un po' che la mio po' che la mio po' che la mio po' che la mio po' che la mio po' che la mio po' che la
2025-05-19 05:01:20,426 - INFO - joeynmt.training - Example #1
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'è', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che', 'ho', 'fatto', 'che']
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Hypothesis: Ma non ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che è che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che ho fatto che
2025-05-19 05:01:20,426 - INFO - joeynmt.training - Example #2
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:01:20,426 - INFO - joeynmt.training - 	Hypothesis: In un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 05:01:20,426 - INFO - joeynmt.training - Example #3
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:01:20,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'è', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di', 'parte', 'di']
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Hypothesis: Non è di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di parte di
2025-05-19 05:01:20,427 - INFO - joeynmt.training - Example #4
2025-05-19 05:01:20,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:01:20,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:01:20,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:01:20,427 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 05:02:02,520 - INFO - joeynmt.training - Epoch   9, Step:    25600, Batch Loss:     4.236155, Batch Acc: 0.108787, Tokens per Sec:     1553, Lr: 0.000210
2025-05-19 05:02:44,837 - INFO - joeynmt.training - Epoch   9, Step:    25700, Batch Loss:     4.323791, Batch Acc: 0.109173, Tokens per Sec:     1521, Lr: 0.000210
2025-05-19 05:03:27,599 - INFO - joeynmt.training - Epoch   9, Step:    25800, Batch Loss:     4.121893, Batch Acc: 0.109094, Tokens per Sec:     1569, Lr: 0.000210
2025-05-19 05:04:10,424 - INFO - joeynmt.training - Epoch   9, Step:    25900, Batch Loss:     4.300711, Batch Acc: 0.112314, Tokens per Sec:     1520, Lr: 0.000210
2025-05-19 05:04:52,651 - INFO - joeynmt.training - Epoch   9, Step:    26000, Batch Loss:     4.087075, Batch Acc: 0.110484, Tokens per Sec:     1499, Lr: 0.000210
2025-05-19 05:04:52,651 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:04:52,652 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:07:35,387 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.28, ppl:  72.48, acc:   0.11, generation: 162.7235[sec], evaluation: 0.0000[sec]
2025-05-19 05:07:35,593 - INFO - joeynmt.helpers - delete models_bpelvl/25000.ckpt
2025-05-19 05:07:35,595 - INFO - joeynmt.helpers - delete /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/25000.ckpt
2025-05-19 05:07:35,595 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/25000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/25000.ckpt')
2025-05-19 05:07:35,595 - INFO - joeynmt.training - Example #0
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:07:35,595 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:07:35,595 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:07:35,595 - INFO - joeynmt.training - 	Hypothesis: In un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 05:07:35,595 - INFO - joeynmt.training - Example #1
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:07:35,595 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 05:07:35,596 - INFO - joeynmt.training - Example #2
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'essere', 'la', 'nostra', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro']
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Hypothesis: Abbiamo essere la nostra altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro
2025-05-19 05:07:35,596 - INFO - joeynmt.training - Example #3
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'il', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte', 'di', 'nostra', 'parte']
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Hypothesis: Si il nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte di nostra parte
2025-05-19 05:07:35,596 - INFO - joeynmt.training - Example #4
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:07:35,596 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'sua', 'miei', 'cosa', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è']
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:07:35,596 - INFO - joeynmt.training - 	Hypothesis: La sua miei cosa non è un modo che non è un modo che non è che non è che non è che non è che non è un modo che non è un modo che non è un modo che non è che non è che non è un cosa non è un modo che non è che non è che non è che non è
2025-05-19 05:08:17,640 - INFO - joeynmt.training - Epoch   9, Step:    26100, Batch Loss:     4.436121, Batch Acc: 0.111137, Tokens per Sec:     1533, Lr: 0.000210
2025-05-19 05:09:00,299 - INFO - joeynmt.training - Epoch   9, Step:    26200, Batch Loss:     4.356070, Batch Acc: 0.105109, Tokens per Sec:     1518, Lr: 0.000210
2025-05-19 05:09:43,035 - INFO - joeynmt.training - Epoch   9, Step:    26300, Batch Loss:     4.239900, Batch Acc: 0.109369, Tokens per Sec:     1491, Lr: 0.000210
2025-05-19 05:10:25,517 - INFO - joeynmt.training - Epoch   9, Step:    26400, Batch Loss:     4.293877, Batch Acc: 0.110319, Tokens per Sec:     1553, Lr: 0.000210
2025-05-19 05:11:07,693 - INFO - joeynmt.training - Epoch   9, Step:    26500, Batch Loss:     4.193034, Batch Acc: 0.109046, Tokens per Sec:     1550, Lr: 0.000210
2025-05-19 05:11:07,693 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:11:07,693 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:13:49,075 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.33, ppl:  75.72, acc:   0.10, generation: 161.3701[sec], evaluation: 0.0000[sec]
2025-05-19 05:13:49,077 - INFO - joeynmt.training - Example #0
2025-05-19 05:13:49,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:13:49,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:13:49,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Hypothesis: In un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un di un po' di un po' di
2025-05-19 05:13:49,078 - INFO - joeynmt.training - Example #1
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che', 'non', 'che']
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Hypothesis: Ma non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che non che
2025-05-19 05:13:49,078 - INFO - joeynmt.training - Example #2
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'essere', 'la', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri', 'loro', 'nostri']
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:13:49,078 - INFO - joeynmt.training - 	Hypothesis: Abbiamo essere la loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri loro nostri
2025-05-19 05:13:49,078 - INFO - joeynmt.training - Example #3
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:13:49,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri', 'nostri']
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Hypothesis: E la nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri nostri
2025-05-19 05:13:49,079 - INFO - joeynmt.training - Example #4
2025-05-19 05:13:49,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:13:49,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:13:49,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:13:49,079 - INFO - joeynmt.training - 	Hypothesis: La mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2025-05-19 05:14:32,702 - INFO - joeynmt.training - Epoch   9, Step:    26600, Batch Loss:     4.104836, Batch Acc: 0.108921, Tokens per Sec:     1464, Lr: 0.000210
2025-05-19 05:15:16,150 - INFO - joeynmt.training - Epoch   9, Step:    26700, Batch Loss:     4.163025, Batch Acc: 0.109860, Tokens per Sec:     1492, Lr: 0.000210
2025-05-19 05:15:58,509 - INFO - joeynmt.training - Epoch   9, Step:    26800, Batch Loss:     4.141985, Batch Acc: 0.112255, Tokens per Sec:     1571, Lr: 0.000210
2025-05-19 05:16:40,491 - INFO - joeynmt.training - Epoch   9, Step:    26900, Batch Loss:     4.261171, Batch Acc: 0.111890, Tokens per Sec:     1505, Lr: 0.000210
2025-05-19 05:17:22,530 - INFO - joeynmt.training - Epoch   9, Step:    27000, Batch Loss:     4.247107, Batch Acc: 0.110951, Tokens per Sec:     1566, Lr: 0.000210
2025-05-19 05:17:22,532 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:17:22,532 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:20:05,664 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  73.30, acc:   0.11, generation: 163.1208[sec], evaluation: 0.0000[sec]
2025-05-19 05:20:05,667 - INFO - joeynmt.training - Example #0
2025-05-19 05:20:05,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:20:05,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:20:05,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'che', 'non', 'è', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un']
2025-05-19 05:20:05,667 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:20:05,667 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:20:05,667 - INFO - joeynmt.training - 	Hypothesis: In un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo che non è un modo di un modo di un modo che non è un modo che non è un modo di un modo di un modo di un
2025-05-19 05:20:05,667 - INFO - joeynmt.training - Example #1
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 05:20:05,668 - INFO - joeynmt.training - Example #2
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'un', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro', 'altro']
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Hypothesis: Abbiamo un altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro altro
2025-05-19 05:20:05,668 - INFO - joeynmt.training - Example #3
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:20:05,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'un', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro']
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:20:05,668 - INFO - joeynmt.training - 	Hypothesis: Si è un nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro
2025-05-19 05:20:05,669 - INFO - joeynmt.training - Example #4
2025-05-19 05:20:05,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:20:05,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:20:05,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'cosa', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'cosa', 'non', 'è', 'un', "po'", 'di', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'"]
2025-05-19 05:20:05,669 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:20:05,669 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:20:05,669 - INFO - joeynmt.training - 	Hypothesis: La mio po' di un po' di un po' di un cosa non è un po' di un po' di un po' di un po' di un cosa non è un cosa non è un po' di un po' di un cosa non è un po' di un cosa non è un cosa non è un cosa non è un po' di un po' di un po'
2025-05-19 05:20:49,261 - INFO - joeynmt.training - Epoch   9, Step:    27100, Batch Loss:     4.336708, Batch Acc: 0.112222, Tokens per Sec:     1516, Lr: 0.000210
2025-05-19 05:21:31,751 - INFO - joeynmt.training - Epoch   9, Step:    27200, Batch Loss:     4.208644, Batch Acc: 0.112241, Tokens per Sec:     1523, Lr: 0.000210
2025-05-19 05:22:13,570 - INFO - joeynmt.training - Epoch   9, Step:    27300, Batch Loss:     4.332671, Batch Acc: 0.115790, Tokens per Sec:     1541, Lr: 0.000210
2025-05-19 05:22:56,232 - INFO - joeynmt.training - Epoch   9, Step:    27400, Batch Loss:     4.336111, Batch Acc: 0.111801, Tokens per Sec:     1525, Lr: 0.000210
2025-05-19 05:23:39,756 - INFO - joeynmt.training - Epoch   9, Step:    27500, Batch Loss:     4.304802, Batch Acc: 0.114314, Tokens per Sec:     1466, Lr: 0.000210
2025-05-19 05:23:39,758 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:23:39,758 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:26:22,130 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  72.86, acc:   0.11, generation: 162.3598[sec], evaluation: 0.0000[sec]
2025-05-19 05:26:22,133 - INFO - joeynmt.training - Example #0
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Hypothesis: In un modo che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 05:26:22,134 - INFO - joeynmt.training - Example #1
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non']
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non non non non non non non non non è che non è che non è che non è che non è che non è che non non non è che non è che non è che non è che non non
2025-05-19 05:26:22,134 - INFO - joeynmt.training - Example #2
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'essere', 'la', 'nostra', 'è', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un']
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:26:22,134 - INFO - joeynmt.training - 	Hypothesis: Abbiamo essere la nostra è di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un
2025-05-19 05:26:22,134 - INFO - joeynmt.training - Example #3
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:26:22,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:26:22,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Hypothesis: E' un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 05:26:22,135 - INFO - joeynmt.training - Example #4
2025-05-19 05:26:22,135 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:26:22,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:26:22,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è']
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:26:22,135 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che è che è che è che è che non è che non è che non è che non è che non è che non è che non è
2025-05-19 05:27:05,958 - INFO - joeynmt.training - Epoch   9, Step:    27600, Batch Loss:     4.251477, Batch Acc: 0.107769, Tokens per Sec:     1533, Lr: 0.000210
2025-05-19 05:27:48,482 - INFO - joeynmt.training - Epoch   9, Step:    27700, Batch Loss:     4.293625, Batch Acc: 0.110094, Tokens per Sec:     1556, Lr: 0.000210
2025-05-19 05:28:30,789 - INFO - joeynmt.training - Epoch   9, Step:    27800, Batch Loss:     4.342337, Batch Acc: 0.108567, Tokens per Sec:     1542, Lr: 0.000210
2025-05-19 05:29:12,682 - INFO - joeynmt.training - Epoch   9, Step:    27900, Batch Loss:     4.243379, Batch Acc: 0.111229, Tokens per Sec:     1484, Lr: 0.000210
2025-05-19 05:29:54,403 - INFO - joeynmt.training - Epoch   9, Step:    28000, Batch Loss:     4.231728, Batch Acc: 0.114316, Tokens per Sec:     1549, Lr: 0.000210
2025-05-19 05:29:54,404 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:29:54,404 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:32:36,649 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.27, ppl:  71.63, acc:   0.11, generation: 162.2339[sec], evaluation: 0.0000[sec]
2025-05-19 05:32:36,651 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 05:32:36,862 - INFO - joeynmt.helpers - delete models_bpelvl/23000.ckpt
2025-05-19 05:32:36,866 - INFO - joeynmt.training - Example #0
2025-05-19 05:32:36,866 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:32:36,866 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:32:36,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 05:32:36,866 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:32:36,866 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:32:36,866 - INFO - joeynmt.training - 	Hypothesis: In un modo che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 05:32:36,867 - INFO - joeynmt.training - Example #1
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non non non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non
2025-05-19 05:32:36,867 - INFO - joeynmt.training - Example #2
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Hypothesis: In un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 05:32:36,867 - INFO - joeynmt.training - Example #3
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'un', 'mondo.', '</s>']
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Hypothesis: E' un mondo.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - Example #4
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:32:36,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:32:36,867 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non
2025-05-19 05:33:20,795 - INFO - joeynmt.training - Epoch   9, Step:    28100, Batch Loss:     4.265699, Batch Acc: 0.108560, Tokens per Sec:     1416, Lr: 0.000210
2025-05-19 05:34:04,854 - INFO - joeynmt.training - Epoch   9, Step:    28200, Batch Loss:     4.321082, Batch Acc: 0.108193, Tokens per Sec:     1467, Lr: 0.000210
2025-05-19 05:34:47,081 - INFO - joeynmt.training - Epoch   9, Step:    28300, Batch Loss:     4.301935, Batch Acc: 0.107914, Tokens per Sec:     1519, Lr: 0.000210
2025-05-19 05:35:30,145 - INFO - joeynmt.training - Epoch   9, Step:    28400, Batch Loss:     4.365778, Batch Acc: 0.109898, Tokens per Sec:     1440, Lr: 0.000210
2025-05-19 05:36:12,894 - INFO - joeynmt.training - Epoch   9, Step:    28500, Batch Loss:     4.163538, Batch Acc: 0.111212, Tokens per Sec:     1551, Lr: 0.000210
2025-05-19 05:36:12,895 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:36:12,895 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:38:57,597 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.30, ppl:  73.52, acc:   0.11, generation: 164.6898[sec], evaluation: 0.0000[sec]
2025-05-19 05:38:57,600 - INFO - joeynmt.training - Example #0
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Hypothesis: In un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 05:38:57,600 - INFO - joeynmt.training - Example #1
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:38:57,600 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non non non non non non non non non non non non non non non non non non non non non non non non non è che non è che non è che non è che non è che non non non non non non non è che non è che non non non non non non
2025-05-19 05:38:57,600 - INFO - joeynmt.training - Example #2
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:38:57,600 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Abbiamo', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di', 'un', 'parte', 'di']
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Hypothesis: Abbiamo un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di un parte di
2025-05-19 05:38:57,601 - INFO - joeynmt.training - Example #3
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'di', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Hypothesis: E' di un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 05:38:57,601 - INFO - joeynmt.training - Example #4
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:38:57,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:38:57,601 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 05:39:40,214 - INFO - joeynmt.training - Epoch   9, Step:    28600, Batch Loss:     4.333394, Batch Acc: 0.108421, Tokens per Sec:     1564, Lr: 0.000210
2025-05-19 05:40:13,274 - INFO - joeynmt.training - Epoch   9: total training loss 13549.84
2025-05-19 05:40:13,275 - INFO - joeynmt.training - EPOCH 10
2025-05-19 05:40:23,045 - INFO - joeynmt.training - Epoch  10, Step:    28700, Batch Loss:     4.229634, Batch Acc: 0.106996, Tokens per Sec:     1595, Lr: 0.000210
2025-05-19 05:41:05,210 - INFO - joeynmt.training - Epoch  10, Step:    28800, Batch Loss:     4.189510, Batch Acc: 0.110784, Tokens per Sec:     1529, Lr: 0.000210
2025-05-19 05:41:47,456 - INFO - joeynmt.training - Epoch  10, Step:    28900, Batch Loss:     4.275743, Batch Acc: 0.107468, Tokens per Sec:     1496, Lr: 0.000210
2025-05-19 05:42:30,618 - INFO - joeynmt.training - Epoch  10, Step:    29000, Batch Loss:     4.234571, Batch Acc: 0.112633, Tokens per Sec:     1477, Lr: 0.000210
2025-05-19 05:42:30,619 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:42:30,619 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:45:14,332 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  72.72, acc:   0.11, generation: 163.7005[sec], evaluation: 0.0000[sec]
2025-05-19 05:45:14,336 - INFO - joeynmt.training - Example #0
2025-05-19 05:45:14,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:45:14,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:45:14,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', 'di', 'un']
2025-05-19 05:45:14,336 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:45:14,336 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:45:14,336 - INFO - joeynmt.training - 	Hypothesis: In un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un di un
2025-05-19 05:45:14,336 - INFO - joeynmt.training - Example #1
2025-05-19 05:45:14,336 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:45:14,336 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un']
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Hypothesis: Ma non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un
2025-05-19 05:45:14,337 - INFO - joeynmt.training - Example #2
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 05:45:14,337 - INFO - joeynmt.training - Example #3
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ["E'", 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo']
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Hypothesis: E' di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo
2025-05-19 05:45:14,337 - INFO - joeynmt.training - Example #4
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:45:14,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'gente', 'e', 'non', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo', 'che', 'è', 'un', 'modo']
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:45:14,337 - INFO - joeynmt.training - 	Hypothesis: La gente e non è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo che è un modo
2025-05-19 05:45:58,090 - INFO - joeynmt.training - Epoch  10, Step:    29100, Batch Loss:     4.509020, Batch Acc: 0.116388, Tokens per Sec:     1467, Lr: 0.000210
2025-05-19 05:46:41,785 - INFO - joeynmt.training - Epoch  10, Step:    29200, Batch Loss:     4.215070, Batch Acc: 0.114400, Tokens per Sec:     1454, Lr: 0.000210
2025-05-19 05:47:24,416 - INFO - joeynmt.training - Epoch  10, Step:    29300, Batch Loss:     4.270796, Batch Acc: 0.115125, Tokens per Sec:     1509, Lr: 0.000210
2025-05-19 05:48:07,146 - INFO - joeynmt.training - Epoch  10, Step:    29400, Batch Loss:     4.141109, Batch Acc: 0.112732, Tokens per Sec:     1486, Lr: 0.000210
2025-05-19 05:48:50,635 - INFO - joeynmt.training - Epoch  10, Step:    29500, Batch Loss:     4.135862, Batch Acc: 0.112449, Tokens per Sec:     1499, Lr: 0.000210
2025-05-19 05:48:50,636 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:48:50,636 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:51:35,197 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.32, ppl:  75.22, acc:   0.11, generation: 164.5487[sec], evaluation: 0.0000[sec]
2025-05-19 05:51:35,202 - INFO - joeynmt.training - Example #0
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Hypothesis: E non è che non è che non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non è che non è che non non non non non non non non non non non non non non non non non non non non
2025-05-19 05:51:35,202 - INFO - joeynmt.training - Example #1
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:51:35,202 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 05:51:35,202 - INFO - joeynmt.training - Example #2
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:51:35,202 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Hypothesis: In un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 05:51:35,203 - INFO - joeynmt.training - Example #3
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'è', 'di', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un']
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Hypothesis: Si è di un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un
2025-05-19 05:51:35,203 - INFO - joeynmt.training - Example #4
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:51:35,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:51:35,203 - INFO - joeynmt.training - 	Hypothesis: La mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di
2025-05-19 05:52:18,985 - INFO - joeynmt.training - Epoch  10, Step:    29600, Batch Loss:     4.335463, Batch Acc: 0.107938, Tokens per Sec:     1497, Lr: 0.000210
2025-05-19 05:53:02,163 - INFO - joeynmt.training - Epoch  10, Step:    29700, Batch Loss:     4.242939, Batch Acc: 0.110816, Tokens per Sec:     1500, Lr: 0.000210
2025-05-19 05:53:45,770 - INFO - joeynmt.training - Epoch  10, Step:    29800, Batch Loss:     4.382279, Batch Acc: 0.111260, Tokens per Sec:     1493, Lr: 0.000210
2025-05-19 05:54:28,534 - INFO - joeynmt.training - Epoch  10, Step:    29900, Batch Loss:     4.230110, Batch Acc: 0.109314, Tokens per Sec:     1528, Lr: 0.000210
2025-05-19 05:55:11,136 - INFO - joeynmt.training - Epoch  10, Step:    30000, Batch Loss:     4.172822, Batch Acc: 0.113534, Tokens per Sec:     1548, Lr: 0.000210
2025-05-19 05:55:11,136 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 05:55:11,136 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 05:57:55,867 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.28, ppl:  72.51, acc:   0.11, generation: 164.7190[sec], evaluation: 0.0000[sec]
2025-05-19 05:57:55,872 - INFO - joeynmt.training - Example #0
2025-05-19 05:57:55,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 05:57:55,872 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 05:57:55,872 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'che', 'non', 'è', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'persone', 'di', 'persone', 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di', 'un', "po'", 'di']
2025-05-19 05:57:55,872 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 05:57:55,872 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 05:57:55,872 - INFO - joeynmt.training - 	Hypothesis: La mia cosa che non è un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di un po' di persone di persone di un po' di un po' di un po' di un po' di un po' di
2025-05-19 05:57:55,872 - INFO - joeynmt.training - Example #1
2025-05-19 05:57:55,872 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non
2025-05-19 05:57:55,873 - INFO - joeynmt.training - Example #2
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di']
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Hypothesis: In un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di
2025-05-19 05:57:55,873 - INFO - joeynmt.training - Example #3
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'è', 'un', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra', 'di', 'nostra']
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Hypothesis: Non è un di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra di nostra
2025-05-19 05:57:55,873 - INFO - joeynmt.training - Example #4
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 05:57:55,873 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la', 'gente', 'e', 'la']
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 05:57:55,873 - INFO - joeynmt.training - 	Hypothesis: La gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la gente e la
2025-05-19 05:58:39,759 - INFO - joeynmt.training - Epoch  10, Step:    30100, Batch Loss:     4.462992, Batch Acc: 0.110795, Tokens per Sec:     1480, Lr: 0.000210
2025-05-19 05:59:22,196 - INFO - joeynmt.training - Epoch  10, Step:    30200, Batch Loss:     4.236388, Batch Acc: 0.110427, Tokens per Sec:     1501, Lr: 0.000210
2025-05-19 06:00:06,529 - INFO - joeynmt.training - Epoch  10, Step:    30300, Batch Loss:     4.199635, Batch Acc: 0.111902, Tokens per Sec:     1480, Lr: 0.000210
2025-05-19 06:00:49,270 - INFO - joeynmt.training - Epoch  10, Step:    30400, Batch Loss:     4.319296, Batch Acc: 0.111128, Tokens per Sec:     1506, Lr: 0.000210
2025-05-19 06:01:32,630 - INFO - joeynmt.training - Epoch  10, Step:    30500, Batch Loss:     4.203279, Batch Acc: 0.107625, Tokens per Sec:     1544, Lr: 0.000210
2025-05-19 06:01:32,631 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 06:01:32,631 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 06:04:17,110 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.29, ppl:  72.74, acc:   0.11, generation: 164.4664[sec], evaluation: 0.0000[sec]
2025-05-19 06:04:17,115 - INFO - joeynmt.training - Example #0
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'che']
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo che
2025-05-19 06:04:17,115 - INFO - joeynmt.training - Example #1
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che']
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Hypothesis: Ma non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che
2025-05-19 06:04:17,115 - INFO - joeynmt.training - Example #2
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 06:04:17,115 - INFO - joeynmt.training - 	Hypothesis: In un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 06:04:17,115 - INFO - joeynmt.training - Example #3
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 06:04:17,115 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di', 'un', 'mondo', 'di']
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Hypothesis: Si un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di un mondo di
2025-05-19 06:04:17,116 - INFO - joeynmt.training - Example #4
2025-05-19 06:04:17,116 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 06:04:17,116 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 06:04:17,116 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', 'cosa', 'non', 'è', 'un', "po'"]
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 06:04:17,116 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un cosa non è un po'
2025-05-19 06:05:00,075 - INFO - joeynmt.training - Epoch  10, Step:    30600, Batch Loss:     4.219982, Batch Acc: 0.111669, Tokens per Sec:     1520, Lr: 0.000210
2025-05-19 06:05:43,461 - INFO - joeynmt.training - Epoch  10, Step:    30700, Batch Loss:     4.242229, Batch Acc: 0.110584, Tokens per Sec:     1473, Lr: 0.000210
2025-05-19 06:06:27,204 - INFO - joeynmt.training - Epoch  10, Step:    30800, Batch Loss:     4.282868, Batch Acc: 0.113132, Tokens per Sec:     1452, Lr: 0.000210
2025-05-19 06:07:10,957 - INFO - joeynmt.training - Epoch  10, Step:    30900, Batch Loss:     4.264193, Batch Acc: 0.112886, Tokens per Sec:     1475, Lr: 0.000210
2025-05-19 06:07:54,490 - INFO - joeynmt.training - Epoch  10, Step:    31000, Batch Loss:     4.190241, Batch Acc: 0.113924, Tokens per Sec:     1472, Lr: 0.000210
2025-05-19 06:07:54,491 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 06:07:54,491 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 06:10:40,910 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.32, ppl:  75.28, acc:   0.11, generation: 166.4074[sec], evaluation: 0.0000[sec]
2025-05-19 06:10:40,916 - INFO - joeynmt.training - Example #0
2025-05-19 06:10:40,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 06:10:40,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 06:10:40,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è', 'che', 'è']
2025-05-19 06:10:40,916 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 06:10:40,916 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 06:10:40,916 - INFO - joeynmt.training - 	Hypothesis: In un modo che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è che è
2025-05-19 06:10:40,917 - INFO - joeynmt.training - Example #1
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non', 'non']
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Hypothesis: Ma non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non non
2025-05-19 06:10:40,917 - INFO - joeynmt.training - Example #2
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema']
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Hypothesis: In di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema di un sistema
2025-05-19 06:10:40,917 - INFO - joeynmt.training - Example #3
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'la', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone', 'di', 'loro', 'persone']
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Hypothesis: E la loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone di loro persone
2025-05-19 06:10:40,917 - INFO - joeynmt.training - Example #4
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 06:10:40,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non', 'è', 'che', 'non']
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 06:10:40,917 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non è che non
2025-05-19 06:11:23,820 - INFO - joeynmt.training - Epoch  10, Step:    31100, Batch Loss:     4.518785, Batch Acc: 0.112389, Tokens per Sec:     1511, Lr: 0.000210
2025-05-19 06:12:08,073 - INFO - joeynmt.training - Epoch  10, Step:    31200, Batch Loss:     4.251129, Batch Acc: 0.109128, Tokens per Sec:     1485, Lr: 0.000210
2025-05-19 06:12:50,555 - INFO - joeynmt.training - Epoch  10, Step:    31300, Batch Loss:     4.238337, Batch Acc: 0.113476, Tokens per Sec:     1533, Lr: 0.000210
2025-05-19 06:13:33,651 - INFO - joeynmt.training - Epoch  10, Step:    31400, Batch Loss:     4.260416, Batch Acc: 0.110912, Tokens per Sec:     1498, Lr: 0.000210
2025-05-19 06:14:16,169 - INFO - joeynmt.training - Epoch  10, Step:    31500, Batch Loss:     4.254101, Batch Acc: 0.114565, Tokens per Sec:     1506, Lr: 0.000210
2025-05-19 06:14:16,171 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 06:14:16,171 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 06:16:56,592 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   4.26, ppl:  71.07, acc:   0.11, generation: 160.4100[sec], evaluation: 0.0000[sec]
2025-05-19 06:16:56,596 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-19 06:16:56,807 - INFO - joeynmt.helpers - delete models_bpelvl/26000.ckpt
2025-05-19 06:16:56,810 - INFO - joeynmt.training - Example #0
2025-05-19 06:16:56,810 - DEBUG - joeynmt.training - 	Tokenized source:     ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Foli@@', 'en', 'gezeigt,', 'um', 'zu', 'ver@@', 'anschau@@', 'lichen,', 'dass', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'app@@', 'e,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grös@@', 'se', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'gesch@@', 'rum@@', 'pft', 'ist.']
2025-05-19 06:16:56,810 - DEBUG - joeynmt.training - 	Tokenized reference:  ["L'anno", 'scorso', 'ho', 'mostrato', 'queste', 'diapositive', 'per', 'dimostrare', 'che', 'la', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica,', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '48', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali,', 'si', 'è', 'ri@@', 'stretta', 'del', '40@@', '%.']
2025-05-19 06:16:56,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un', 'modo', 'che', 'non', 'sono', 'un']
2025-05-19 06:16:56,810 - INFO - joeynmt.training - 	Source:     Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-19 06:16:56,810 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive  per dimostrare che la calotta glaciale artica,  che per quasi tre milioni di anni ha avuto  le dimensioni dei 48 Stati Uniti continentali,  si è ristretta del 40%.
2025-05-19 06:16:56,810 - INFO - joeynmt.training - 	Hypothesis: In un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un modo che non sono un
2025-05-19 06:16:56,811 - INFO - joeynmt.training - Example #1
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ern@@', 'st@@', 'haf@@', 'tigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dick@@', 'e', 'des', 'Eis@@', 'es', 'zeigt.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tuttavia', 'questo', 'sottoval@@', 'uta', 'la', 'gravità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'spess@@', 'ore', 'del', 'ghiaccio.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono', 'un', 'cosa', 'non', 'sono']
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Source:     Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema  perché non mostra lo spessore del ghiaccio.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Hypothesis: Ma non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono un cosa non sono
2025-05-19 06:16:56,811 - INFO - joeynmt.training - Example #2
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['In', 'gewissem', 'Sinne', 'ist', 'die', 'ar@@', 'kt@@', 'ische', 'Eis@@', 'k@@', 'appe', 'das', 'schlag@@', 'ende', 'Herz', 'unseres', 'globalen', 'Klima@@', 'system@@', 's.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'otta', 'glaci@@', 'ale', 'art@@', 'ica', 'è,', 'in', 'un', 'certo', 'senso,', 'il', 'cuore', 'puls@@', 'ante', 'del', 'sistema', 'climatico', 'globale.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['In', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di']
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Source:     In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso,  il cuore pulsante del sistema climatico globale.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Hypothesis: In un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di
2025-05-19 06:16:56,811 - INFO - joeynmt.training - Example #3
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrum@@', 'pft', 'im', 'Somm@@', 'er.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'esp@@', 'ande', "d'@@", 'inverno', 'e', 'si', 'ritir@@', 'a', "d'@@", 'estate.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Non', 'è', 'un', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo', 'di', 'mondo']
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Source:     Sie wächst im Winter und schrumpft im Sommer.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Hypothesis: Non è un di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo di mondo
2025-05-19 06:16:56,811 - INFO - joeynmt.training - Example #4
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['Die', 'nächste', 'Foli@@', 'e,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitraff@@', 'er@@', 'aufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossima', 'diapositiva', 'sarà', 'una', 'rapida', 'car@@', 'r@@', 'ell@@', 'ata', 'sugli', 'avven@@', 'imenti', 'degli', 'ultimi', '25', 'anni.']
2025-05-19 06:16:56,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'mia', 'cosa', 'non', 'sono', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo', 'di', 'un', 'modo']
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Source:     Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida  carrellata sugli avvenimenti degli ultimi 25 anni.
2025-05-19 06:16:56,811 - INFO - joeynmt.training - 	Hypothesis: La mia cosa non sono un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo di un modo
2025-05-19 06:17:39,962 - INFO - joeynmt.training - Epoch  10, Step:    31600, Batch Loss:     4.225504, Batch Acc: 0.114198, Tokens per Sec:     1510, Lr: 0.000210
2025-05-19 06:18:23,009 - INFO - joeynmt.training - Epoch  10, Step:    31700, Batch Loss:     4.197421, Batch Acc: 0.109946, Tokens per Sec:     1535, Lr: 0.000210
2025-05-19 06:19:06,077 - INFO - joeynmt.training - Epoch  10, Step:    31800, Batch Loss:     4.304999, Batch Acc: 0.110348, Tokens per Sec:     1474, Lr: 0.000210
2025-05-19 06:19:36,649 - INFO - joeynmt.training - Epoch  10: total training loss 13524.16
2025-05-19 06:19:36,650 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-19 06:19:36,650 - INFO - joeynmt.training - Best validation result (greedy) at step    31500:  71.07 ppl.
2025-05-19 06:19:36,661 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-19 06:19:36,787 - INFO - joeynmt.model - Enc-dec model built.
2025-05-19 06:19:36,825 - INFO - joeynmt.helpers - Load model from /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/31500.ckpt.
2025-05-19 06:19:36,829 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=31870),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=31870),
	loss_function=None)
2025-05-19 06:19:36,832 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-19 06:19:36,832 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 06:19:36,832 - INFO - joeynmt.prediction - Predicting 923 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-19 06:38:09,561 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 1112.7086[sec], evaluation: 0.0000[sec]
2025-05-19 06:38:09,569 - INFO - joeynmt.prediction - Translations saved to: /Users/blueberry/Library/CloudStorage/OneDrive-UniversitätZürichUZH/Studium/FS25/MT/MT_exercises/MT_ex4/mt-exercise-4/models_bpelvl/00031500.hyps.dev.
2025-05-19 06:38:09,569 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-19 06:38:09,570 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-19 06:38:09,570 - INFO - joeynmt.prediction - Predicting 1567 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
